<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 08 Jul 2025 16:12:54 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Accelerating data science innovation: How Bayer Crop Science used AWS AI/ML services to build their next-generation MLOps service</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_1/</link>
      <pubDate>Tue, 08 Jul 2025 16:12:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_1/</guid>
      <description>
        
          
            In this post, we show how Bayer Crop Science manages large-scale data science operations by training models for their data analytics needs and maintaining high-quality code documentation to support developers. Through these solutions, Bayer Crop Science projects up to a 70% reduction in developer onboarding time and up to a 30% improvement in developer productivity.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerating-data-science-innovation-how-bayer-crop-science-used-aws-ai-ml-services-to-build-their-next-generation-mlops-service/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Combat financial fraud with GraphRAG on Amazon Bedrock Knowledge Bases</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_2/</link>
      <pubDate>Tue, 08 Jul 2025 16:10:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_2/</guid>
      <description>
        
          
            In this post, we show how to use Amazon Bedrock Knowledge Bases GraphRAG with Amazon Neptune Analytics to build a financial fraud detection solution.
Link to article: https://aws.amazon.com/blogs/machine-learning/combat-financial-fraud-with-graphrag-on-amazon-bedrock-knowledge-bases/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Classify call center conversations with Amazon Bedrock batch inference</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_3/</link>
      <pubDate>Tue, 08 Jul 2025 16:05:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_3/</guid>
      <description>
        
          
            In this post, we demonstrate how to build an end-to-end solution for text classification using the Amazon Bedrock batch inference capability with the Anthropic’s Claude Haiku model. We walk through classifying travel agency call center conversations into categories, showcasing how to generate synthetic training data, process large volumes of text data, and automate the entire workflow using AWS services.
Link to article: https://aws.amazon.com/blogs/machine-learning/classify-call-center-conversations-with-amazon-bedrock-batch-inference/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Effective cross-lingual LLM evaluation with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_4/</link>
      <pubDate>Tue, 08 Jul 2025 15:46:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_4/</guid>
      <description>
        
          
            In this post, we demonstrate how to use the evaluation features of Amazon Bedrock to deliver reliable results across language barriers without the need for localized prompts or custom infrastructure. Through comprehensive testing and analysis, we share practical strategies to help reduce the cost and complexity of multilingual evaluation while maintaining high standards across global large language model (LLM) deployments.
Link to article: https://aws.amazon.com/blogs/machine-learning/effective-cross-lingual-llm-evaluation-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Cohere Embed 4 multimodal embeddings model is now available on Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_5/</link>
      <pubDate>Tue, 08 Jul 2025 15:43:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_5/</guid>
      <description>
        
          
            The Cohere Embed 4 multimodal embeddings model is now generally available on Amazon SageMaker JumpStart. The Embed 4 model is built for multimodal business documents, has leading multilingual capabilities, and offers notable improvement over Embed 3 across key benchmarks. In this post, we discuss the benefits and capabilities of this new model. We also walk you through how to deploy and use the Embed 4 model using SageMaker JumpStart.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How INRIX accelerates transportation planning with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/07_07_2025/07_07_2025_0/</link>
      <pubDate>Mon, 07 Jul 2025 20:40:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_07_2025/07_07_2025_0/</guid>
      <description>
        
          
            INRIX pioneered the use of GPS data from connected vehicles for transportation intelligence. In this post, we partnered with Amazon Web Services (AWS) customer INRIX to demonstrate how Amazon Bedrock can be used to determine the best countermeasures for specific city locations using rich transportation data and how such countermeasures can be automatically visualized in street view images. This approach allows for significant planning acceleration compared to traditional approaches using conceptual drawings.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Qwen3 family of reasoning models now available in Amazon Bedrock Marketplace and Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/07_07_2025/07_07_2025_1/</link>
      <pubDate>Mon, 07 Jul 2025 19:58:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_07_2025/07_07_2025_1/</guid>
      <description>
        
          
            Today, we are excited to announce that Qwen3, the latest generation of large language models (LLMs) in the Qwen family, is available through Amazon Bedrock Marketplace and Amazon SageMaker JumpStart. With this launch, you can deploy the Qwen3 models—available in 0.6B, 4B, 8B, and 32B parameter sizes—to build, experiment, and responsibly scale your generative AI applications on AWS. In this post, we demonstrate how to get started with Qwen3 on Amazon Bedrock Marketplace and SageMaker JumpStart.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a just-in-time knowledge base with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/07_07_2025/07_07_2025_2/</link>
      <pubDate>Mon, 07 Jul 2025 19:56:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_07_2025/07_07_2025_2/</guid>
      <description>
        
          
            Traditional Retrieval Augmented Generation (RAG) systems consume valuable resources by ingesting and maintaining embeddings for documents that might never be queried, resulting in unnecessary storage costs and reduced system efficiency. This post presents a just-in-time knowledge base solution that reduces unused consumption through intelligent document processing. The solution processes documents only when needed and automatically removes unused resources, so organizations can scale their document repositories without proportionally increasing infrastructure costs.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Agents as escalators: Real-time AI video monitoring with Amazon Bedrock Agents and video streams</title>
      <link>https://www.dotnetramblings.com/post/07_07_2025/07_07_2025_3/</link>
      <pubDate>Mon, 07 Jul 2025 19:52:55 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_07_2025/07_07_2025_3/</guid>
      <description>
        
          
            In this post, we show how to build a fully deployable solution that processes video streams using OpenCV, Amazon Bedrock for contextual scene understanding and automated responses through Amazon Bedrock Agents. This solution extends the capabilities demonstrated in Automate chatbot for document and data retrieval using Amazon Bedrock Agents and Knowledge Bases, which discussed using Amazon Bedrock Agents for document and data retrieval. In this post, we apply Amazon Bedrock Agents to real-time video analysis and event monitoring.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Transforming network operations with AI: How Swisscom built a network assistant using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/03_07_2025/03_07_2025_3/</link>
      <pubDate>Thu, 03 Jul 2025 14:07:44 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_07_2025/03_07_2025_3/</guid>
      <description>
        
          
            In this post, we explore how Swisscom developed their Network Assistant. We discuss the initial challenges and how they implemented a solution that delivers measurable benefits. We examine the technical architecture, discuss key learnings, and look at future enhancements that can further transform network operations.
Link to article: https://aws.amazon.com/blogs/machine-learning/transforming-network-operations-with-ai-how-swisscom-built-a-network-assistant-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>End-to-End model training and deployment with Amazon SageMaker Unified Studio</title>
      <link>https://www.dotnetramblings.com/post/03_07_2025/03_07_2025_4/</link>
      <pubDate>Thu, 03 Jul 2025 14:04:43 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_07_2025/03_07_2025_4/</guid>
      <description>
        
          
            In this post, we guide you through the stages of customizing large language models (LLMs) with SageMaker Unified Studio and SageMaker AI, covering the end-to-end process starting from data discovery to fine-tuning FMs with SageMaker AI distributed training, tracking metrics using MLflow, and then deploying models using SageMaker AI inference for real-time inference. We also discuss best practices to choose the right instance size and share some debugging best practices while working with JupyterLab notebooks in SageMaker Unified Studio.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimize RAG in production environments using Amazon SageMaker JumpStart and Amazon OpenSearch Service</title>
      <link>https://www.dotnetramblings.com/post/02_07_2025/02_07_2025_0/</link>
      <pubDate>Wed, 02 Jul 2025 20:55:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_07_2025/02_07_2025_0/</guid>
      <description>
        
          
            In this post, we show how to use Amazon OpenSearch Service as a vector store to build an efficient RAG application.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimize-rag-in-production-environments-using-amazon-sagemaker-jumpstart-and-amazon-opensearch-service/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Advancing AI agent governance with Boomi and AWS: A unified approach to observability and compliance</title>
      <link>https://www.dotnetramblings.com/post/02_07_2025/02_07_2025_2/</link>
      <pubDate>Wed, 02 Jul 2025 19:22:05 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_07_2025/02_07_2025_2/</guid>
      <description>
        
          
            In this post, we share how Boomi partnered with AWS to help enterprises accelerate and scale AI adoption with confidence using Agent Control Tower.
Link to article: https://aws.amazon.com/blogs/machine-learning/advancing-ai-agent-governance-with-boomi-and-aws-a-unified-approach-to-observability-and-compliance/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use Amazon SageMaker Unified Studio to build complex AI workflows using Amazon Bedrock Flows</title>
      <link>https://www.dotnetramblings.com/post/01_07_2025/01_07_2025_1/</link>
      <pubDate>Tue, 01 Jul 2025 20:42:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_07_2025/01_07_2025_1/</guid>
      <description>
        
          
            In this post, we demonstrate how you can use SageMaker Unified Studio to create complex AI workflows using Amazon Bedrock Flows.
Link to article: https://aws.amazon.com/blogs/machine-learning/use-amazon-sagemaker-unified-studio-to-build-complex-ai-workflows-using-amazon-bedrock-flows/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerating AI innovation: Scale MCP servers for enterprise workloads with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/01_07_2025/01_07_2025_2/</link>
      <pubDate>Tue, 01 Jul 2025 18:16:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_07_2025/01_07_2025_2/</guid>
      <description>
        
          
            In this post, we present a centralized Model Context Protocol (MCP) server implementation using Amazon Bedrock that provides shared access to tools and resources for enterprise AI workloads. The solution enables organizations to accelerate AI innovation by standardizing access to resources and tools through MCP, while maintaining security and governance through a centralized approach.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerating-ai-innovation-scale-mcp-servers-for-enterprise-workloads-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Choosing the right approach for generative AI-powered structured data retrieval</title>
      <link>https://www.dotnetramblings.com/post/01_07_2025/01_07_2025_3/</link>
      <pubDate>Tue, 01 Jul 2025 18:11:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_07_2025/01_07_2025_3/</guid>
      <description>
        
          
            In this post, we explore five different patterns for implementing LLM-powered structured data query capabilities in AWS, including direct conversational interfaces, BI tool enhancements, and custom text-to-SQL solutions.
Link to article: https://aws.amazon.com/blogs/machine-learning/choosing-the-right-approach-for-generative-ai-powered-structured-data-retrieval/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Revolutionizing drug data analysis using Amazon Bedrock multimodal RAG capabilities</title>
      <link>https://www.dotnetramblings.com/post/01_07_2025/01_07_2025_4/</link>
      <pubDate>Tue, 01 Jul 2025 18:05:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_07_2025/01_07_2025_4/</guid>
      <description>
        
          
            In this post, we explore how Amazon Bedrock&#39;s multimodal RAG capabilities revolutionize drug data analysis by efficiently processing complex medical documentation containing text, images, graphs, and tables.
Link to article: https://aws.amazon.com/blogs/machine-learning/revolutionizing-drug-data-analysis-using-amazon-bedrock-multimodal-rag-capabilities/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
