<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Mon, 10 Mar 2025 20:59:29 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Transforming financial analysis with CreditAI on Amazon Bedrock: Octus’s journey with AWS</title>
      <link>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_0/</link>
      <pubDate>Mon, 10 Mar 2025 20:59:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_0/</guid>
      <description>
        
          
            In this post, we demonstrate how Octus migrated its flagship product, CreditAI, to Amazon Bedrock, transforming how investment professionals access and analyze credit intelligence. We walk through the journey Octus took from managing multiple cloud providers and costly GPU instances to implementing a streamlined, cost-effective solution using AWS services including Amazon Bedrock, AWS Fargate, and Amazon OpenSearch Service.
Link to article: https://aws.amazon.com/blogs/machine-learning/transforming-financial-analysis-with-creditai-on-amazon-bedrock-octuss-journey-with-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimize reasoning models like DeepSeek with prompt optimization on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_1/</link>
      <pubDate>Mon, 10 Mar 2025 20:53:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to optimize reasoning models like DeepSeek-R1 using prompt optimization on Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimize-reasoning-models-like-deepseek-with-prompt-optimization-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock announces general availability of multi-agent collaboration</title>
      <link>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_3/</link>
      <pubDate>Mon, 10 Mar 2025 16:08:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_3/</guid>
      <description>
        
          
            Today, we’re announcing the general availability (GA) of multi-agent collaboration on Amazon Bedrock. This capability allows developers to build, deploy, and manage networks of AI agents that work together to execute complex, multi-step workflows efficiently.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-announces-general-availability-of-multi-agent-collaboration/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerating insurance policy reviews with generative AI: Verisk’s Mozart companion</title>
      <link>https://www.dotnetramblings.com/post/07_03_2025/07_03_2025_1/</link>
      <pubDate>Fri, 07 Mar 2025 20:52:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_03_2025/07_03_2025_1/</guid>
      <description>
        
          
            This post is co-authored with Sundeep Sardana, Malolan Raman, Joseph Lam, Maitri Shah and Vaibhav Singh from Verisk. Verisk (Nasdaq: VRSK) is a leading strategic data analytics and technology partner to the global insurance industry, empowering clients to strengthen operating efficiency, improve underwriting and claims outcomes, combat fraud, and make informed decisions about global risks. […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerating-insurance-policy-reviews-with-generative-ai-verisks-mozart-companion/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Announcing general availability of Amazon Bedrock Knowledge Bases GraphRAG with Amazon Neptune Analytics</title>
      <link>https://www.dotnetramblings.com/post/07_03_2025/07_03_2025_3/</link>
      <pubDate>Fri, 07 Mar 2025 18:23:14 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_03_2025/07_03_2025_3/</guid>
      <description>
        
          
            Today, Amazon Web Services (AWS) announced the general availability of Amazon Bedrock Knowledge Bases GraphRAG (GraphRAG), a capability in Amazon Bedrock Knowledge Bases that enhances Retrieval-Augmented Generation (RAG) with graph data in Amazon Neptune Analytics. In this post, we discuss the benefits of GraphRAG and how to get started with it in Amazon Bedrock Knowledge Bases.
Link to article: https://aws.amazon.com/blogs/machine-learning/announcing-general-availability-of-amazon-bedrock-knowledge-bases-graphrag-with-amazon-neptune-analytics/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a Multi-Agent System with LangGraph and Mistral on AWS</title>
      <link>https://www.dotnetramblings.com/post/06_03_2025/06_03_2025_4/</link>
      <pubDate>Thu, 06 Mar 2025 17:02:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_03_2025/06_03_2025_4/</guid>
      <description>
        
          
            In this post, we explore how to use LangGraph and Mistral models on Amazon Bedrock to create a powerful multi-agent system that can handle sophisticated workflows through collaborative problem-solving. This integration enables the creation of AI agents that can work together to solve complex problems, mimicking humanlike reasoning and collaboration.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-multi-agent-system-with-langgraph-and-mistral-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluate RAG responses with Amazon Bedrock, LlamaIndex and RAGAS</title>
      <link>https://www.dotnetramblings.com/post/06_03_2025/06_03_2025_6/</link>
      <pubDate>Thu, 06 Mar 2025 16:52:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_03_2025/06_03_2025_6/</guid>
      <description>
        
          
            In this post, we’ll explore how to leverage Amazon Bedrock, LlamaIndex, and RAGAS to enhance your RAG implementations. You’ll learn practical techniques to evaluate and optimize your AI systems, enabling more accurate, context-aware responses that align with your organization’s specific needs.
Link to article: https://aws.amazon.com/blogs/machine-learning/evaluate-rag-responses-with-amazon-bedrock-llamaindex-and-ragas/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Innovating at speed: BMW’s generative AI solution for cloud incident analysis</title>
      <link>https://www.dotnetramblings.com/post/05_03_2025/05_03_2025_0/</link>
      <pubDate>Wed, 05 Mar 2025 21:33:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_03_2025/05_03_2025_0/</guid>
      <description>
        
          
            In this post, we explain how BMW uses generative AI to speed up the root cause analysis of incidents in complex and distributed systems in the cloud such as BMW’s Connected Vehicle backend serving 23 million vehicles. Read on to learn how the solution, collaboratively pioneered by AWS and BMW, uses Amazon Bedrock Agents and Amazon CloudWatch logs and metrics to find root causes quicker. This post is intended for cloud solution architects and developers interested in speeding up their incident workflows.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Time series forecasting with LLM-based foundation models and scalable AIOps on AWS</title>
      <link>https://www.dotnetramblings.com/post/05_03_2025/05_03_2025_1/</link>
      <pubDate>Wed, 05 Mar 2025 21:20:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_03_2025/05_03_2025_1/</guid>
      <description>
        
          
            In this blog post, we will guide you through the process of integrating Chronos into Amazon SageMaker Pipeline using a synthetic dataset that simulates a sales forecasting scenario, unlocking accurate and efficient predictions with minimal data.
Link to article: https://aws.amazon.com/blogs/machine-learning/time-series-forecasting-with-llm-based-foundation-models-and-scalable-aiops-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Ground truth generation and review best practices for evaluating generative AI question-answering with FMEval</title>
      <link>https://www.dotnetramblings.com/post/05_03_2025/05_03_2025_2/</link>
      <pubDate>Wed, 05 Mar 2025 21:17:27 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_03_2025/05_03_2025_2/</guid>
      <description>
        
          
            In this post, we discuss best practices for applying LLMs to generate ground truth for evaluating question-answering assistants with FMEval on an enterprise scale. FMEval is a comprehensive evaluation suite from Amazon SageMaker Clarify, and provides standardized implementations of metrics to assess quality and responsibility. To learn more about FMEval, see Evaluate large language models for quality and responsibility of LLMs.
Link to article: https://aws.amazon.com/blogs/machine-learning/ground-truth-generation-and-review-best-practices-for-evaluating-generative-ai-question-answering-with-fmeval/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate AWS Well-Architected reviews with Generative AI</title>
      <link>https://www.dotnetramblings.com/post/04_03_2025/04_03_2025_2/</link>
      <pubDate>Tue, 04 Mar 2025 16:28:03 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_03_2025/04_03_2025_2/</guid>
      <description>
        
          
            In this post, we explore a generative AI solution leveraging Amazon Bedrock to streamline the WAFR process. We demonstrate how to harness the power of LLMs to build an intelligent, scalable system that analyzes architecture documents and generates insightful recommendations based on AWS Well-Architected best practices. This solution automates portions of the WAFR report creation, helping solutions architects improve the efficiency and thoroughness of architectural assessments while supporting their decision-making process.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Dynamic metadata filtering for Amazon Bedrock Knowledge Bases with LangChain</title>
      <link>https://www.dotnetramblings.com/post/04_03_2025/04_03_2025_3/</link>
      <pubDate>Tue, 04 Mar 2025 16:19:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_03_2025/04_03_2025_3/</guid>
      <description>
        
          
            Amazon Bedrock Knowledge Bases has a metadata filtering capability that allows you to refine search results based on specific attributes of the documents, improving retrieval accuracy and the relevance of responses. These metadata filters can be used in combination with the typical semantic (or hybrid) similarity search. In this post, we discuss using metadata filters with Amazon Bedrock Knowledge Bases.
Link to article: https://aws.amazon.com/blogs/machine-learning/dynamic-metadata-filtering-for-amazon-bedrock-knowledge-bases-with-langchain/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Customize DeepSeek-R1 distilled models using Amazon SageMaker HyperPod recipes – Part 1</title>
      <link>https://www.dotnetramblings.com/post/03_03_2025/03_03_2025_0/</link>
      <pubDate>Mon, 03 Mar 2025 21:09:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_03_2025/03_03_2025_0/</guid>
      <description>
        
          
            In this two-part series, we discuss how you can reduce the DeepSeek model customization complexity by using the pre-built fine-tuning workflows (also called “recipes”) for both DeepSeek-R1 model and its distilled variations, released as part of Amazon SageMaker HyperPod recipes. In this first post, we will build a solution architecture for fine-tuning DeepSeek-R1 distilled models and demonstrate the approach by providing a step-by-step example on customizing the DeepSeek-R1 Distill Qwen 7b model using recipes, achieving an average of 25% on all the Rouge scores, with a maximum of 49% on Rouge 2 score with both SageMaker HyperPod and SageMaker training jobs.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Reduce conversational AI response time through inference at the edge with AWS Local Zones</title>
      <link>https://www.dotnetramblings.com/post/03_03_2025/03_03_2025_4/</link>
      <pubDate>Mon, 03 Mar 2025 16:44:46 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_03_2025/03_03_2025_4/</guid>
      <description>
        
          
            This guide demonstrates how to deploy an open source foundation model from Hugging Face on Amazon EC2 instances across three locations: a commercial AWS Region and two AWS Local Zones. Through comparative benchmarking tests, we illustrate how deploying foundation models in Local Zones closer to end users can significantly reduce latency—a critical factor for real-time applications such as conversational AI assistants.
Link to article: https://aws.amazon.com/blogs/machine-learning/reduce-conversational-ai-response-time-through-inference-at-the-edge-with-aws-local-zones/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Pixtral-12B-2409 is now available on Amazon Bedrock Marketplace</title>
      <link>https://www.dotnetramblings.com/post/03_03_2025/03_03_2025_5/</link>
      <pubDate>Mon, 03 Mar 2025 16:43:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_03_2025/03_03_2025_5/</guid>
      <description>
        
          
            In this post, we walk through how to discover, deploy, and use the Mistral AI Pixtral 12B model for a variety of real-world vision use cases.
Link to article: https://aws.amazon.com/blogs/machine-learning/pixtral-12b-2409-is-now-available-on-amazon-bedrock-marketplace/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
