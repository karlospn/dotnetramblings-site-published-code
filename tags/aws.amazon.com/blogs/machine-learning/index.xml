<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 21 May 2024 16:28:09 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Create a multimodal assistant with advanced RAG and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_4/</link>
      <pubDate>Tue, 21 May 2024 16:28:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_4/</guid>
      <description>
        
          
            In this post, we present a new approach named multimodal RAG (mmRAG) to tackle those existing limitations in greater detail. The solution intends to address these limitations for practical generative artificial intelligence (AI) assistant use cases. Additionally, we examine potential solutions to enhance the capabilities of large language models (LLMs) and visual language models (VLMs) with advanced LangChain capabilities, enabling them to generate more comprehensive, coherent, and accurate outputs while effectively handling multimodal data
          
          
        
      </description>
    </item>
    
    <item>
      <title>How 20 Minutes empowers journalists and boosts audience engagement with generative AI on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_5/</link>
      <pubDate>Tue, 21 May 2024 16:16:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_5/</guid>
      <description>
        
          
            This post is co-written with Aurélien Capdecomme and Bertrand d’Aure from 20 Minutes. With 19 million monthly readers, 20 Minutes is a major player in the French media landscape. The media organization delivers useful, relevant, and accessible information to an audience that consists primarily of young and active urban readers. Every month, nearly 8.3 million 25–49-year-olds choose […]
Link to article: https://aws.amazon.com/blogs/machine-learning/how-20-minutes-empowers-journalists-and-boosts-audience-engagement-with-generative-ai-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Efficient and cost-effective multi-tenant LoRA serving with Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_13/</link>
      <pubDate>Tue, 21 May 2024 15:33:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_13/</guid>
      <description>
        
          
            In this post, we explore a solution that addresses these challenges head-on using LoRA serving with Amazon SageMaker. By using the new performance optimizations of LoRA techniques in SageMaker large model inference (LMI) containers along with inference components, we demonstrate how organizations can efficiently manage and serve their growing portfolio of fine-tuned models, while optimizing costs and providing seamless performance for their customers. The latest SageMaker LMI container offers unmerged-LoRA inference, sped up with our LMI-Dist inference engine and OpenAI style chat schema.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Mixtral 8x22B is now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/17_05_2024/17_05_2024_3/</link>
      <pubDate>Fri, 17 May 2024 16:02:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_05_2024/17_05_2024_3/</guid>
      <description>
        
          
            Today, we are excited to announce the Mixtral-8x22B large language model (LLM), developed by Mistral AI, is available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. You can try out this model with SageMaker JumpStart, a machine learning (ML) hub that provides access to algorithms and models so you […]
Link to article: https://aws.amazon.com/blogs/machine-learning/mixtral-8x22b-is-now-available-in-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building Generative AI prompt chaining workflows with human in the loop</title>
      <link>https://www.dotnetramblings.com/post/17_05_2024/17_05_2024_4/</link>
      <pubDate>Fri, 17 May 2024 15:51:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_05_2024/17_05_2024_4/</guid>
      <description>
        
          
            While Generative AI can create highly realistic content, including text, images, and videos, it can also generate outputs that appear plausible but are verifiably incorrect. Incorporating human judgment is crucial, especially in complex and high-risk decision-making scenarios. This involves building a human-in-the-loop process where humans play an active role in decision making alongside the AI system. In this blog post, you will learn about prompt chaining, how to break a complex task into multiple tasks to use prompt chaining with an LLM in a specific order, and how to involve a human to review the response generated by the LLM.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How LotteON built a personalized recommendation system using Amazon SageMaker and MLOps</title>
      <link>https://www.dotnetramblings.com/post/16_05_2024/16_05_2024_6/</link>
      <pubDate>Thu, 16 May 2024 16:13:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_05_2024/16_05_2024_6/</guid>
      <description>
        
          
            This post is co-written with HyeKyung Yang, Jieun Lim, and SeungBum Shim from LotteON. LotteON aims to be a platform that not only sells products, but also provides a personalized recommendation experience tailored to your preferred lifestyle. LotteON operates various specialty stores, including fashion, beauty, luxury, and kids, and strives to provide a personalized shopping […]
Link to article: https://aws.amazon.com/blogs/machine-learning/how-lotteon-built-a-personalized-recommendation-system-using-amazon-sagemaker-and-mlops/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a serverless exam generator application from your own lecture content using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/15_05_2024/15_05_2024_5/</link>
      <pubDate>Wed, 15 May 2024 16:21:20 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_05_2024/15_05_2024_5/</guid>
      <description>
        
          
            Crafting new questions for exams and quizzes can be tedious and time-consuming for educators. The time required varies based on factors like subject matter, question types, experience level, and class level. Multiple-choice questions require substantial time to generate quality distractors and ensure a single unambiguous answer, and composing effective true-false questions demands careful effort to […]
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-serverless-exam-generator-application-from-your-own-lecture-content-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate NLP inference with ONNX Runtime on AWS Graviton processors</title>
      <link>https://www.dotnetramblings.com/post/15_05_2024/15_05_2024_6/</link>
      <pubDate>Wed, 15 May 2024 16:03:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_05_2024/15_05_2024_6/</guid>
      <description>
        
          
            ONNX is an open source machine learning (ML) framework that provides interoperability across a wide range of frameworks, operating systems, and hardware platforms. ONNX Runtime is the runtime engine used for model inference and training with ONNX. AWS Graviton3 processors are optimized for ML workloads, including support for bfloat16, Scalable Vector Extension (SVE), and Matrix […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-nlp-inference-with-onnx-runtime-on-aws-graviton-processors/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Learn how Amazon Ads created a generative AI-powered image generation capability using Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/15_05_2024/15_05_2024_7/</link>
      <pubDate>Wed, 15 May 2024 15:45:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_05_2024/15_05_2024_7/</guid>
      <description>
        
          
            Amazon Ads helps advertisers and brands achieve their business goals by developing innovative solutions that reach millions of Amazon customers at every stage of their journey. At Amazon Ads, we believe that what makes advertising effective is delivering relevant ads in the right context and at the right moment within the consumer buying journey. With that […]
Link to article: https://aws.amazon.com/blogs/machine-learning/learn-how-amazon-ads-created-a-generative-ai-powered-image-generation-capability-using-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
