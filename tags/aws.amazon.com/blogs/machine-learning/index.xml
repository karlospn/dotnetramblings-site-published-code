<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Wed, 19 Mar 2025 16:56:57 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tool choice with Amazon Nova models</title>
      <link>https://www.dotnetramblings.com/post/19_03_2025/19_03_2025_3/</link>
      <pubDate>Wed, 19 Mar 2025 16:56:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_03_2025/19_03_2025_3/</guid>
      <description>
        
          
            To add fine-grained control to how tools are used, we have released a feature for tool choice for Amazon Nova models. Instead of relying on prompt engineering, tool choice forces the model to adhere to the settings in place. In this post, we discuss tool use and the new tool choice feature, with example use cases.
Link to article: https://aws.amazon.com/blogs/machine-learning/tool-choice-with-amazon-nova-models/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Integrate generative AI capabilities into Microsoft Office using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/19_03_2025/19_03_2025_4/</link>
      <pubDate>Wed, 19 Mar 2025 16:39:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_03_2025/19_03_2025_4/</guid>
      <description>
        
          
            In this blog post, we showcase a powerful solution that seamlessly integrates AWS generative AI capabilities in the form of large language models (LLMs) based on Amazon Bedrock into the Office experience. By harnessing the latest advancements in generative AI, we empower employees to unlock new levels of efficiency and creativity within the tools they already use every day.
Link to article: https://aws.amazon.com/blogs/machine-learning/integrate-generative-ai-capabilities-into-microsoft-office-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>From innovation to impact: How AWS and NVIDIA enable real-world generative AI success</title>
      <link>https://www.dotnetramblings.com/post/19_03_2025/19_03_2025_5/</link>
      <pubDate>Wed, 19 Mar 2025 16:11:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_03_2025/19_03_2025_5/</guid>
      <description>
        
          
            In this post, I will share some of these customers’ remarkable journeys, offering practical insights for any organization looking to harness the power of generative AI.
Link to article: https://aws.amazon.com/blogs/machine-learning/from-innovation-to-impact-how-aws-and-nvidia-enable-real-world-generative-ai-success/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Q Business now available in Europe (Ireland) AWS Region</title>
      <link>https://www.dotnetramblings.com/post/19_03_2025/19_03_2025_10/</link>
      <pubDate>Wed, 19 Mar 2025 14:17:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_03_2025/19_03_2025_10/</guid>
      <description>
        
          
            Today, we are excited to announce that Amazon Q Business—a fully managed generative-AI powered assistant that you can configure to answer questions, provide summaries and generate content based on your enterprise data—is now generally available in the Europe (Ireland) AWS Region.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-q-business-now-available-in-europe-ireland-aws-region/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Running NVIDIA NeMo 2.0 Framework on Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_0/</link>
      <pubDate>Tue, 18 Mar 2025 20:00:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_0/</guid>
      <description>
        
          
            In this blog post, we explore how to integrate NeMo 2.0 with SageMaker HyperPod to enable efficient training of large language models (LLMs). We cover the setup process and provide a step-by-step guide to running a NeMo job on a SageMaker HyperPod cluster.
Link to article: https://aws.amazon.com/blogs/machine-learning/running-nvidia-nemo-2-0-framework-on-amazon-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>NeMo Retriever Llama 3.2 text embedding and reranking NVIDIA NIM microservices now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_1/</link>
      <pubDate>Tue, 18 Mar 2025 20:00:22 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_1/</guid>
      <description>
        
          
            Today, we are excited to announce that the NeMo Retriever Llama3.2 Text Embedding and Reranking NVIDIA NIM microservices are available in Amazon SageMaker JumpStart. With this launch, you can now deploy NVIDIA’s optimized reranking and embedding models to build, experiment, and responsibly scale your generative AI ideas on AWS. In this post, we demonstrate how to get started with these models on SageMaker JumpStart.
Link to article: https://aws.amazon.com/blogs/machine-learning/nemo-retriever-llama-3-2-text-embedding-and-reranking-nvidia-nim-microservices-now-available-in-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock Guardrails announces IAM Policy-based enforcement to deliver safe AI interactions</title>
      <link>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_5/</link>
      <pubDate>Tue, 18 Mar 2025 18:15:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_5/</guid>
      <description>
        
          
            Today, we’re announcing a significant enhancement to Amazon Bedrock Guardrails: AWS Identity and Access Management (IAM) policy-based enforcement. This powerful capability enables security and compliance teams to establish mandatory guardrails for every model inference call, making sure organizational safety policies are consistently enforced across AI interactions. This feature enhances AI governance by enabling centralized control over guardrail implementation.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-guardrails-announces-iam-policy-based-enforcement-to-deliver-safe-ai-interactions/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build your gen AI–based text-to-SQL application using RAG, powered by Amazon Bedrock (Claude 3 Sonnet and Amazon Titan for embedding)</title>
      <link>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_6/</link>
      <pubDate>Tue, 18 Mar 2025 17:30:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_6/</guid>
      <description>
        
          
            In this post, we explore using Amazon Bedrock to create a text-to-SQL application using RAG. We use Anthropic’s Claude 3.5 Sonnet model to generate SQL queries, Amazon Titan in Amazon Bedrock for text embedding and Amazon Bedrock to access these models.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-your-gen-ai-based-text-to-sql-application-using-rag-powered-by-amazon-bedrock-claude-3-sonnet-and-amazon-titan-for-embedding/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unleash AI innovation with Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_7/</link>
      <pubDate>Tue, 18 Mar 2025 16:30:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_7/</guid>
      <description>
        
          
            In this post, we show how SageMaker HyperPod, and its new features introduced at AWS re:Invent 2024, is designed to meet the demands of modern AI workloads, offering a persistent and optimized cluster tailored for distributed training and accelerated inference at cloud scale and attractive price-performance.
Link to article: https://aws.amazon.com/blogs/machine-learning/unleash-ai-innovation-with-amazon-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Revolutionizing clinical trials with the power of voice and AI</title>
      <link>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_8/</link>
      <pubDate>Tue, 18 Mar 2025 16:25:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_8/</guid>
      <description>
        
          
            As the healthcare industry continues to embrace digital transformation, solutions that combine advanced technologies like audio-to-text translation and LLMs will become increasingly valuable in addressing key challenges, such as patient education, engagement, and empowerment. In this post, we discuss possible use cases for combining speech recognition technology with LLMs, and how the solution can revolutionize clinical trials.
Link to article: https://aws.amazon.com/blogs/machine-learning/revolutionizing-clinical-trials-with-the-power-of-voice-and-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Intelligent healthcare assistants: Empowering stakeholders with personalized support and data-driven insights</title>
      <link>https://www.dotnetramblings.com/post/17_03_2025/17_03_2025_1/</link>
      <pubDate>Mon, 17 Mar 2025 17:49:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_03_2025/17_03_2025_1/</guid>
      <description>
        
          
            Healthcare decisions often require integrating information from multiple sources, such as medical literature, clinical databases, and patient records. LLMs lack the ability to seamlessly access and synthesize data from these diverse and distributed sources. This limits their potential to provide comprehensive and well-informed insights for healthcare applications. In this blog post, we will explore how Mistral LLM on Amazon Bedrock can address these challenges and enable the development of intelligent healthcare agents with LLM function calling capabilities, while maintaining robust data security and privacy through Amazon Bedrock Guardrails.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Getting started with computer use in Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/14_03_2025/14_03_2025_2/</link>
      <pubDate>Fri, 14 Mar 2025 18:20:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_03_2025/14_03_2025_2/</guid>
      <description>
        
          
            Today, we’re announcing computer use support within Amazon Bedrock Agents using Anthropic’s Claude 3.5 Sonnet V2 and Anthropic’s Claude Sonnet 3.7 models on Amazon Bedrock. This integration brings Anthropic’s visual perception capabilities as a managed tool within Amazon Bedrock Agents, providing you with a secure, traceable, and managed way to implement computer use automation in your workflows.
Link to article: https://aws.amazon.com/blogs/machine-learning/getting-started-with-computer-use-in-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluating RAG applications with Amazon Bedrock knowledge base evaluation</title>
      <link>https://www.dotnetramblings.com/post/14_03_2025/14_03_2025_6/</link>
      <pubDate>Fri, 14 Mar 2025 15:39:25 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_03_2025/14_03_2025_6/</guid>
      <description>
        
          
            This post focuses on RAG evaluation with Amazon Bedrock Knowledge Bases, provides a guide to set up the feature, discusses nuances to consider as you evaluate your prompts and responses, and finally discusses best practices. By the end of this post, you will understand how the latest Amazon Bedrock evaluation features can streamline your approach to AI quality assurance, enabling more efficient and confident development of RAG applications.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How GoDaddy built a category generation system at scale with batch inference for Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_6/</link>
      <pubDate>Thu, 13 Mar 2025 16:43:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_6/</guid>
      <description>
        
          
            This post provides an overview of a custom solution developed by the for GoDaddy, a domain registrar, registry, web hosting, and ecommerce company that seeks to make entrepreneurship more accessible by using generative AI to provide personalized business insights to over 21 million customers. In this collaboration, the Generative AI Innovation Center team created an accurate and cost-efficient generative AI–based solution using batch inference in Amazon Bedrock, helping GoDaddy improve their existing product categorization system.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Benchmarking customized models on Amazon Bedrock using LLMPerf and LiteLLM</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_8/</link>
      <pubDate>Thu, 13 Mar 2025 14:09:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_8/</guid>
      <description>
        
          
            This post begins a blog series exploring DeepSeek and open FMs on Amazon Bedrock Custom Model Import. It covers the process of performance benchmarking of custom models in Amazon Bedrock using popular open source tools: LLMPerf and LiteLLM. It includes a notebook that includes step-by-step instructions to deploy a DeepSeek-R1-Distill-Llama-8B model, but the same steps apply for any other model supported by Amazon Bedrock Custom Model Import.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Creating asynchronous AI agents with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_9/</link>
      <pubDate>Thu, 13 Mar 2025 14:06:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_9/</guid>
      <description>
        
          
            The integration of generative AI agents into business processes is poised to accelerate as organizations recognize the untapped potential of these technologies. Advancements in multimodal artificial intelligence (AI), where agents can understand and generate not just text but also images, audio, and video, will further broaden their applications. This post will discuss agentic AI driven architecture and ways of implementing.
Link to article: https://aws.amazon.com/blogs/machine-learning/creating-asynchronous-ai-agents-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How to run Qwen 2.5 on AWS AI chips using Hugging Face libraries</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_10/</link>
      <pubDate>Thu, 13 Mar 2025 14:03:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_10/</guid>
      <description>
        
          
            In this post, we outline how to get started with deploying the Qwen 2.5 family of models on an Inferentia instance using Amazon Elastic Compute Cloud (Amazon EC2) and Amazon SageMaker using the Hugging Face Text Generation Inference (TGI) container and the Hugging Face Optimum Neuron library. Qwen2.5 Coder and Math variants are also supported.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-to-run-qwen-2-5-on-aws-ai-chips-using-hugging-face-libraries/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Revolutionizing customer service: MaestroQA’s integration with Amazon Bedrock for actionable insight</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_11/</link>
      <pubDate>Thu, 13 Mar 2025 14:01:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_11/</guid>
      <description>
        
          
            In this post, we dive deeper into one of MaestroQA’s key features—conversation analytics, which helps support teams uncover customer concerns, address points of friction, adapt support workflows, and identify areas for coaching through the use of Amazon Bedrock. We discuss the unique challenges MaestroQA overcame and how they use AWS to build new features, drive customer insights, and improve operational inefficiencies.
Link to article: https://aws.amazon.com/blogs/machine-learning/revolutionizing-customer-service-maestroqas-integration-with-amazon-bedrock-for-actionable-insight/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimize hosting DeepSeek-R1 distilled models with Hugging Face TGI on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_13/</link>
      <pubDate>Thu, 13 Mar 2025 13:57:58 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_13/</guid>
      <description>
        
          
            In this post, we demonstrate how to optimize hosting DeepSeek-R1 distilled models with Hugging Face Text Generation Inference (TGI) on Amazon SageMaker AI.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimize-hosting-deepseek-r1-distilled-models-with-hugging-face-tgi-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Exploring creative possibilities: A visual guide to Amazon Nova Canvas</title>
      <link>https://www.dotnetramblings.com/post/12_03_2025/12_03_2025_3/</link>
      <pubDate>Wed, 12 Mar 2025 18:10:17 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_03_2025/12_03_2025_3/</guid>
      <description>
        
          
            In this blog post, we showcase a curated gallery of visuals generated by Nova Canvas—categorized by real-world use cases—from marketing and product visualization to concept art and design exploration. Each image is paired with the prompt and parameters that generated it, providing a practical starting point for your own AI-driven creativity. Whether you&#39;re crafting specific types of images, optimizing workflows, or simply seeking inspiration, this guide will help you unlock the full potential of Amazon Nova Canvas.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
