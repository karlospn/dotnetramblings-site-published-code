<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 05 Jun 2025 16:40:32 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Modernize and migrate on-premises fraud detection machine learning workflows to Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_3/</link>
      <pubDate>Thu, 05 Jun 2025 16:40:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_3/</guid>
      <description>
        
          
            Radial is the largest 3PL fulfillment provider, also offering integrated payment, fraud detection, and omnichannel solutions to mid-market and enterprise brands. In this post, we share how Radial optimized the cost and performance of their fraud detection machine learning (ML) applications by modernizing their ML workflow using Amazon SageMaker.
Link to article: https://aws.amazon.com/blogs/machine-learning/modernize-and-migrate-on-premises-fraud-detection-machine-learning-workflows-to-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Contextual retrieval in Anthropic using Amazon Bedrock Knowledge Bases</title>
      <link>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_4/</link>
      <pubDate>Thu, 05 Jun 2025 16:30:55 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_4/</guid>
      <description>
        
          
            Contextual retrieval enhances traditional RAG by adding chunk-specific explanatory context to each chunk before generating embeddings. This approach enriches the vector representation with relevant contextual information, enabling more accurate retrieval of semantically related content when responding to user queries. In this post, we demonstrate how to use contextual retrieval with Anthropic and Amazon Bedrock Knowledge Bases.
Link to article: https://aws.amazon.com/blogs/machine-learning/contextual-retrieval-in-anthropic-using-amazon-bedrock-knowledge-bases/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Run small language models cost-efficiently with AWS Graviton and Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_5/</link>
      <pubDate>Thu, 05 Jun 2025 16:16:20 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_5/</guid>
      <description>
        
          
            In this post, we demonstrate how to deploy a small language model on SageMaker AI by extending our pre-built containers to be compatible with AWS Graviton instances. We first provide an overview of the solution, and then provide detailed implementation steps to help you get started. You can find the example notebook in the GitHub repo.
Link to article: https://aws.amazon.com/blogs/machine-learning/run-small-language-models-cost-efficiently-with-aws-graviton-and-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Impel enhances automotive dealership customer experience with fine-tuned LLMs on Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_0/</link>
      <pubDate>Wed, 04 Jun 2025 21:20:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_0/</guid>
      <description>
        
          
            In this post, we share how Impel enhances the automotive dealership customer experience with fine-tuned LLMs on SageMaker.
Link to article: https://aws.amazon.com/blogs/machine-learning/impel-enhances-automotive-dealership-customer-experience-with-fine-tuned-llms-on-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How climate tech startups are building foundation models with Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_2/</link>
      <pubDate>Wed, 04 Jun 2025 16:07:46 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_2/</guid>
      <description>
        
          
            In this post, we show how climate tech startups are developing foundation models (FMs) that use extensive environmental datasets to tackle issues such as carbon capture, carbon-negative fuels, new materials design for microplastics destruction, and ecosystem preservation. These specialized models require advanced computational capabilities to process and analyze vast amounts of data effectively.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-climate-tech-startups-are-building-foundation-models-with-amazon-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Supercharge your development with Claude Code and Amazon Bedrock prompt caching</title>
      <link>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_3/</link>
      <pubDate>Wed, 04 Jun 2025 16:04:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_3/</guid>
      <description>
        
          
            In this post, we&#39;ll explore how to combine Amazon Bedrock prompt caching with Claude Code—a coding agent released by Anthropic that is now generally available. This powerful combination transforms your development workflow by delivering lightning-fast responses from reducing inference response latency, as well as lowering input token costs.
Link to article: https://aws.amazon.com/blogs/machine-learning/supercharge-your-development-with-claude-code-and-amazon-bedrock-prompt-caching/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlocking the power of Model Context Protocol (MCP) on AWS</title>
      <link>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_4/</link>
      <pubDate>Tue, 03 Jun 2025 16:53:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_4/</guid>
      <description>
        
          
            We’ve witnessed remarkable advances in model capabilities as generative AI companies have invested in developing their offerings. Language models such as Anthropic’s Claude Opus 4 &amp;amp; Sonnet 4 and Amazon Nova on Amazon Bedrock can reason, write, and generate responses with increasing sophistication. But even as these models grow more powerful, they can only work […]
Link to article: https://aws.amazon.com/blogs/machine-learning/unlocking-the-power-of-model-context-protocol-mcp-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a scalable AI assistant to help refugees using AWS</title>
      <link>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_5/</link>
      <pubDate>Tue, 03 Jun 2025 15:35:07 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_5/</guid>
      <description>
        
          
            The Danish humanitarian organization Bevar Ukraine has developed a comprehensive virtual generative AI-powered assistant called Victor, aimed at addressing the pressing needs of Ukrainian refugees integrating into Danish society. This post details our technical implementation using AWS services to create a scalable, multilingual AI assistant system that provides automated assistance while maintaining data security and GDPR compliance.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-scalable-ai-assistant-to-help-refugees-using-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhanced diagnostics flow with LLM and Amazon Bedrock agent integration</title>
      <link>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_6/</link>
      <pubDate>Tue, 03 Jun 2025 15:25:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_6/</guid>
      <description>
        
          
            In this post, we explore how Noodoe uses AI and Amazon Bedrock to optimize EV charging operations. By integrating LLMs, Noodoe enhances station diagnostics, enables dynamic pricing, and delivers multilingual support. These innovations reduce downtime, maximize efficiency, and improve sustainability. Read on to discover how AI is transforming EV charging management.
Link to article: https://aws.amazon.com/blogs/machine-learning/enhanced-diagnostics-flow-with-llm-and-amazon-bedrock-agent-integration/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build GraphRAG applications using Amazon Bedrock Knowledge Bases</title>
      <link>https://www.dotnetramblings.com/post/02_06_2025/02_06_2025_3/</link>
      <pubDate>Mon, 02 Jun 2025 17:39:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_06_2025/02_06_2025_3/</guid>
      <description>
        
          
            In this post, we explore how to use Graph-based Retrieval-Augmented Generation (GraphRAG) in Amazon Bedrock Knowledge Bases to build intelligent applications. Unlike traditional vector search, which retrieves documents based on similarity scores, knowledge graphs encode relationships between entities, allowing large language models (LLMs) to retrieve information with context-aware reasoning.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-graphrag-applications-using-amazon-bedrock-knowledge-bases/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline personalization development: How automated ML workflows accelerate Amazon Personalize implementation</title>
      <link>https://www.dotnetramblings.com/post/02_06_2025/02_06_2025_4/</link>
      <pubDate>Mon, 02 Jun 2025 17:34:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_06_2025/02_06_2025_4/</guid>
      <description>
        
          
            This blog post presents an MLOps solution that uses AWS Cloud Development Kit (AWS CDK) and services like AWS Step Functions, Amazon EventBridge and Amazon Personalize to automate provisioning resources for data preparation, model training, deployment, and monitoring for Amazon Personalize.
Link to article: https://aws.amazon.com/blogs/machine-learning/streamline-personalization-development-how-automated-ml-workflows-accelerate-amazon-personalize-implementation/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fast-track SOP processing using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/02_06_2025/02_06_2025_6/</link>
      <pubDate>Mon, 02 Jun 2025 16:04:37 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_06_2025/02_06_2025_6/</guid>
      <description>
        
          
            When a regulatory body like the US Food and Drug Administration (FDA) introduces changes to regulations, organizations are required to evaluate the changes against their internal SOPs. When necessary, they must update their SOPs to align with the regulation changes and maintain compliance. In this post, we show different approaches using Amazon Bedrock to identify relationships between regulation changes and SOPs.
Link to article: https://aws.amazon.com/blogs/machine-learning/fast-track-sop-processing-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deploy Amazon SageMaker Projects with Terraform Cloud</title>
      <link>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_1/</link>
      <pubDate>Fri, 30 May 2025 17:27:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_1/</guid>
      <description>
        
          
            In this post you define, deploy, and provision a SageMaker Project custom template purely in Terraform. With no dependencies on other IaC tools, you can now enable SageMaker Projects strictly within your Terraform Enterprise infrastructure.
Link to article: https://aws.amazon.com/blogs/machine-learning/deploy-amazon-sagemaker-projects-with-terraform-cloud/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How ZURU improved the accuracy of floor plan generation by 109% using Amazon Bedrock and Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_2/</link>
      <pubDate>Fri, 30 May 2025 17:18:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_2/</guid>
      <description>
        
          
            ZURU collaborated with AWS Generative AI Innovation Center and AWS Professional Services to implement a more accurate text-to-floor plan generator using generative AI. In this post, we show you why a solution using a large language model (LLM) was chosen. We explore how model selection, prompt engineering, and fine-tuning can be used to improve results.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-zuru-improved-the-accuracy-of-floor-plan-generation-by-109-using-amazon-bedrock-and-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Going beyond AI assistants: Examples from Amazon.com reinventing industries with generative AI</title>
      <link>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_3/</link>
      <pubDate>Fri, 30 May 2025 17:10:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_3/</guid>
      <description>
        
          
            Non-conversational applications offer unique advantages such as higher latency tolerance, batch processing, and caching, but their autonomous nature requires stronger guardrails and exhaustive quality assurance compared to conversational applications, which benefit from real-time user feedback and supervision. This post examines four diverse Amazon.com examples of such generative AI applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/going-beyond-ai-assistants-examples-from-amazon-com-reinventing-industries-with-generative-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Architect a mature generative AI foundation on AWS</title>
      <link>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_4/</link>
      <pubDate>Fri, 30 May 2025 17:02:37 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_4/</guid>
      <description>
        
          
            In this post, we give an overview of a well-established generative AI foundation, dive into its components, and present an end-to-end perspective. We look at different operating models and explore how such a foundation can operate within those boundaries. Lastly, we present a maturity model that helps enterprises assess their evolution path.
Link to article: https://aws.amazon.com/blogs/machine-learning/architect-a-mature-generative-ai-foundation-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Using Amazon OpenSearch ML connector APIs</title>
      <link>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_9/</link>
      <pubDate>Fri, 30 May 2025 15:57:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_9/</guid>
      <description>
        
          
            OpenSearch offers a wide range of third-party machine learning (ML) connectors to support this augmentation. This post highlights two of these third-party ML connectors. The first connector we demonstrate is the Amazon Comprehend connector. In this post, we show you how to use this connector to invoke the LangDetect API to detect the languages of ingested documents. The second connector we demonstrate is the Amazon Bedrock connector to invoke the Amazon Titan Text Embeddings v2 model so that you can create embeddings from ingested documents and perform semantic search.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Bridging the gap between development and production: Seamless model lifecycle management with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_10/</link>
      <pubDate>Fri, 30 May 2025 15:53:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_05_2025/30_05_2025_10/</guid>
      <description>
        
          
            Amazon Bedrock Model Copy and Model Share features provide a powerful option for managing the lifecycle of an AI application from development to production. In this comprehensive blog post, we&#39;ll dive deep into the Model Share and Model Copy features, exploring their functionalities, benefits, and practical applications in a typical development-to-production scenario.
Link to article: https://aws.amazon.com/blogs/machine-learning/bridging-the-gap-between-development-and-production-seamless-model-lifecycle-management-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Revolutionizing earth observation with geospatial foundation models on AWS</title>
      <link>https://www.dotnetramblings.com/post/29_05_2025/29_05_2025_0/</link>
      <pubDate>Thu, 29 May 2025 21:16:44 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_05_2025/29_05_2025_0/</guid>
      <description>
        
          
            In this post, we explore how a leading GeoFM (Clay Foundation’s Clay foundation model available on Hugging Face) can be deployed for large-scale inference and fine-tuning on Amazon SageMaker.
Link to article: https://aws.amazon.com/blogs/machine-learning/revolutionizing-earth-observation-with-geospatial-foundation-models-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Create an agentic RAG application for advanced knowledge discovery with LlamaIndex, and Mistral in Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/29_05_2025/29_05_2025_2/</link>
      <pubDate>Thu, 29 May 2025 20:10:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_05_2025/29_05_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate an example of building an agentic RAG application using the LlamaIndex framework. LlamaIndex is a framework that connects FMs with external data sources. It helps ingest, structure, and retrieve information from databases, APIs, PDFs, and more, enabling the agent and RAG for AI applications. This application serves as a research tool, using the Mistral Large 2 FM on Amazon Bedrock generate responses for the agent flow.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Text-to-image basics with Amazon Nova Canvas</title>
      <link>https://www.dotnetramblings.com/post/29_05_2025/29_05_2025_4/</link>
      <pubDate>Thu, 29 May 2025 19:29:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_05_2025/29_05_2025_4/</guid>
      <description>
        
          
            In this post, we focus on the Amazon Nova Canvas image generation model. We then provide an overview of the image generation process (diffusion) and dive deep into the input parameters for text-to-image generation with Amazon Nova Canvas.
Link to article: https://aws.amazon.com/blogs/machine-learning/text-to-image-basics-with-amazon-nova-canvas/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Real-world applications of Amazon Nova Canvas for interior design and product photography</title>
      <link>https://www.dotnetramblings.com/post/29_05_2025/29_05_2025_5/</link>
      <pubDate>Thu, 29 May 2025 19:26:14 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_05_2025/29_05_2025_5/</guid>
      <description>
        
          
            In this post, we explore how Amazon Nova Canvas can solve real-world business challenges through advanced image generation techniques. We focus on two specific use cases that demonstrate the power and flexibility of this technology: interior design and product photography.
Link to article: https://aws.amazon.com/blogs/machine-learning/real-world-applications-of-amazon-nova-canvas-for-interior-design-and-product-photography/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
