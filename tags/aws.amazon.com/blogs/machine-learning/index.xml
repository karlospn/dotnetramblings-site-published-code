<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Wed, 18 Dec 2024 15:22:16 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How Fastweb fine-tuned the Mistral model using Amazon SageMaker HyperPod as a first step to build an Italian large language model</title>
      <link>https://www.dotnetramblings.com/post/18_12_2024/18_12_2024_4/</link>
      <pubDate>Wed, 18 Dec 2024 15:22:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_12_2024/18_12_2024_4/</guid>
      <description>
        
          
            Fastweb, one of Italy’s leading telecommunications operators, recognized the immense potential of AI technologies early on and began investing in this area in 2019. In this post, we explore how Fastweb used cutting-edge AI and ML services to embark on their LLM journey, overcoming challenges and unlocking new opportunities along the way.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-fastweb-fine-tuned-the-mistral-model-using-amazon-sagemaker-hyperpod-as-a-first-step-to-build-an-italian-large-language-model/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Using natural language in Amazon Q Business: From searching and creating ServiceNow incidents and knowledge articles to generating insights</title>
      <link>https://www.dotnetramblings.com/post/18_12_2024/18_12_2024_5/</link>
      <pubDate>Wed, 18 Dec 2024 15:17:07 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_12_2024/18_12_2024_5/</guid>
      <description>
        
          
            In this post, we’ll demonstrate how to configure an Amazon Q Business application and add a custom plugin that gives users the ability to use a natural language interface provided by Amazon Q Business to query real-time data and take actions in ServiceNow.
Link to article: https://aws.amazon.com/blogs/machine-learning/using-natural-language-in-amazon-q-business-from-searching-and-creating-servicenow-incidents-and-knowledge-articles-to-generating-insights/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Simplify multimodal generative AI with Amazon Bedrock Data Automation</title>
      <link>https://www.dotnetramblings.com/post/17_12_2024/17_12_2024_1/</link>
      <pubDate>Tue, 17 Dec 2024 17:58:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_12_2024/17_12_2024_1/</guid>
      <description>
        
          
            Amazon Bedrock Data Automation in public preview, offers a unified experience for developers of all skillsets to easily automate the extraction, transformation, and generation of relevant insights from documents, images, audio, and videos to build generative AI–powered applications. In this post, we demonstrate how to use Amazon Bedrock Data Automation in the AWS Management Console and the AWS SDK for Python (Boto3) for media analysis and intelligent document processing (IDP) workflows.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How TUI uses Amazon Bedrock to scale content creation and enhance hotel descriptions in under 10 seconds</title>
      <link>https://www.dotnetramblings.com/post/17_12_2024/17_12_2024_2/</link>
      <pubDate>Tue, 17 Dec 2024 16:45:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_12_2024/17_12_2024_2/</guid>
      <description>
        
          
            TUI Group is one of the world’s leading global tourism services, providing 21 million customers with an unmatched holiday experience in 180 regions. The TUI content teams are tasked with producing high-quality content for its websites, including product details, hotel information, and travel guides, often using descriptions written by hotel and third-party partners. In this post, we discuss how we used Amazon SageMaker and Amazon Bedrock to build a content generator that rewrites marketing content following specific brand and style guidelines.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Llama 3.3 70B now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/17_12_2024/17_12_2024_11/</link>
      <pubDate>Tue, 17 Dec 2024 00:31:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_12_2024/17_12_2024_11/</guid>
      <description>
        
          
            Today, we are excited to announce that the Llama 3.3 70B from Meta is available in Amazon SageMaker JumpStart. Llama 3.3 70B marks an exciting advancement in large language model (LLM) development, offering comparable performance to larger Llama versions with fewer computational resources. In this post, we explore how to deploy this model efficiently on Amazon SageMaker AI, using advanced SageMaker AI features for optimal performance and cost management.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS re:Invent 2024 Highlights: Top takeaways from Swami Sivasubramanian to help customers manage generative AI at scale</title>
      <link>https://www.dotnetramblings.com/post/16_12_2024/16_12_2024_4/</link>
      <pubDate>Mon, 16 Dec 2024 17:19:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2024/16_12_2024_4/</guid>
      <description>
        
          
            We spoke with Dr. Swami Sivasubramanian, Vice President of Data and AI, shortly after AWS re:Invent 2024 to hear his impressions—and to get insights on how the latest AWS innovations help meet the real-world needs of customers as they build and scale transformative generative AI applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/aws-reinvent-2024-highlights-top-takeaways-from-swami-sivasubramanian-to-help-customers-manage-generative-ai-at-scale/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Multi-tenant RAG with Amazon Bedrock Knowledge Bases</title>
      <link>https://www.dotnetramblings.com/post/16_12_2024/16_12_2024_6/</link>
      <pubDate>Mon, 16 Dec 2024 14:45:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2024/16_12_2024_6/</guid>
      <description>
        
          
            Organizations are continuously seeking ways to use their proprietary knowledge and domain expertise to gain a competitive edge. With the advent of foundation models (FMs) and their remarkable natural language processing capabilities, a new opportunity has emerged to unlock the value of their data assets. As organizations strive to deliver personalized experiences to customers using […]
Link to article: https://aws.amazon.com/blogs/machine-learning/multi-tenant-rag-with-amazon-bedrock-knowledge-bases/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Amazon trains sequential ensemble models at scale with Amazon SageMaker Pipelines</title>
      <link>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_0/</link>
      <pubDate>Fri, 13 Dec 2024 20:31:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_0/</guid>
      <description>
        
          
            Ensemble models are becoming popular within the ML communities. They generate more accurate predictions through combining the predictions of multiple models. Pipelines can quickly be used to create and end-to-end ML pipeline for ensemble models. This enables developers to build highly accurate models while maintaining efficiency, and reproducibility. In this post, we provide an example of an ensemble model that was trained and deployed using Pipelines.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-amazon-trains-sequential-ensemble-models-at-scale-with-amazon-sagemaker-pipelines/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implementing login node load balancing in SageMaker HyperPod for enhanced multi-user experience</title>
      <link>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_1/</link>
      <pubDate>Fri, 13 Dec 2024 20:27:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_1/</guid>
      <description>
        
          
            In this post, we explore a solution for implementing load balancing across login nodes in Slurm-based HyperPod clusters. By distributing user activity evenly across all available nodes, this approach provides more consistent performance, better resource utilization, and a smoother experience for all users. We guide you through the setup process, providing practical steps to achieve effective load balancing in your HyperPod clusters.
Link to article: https://aws.amazon.com/blogs/machine-learning/implementing-login-node-load-balancing-in-sagemaker-hyperpod-for-enhanced-multi-user-experience/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Clearwater Analytics is revolutionizing investment management with generative AI and Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_2/</link>
      <pubDate>Fri, 13 Dec 2024 20:22:17 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_2/</guid>
      <description>
        
          
            In this post, we explore Clearwater Analytics’ foray into generative AI, how they’ve architected their solution with Amazon SageMaker, and dive deep into how Clearwater Analytics is using LLMs to take advantage of more than 18 years of experience within the investment management domain while optimizing model cost and performance.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-clearwater-analytics-is-revolutionizing-investment-management-with-generative-ai-and-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Twitch used agentic workflow with RAG on Amazon Bedrock to supercharge ad sales</title>
      <link>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_3/</link>
      <pubDate>Fri, 13 Dec 2024 20:20:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_3/</guid>
      <description>
        
          
            In this post, we demonstrate how we innovated to build a Retrieval Augmented Generation (RAG) application with agentic workflow and a knowledge base on Amazon Bedrock. We implemented the RAG pipeline in a Slack chat-based assistant to empower the Amazon Twitch ads sales team to move quickly on new sales opportunities.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-twitch-used-agentic-workflow-with-rag-on-amazon-bedrock-to-supercharge-ad-sales/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate analysis and discovery of cancer biomarkers with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_4/</link>
      <pubDate>Fri, 13 Dec 2024 19:17:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_12_2024/13_12_2024_4/</guid>
      <description>
        
          
            Bedrock multi-agent collaboration enables developers to build, deploy, and manage multiple specialized agents working together seamlessly to address increasingly complex business workflows. In this post, we show you how agentic workflows with Amazon Bedrock Agents can help accelerate this journey for research scientists with a natural language interface. We define an example analysis pipeline, specifically for lung cancer survival with clinical, genomics, and imaging modalities of biomarkers. We showcase a variety of specialized agents including a biomarker database analyst, statistician, clinical evidence researcher, and medical imaging expert in collaboration with a supervisor agent.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate your ML lifecycle using the new and improved Amazon SageMaker Python SDK – Part 2: ModelBuilder</title>
      <link>https://www.dotnetramblings.com/post/12_12_2024/12_12_2024_2/</link>
      <pubDate>Thu, 12 Dec 2024 17:18:34 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_12_2024/12_12_2024_2/</guid>
      <description>
        
          
            In Part 1 of this series, we introduced the newly launched ModelTrainer class on the Amazon SageMaker Python SDK and its benefits, and showed you how to fine-tune a Meta Llama 3.1 8B model on a custom dataset. In this post, we look at the enhancements to the ModelBuilder class, which lets you seamlessly deploy a model from ModelTrainer to a SageMaker endpoint, and provides a single interface for multiple deployment configurations.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate your ML lifecycle using the new and improved Amazon SageMaker Python SDK – Part 1: ModelTrainer</title>
      <link>https://www.dotnetramblings.com/post/12_12_2024/12_12_2024_3/</link>
      <pubDate>Thu, 12 Dec 2024 17:18:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_12_2024/12_12_2024_3/</guid>
      <description>
        
          
            In this post, we focus on the ModelTrainer class for simplifying the training experience. The ModelTrainer class provides significant improvements over the current Estimator class, which are discussed in detail in this post. We show you how to use the ModelTrainer class to train your ML models, which includes executing distributed training using a custom script or container. In Part 2, we show you how to build a model and deploy to a SageMaker endpoint using the improved ModelBuilder class.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Q Apps supports customization and governance of generative AI-powered apps</title>
      <link>https://www.dotnetramblings.com/post/12_12_2024/12_12_2024_4/</link>
      <pubDate>Thu, 12 Dec 2024 17:13:05 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_12_2024/12_12_2024_4/</guid>
      <description>
        
          
            In this post, we examine how these features enhance the capabilities of Amazon Q Apps. We explore the new customization options, detailing how these advancements make Amazon Q Apps more accessible and applicable to a wider range of enterprise customers. We focus on key features such as custom labels, verified apps, private sharing, and data collection apps (preview).
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-q-apps-supports-customization-and-governance-of-generative-ai-powered-apps/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Answer questions from tables embedded in documents with Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/12_12_2024/12_12_2024_5/</link>
      <pubDate>Thu, 12 Dec 2024 17:08:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_12_2024/12_12_2024_5/</guid>
      <description>
        
          
            Amazon Q Business launched support for tabular search, which you can use to extract answers from tables embedded in documents ingested in Amazon Q Business. Tabular search is a built-in feature in Amazon Q Business that works seamlessly across many domains, with no setup required from admin or end users. In this post, we ingest different types of documents that have tables and show you how Amazon Q Business responds to questions related to the data in the tables.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How AWS sales uses Amazon Q Business for customer engagement</title>
      <link>https://www.dotnetramblings.com/post/11_12_2024/11_12_2024_2/</link>
      <pubDate>Wed, 11 Dec 2024 17:33:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_12_2024/11_12_2024_2/</guid>
      <description>
        
          
            In April 2024, we launched our AI sales assistant, which we call Field Advisor, making it available to AWS employees in the Sales, Marketing, and Global Services organization, powered by Amazon Q Business. Since that time, thousands of active users have asked hundreds of thousands of questions through Field Advisor, which we have embedded in our customer relationship management (CRM) system, as well as through a Slack application.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Discover insights from your Amazon Aurora PostgreSQL database using the Amazon Q Business connector</title>
      <link>https://www.dotnetramblings.com/post/11_12_2024/11_12_2024_3/</link>
      <pubDate>Wed, 11 Dec 2024 17:20:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_12_2024/11_12_2024_3/</guid>
      <description>
        
          
            In this post, we walk you through configuring and integrating Amazon Q for Business with Aurora PostgreSQL-Compatible to enable your database administrators, data analysts, application developers, leadership, and other teams to quickly get accurate answers to their questions related to the content stored in Aurora PostgreSQL databases.
Link to article: https://aws.amazon.com/blogs/machine-learning/discover-insights-from-your-amazon-aurora-postgresql-database-using-the-amazon-q-business-connector/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Tealium built a chatbot evaluation platform with Ragas and Auto-Instruct using AWS generative AI services</title>
      <link>https://www.dotnetramblings.com/post/11_12_2024/11_12_2024_4/</link>
      <pubDate>Wed, 11 Dec 2024 17:10:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_12_2024/11_12_2024_4/</guid>
      <description>
        
          
            In this post, we illustrate the importance of generative AI in the collaboration between Tealium and the AWS Generative AI Innovation Center (GenAIIC) team by automating the following: 1/ Evaluating the retriever and the generated answer of a RAG system based on the Ragas Repository powered by Amazon Bedrock, 2/ Generating improved instructions for each question-and-answer pair using an automatic prompt engineering technique based on the Auto-Instruct Repository. An instruction refers to a general direction or command given to the model to guide generation of a response.
          
          
        
      </description>
    </item>
    
    <item>
      <title>EBSCOlearning scales assessment generation for their online learning content with generative AI</title>
      <link>https://www.dotnetramblings.com/post/11_12_2024/11_12_2024_7/</link>
      <pubDate>Wed, 11 Dec 2024 16:50:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_12_2024/11_12_2024_7/</guid>
      <description>
        
          
            In this post, we illustrate how EBSCOlearning partnered with AWS Generative AI Innovation Center (GenAIIC) to use the power of generative AI in revolutionizing their learning assessment process. We explore the challenges faced in traditional question-answer (QA) generation and the innovative AI-driven solution developed to address them.
Link to article: https://aws.amazon.com/blogs/machine-learning/ebscolearning-scales-assessment-generation-for-their-online-learning-content-with-generative-ai/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
