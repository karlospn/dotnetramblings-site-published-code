<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 13 Mar 2025 16:43:53 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How GoDaddy built a category generation system at scale with batch inference for Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_6/</link>
      <pubDate>Thu, 13 Mar 2025 16:43:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_6/</guid>
      <description>
        
          
            This post provides an overview of a custom solution developed by the for GoDaddy, a domain registrar, registry, web hosting, and ecommerce company that seeks to make entrepreneurship more accessible by using generative AI to provide personalized business insights to over 21 million customers. In this collaboration, the Generative AI Innovation Center team created an accurate and cost-efficient generative AI–based solution using batch inference in Amazon Bedrock, helping GoDaddy improve their existing product categorization system.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Benchmarking customized models on Amazon Bedrock using LLMPerf and LiteLLM</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_8/</link>
      <pubDate>Thu, 13 Mar 2025 14:09:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_8/</guid>
      <description>
        
          
            This post begins a blog series exploring DeepSeek and open FMs on Amazon Bedrock Custom Model Import. It covers the process of performance benchmarking of custom models in Amazon Bedrock using popular open source tools: LLMPerf and LiteLLM. It includes a notebook that includes step-by-step instructions to deploy a DeepSeek-R1-Distill-Llama-8B model, but the same steps apply for any other model supported by Amazon Bedrock Custom Model Import.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Creating asynchronous AI agents with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_9/</link>
      <pubDate>Thu, 13 Mar 2025 14:06:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_9/</guid>
      <description>
        
          
            The integration of generative AI agents into business processes is poised to accelerate as organizations recognize the untapped potential of these technologies. Advancements in multimodal artificial intelligence (AI), where agents can understand and generate not just text but also images, audio, and video, will further broaden their applications. This post will discuss agentic AI driven architecture and ways of implementing.
Link to article: https://aws.amazon.com/blogs/machine-learning/creating-asynchronous-ai-agents-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How to run Qwen 2.5 on AWS AI chips using Hugging Face libraries</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_10/</link>
      <pubDate>Thu, 13 Mar 2025 14:03:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_10/</guid>
      <description>
        
          
            In this post, we outline how to get started with deploying the Qwen 2.5 family of models on an Inferentia instance using Amazon Elastic Compute Cloud (Amazon EC2) and Amazon SageMaker using the Hugging Face Text Generation Inference (TGI) container and the Hugging Face Optimum Neuron library. Qwen2.5 Coder and Math variants are also supported.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-to-run-qwen-2-5-on-aws-ai-chips-using-hugging-face-libraries/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Revolutionizing customer service: MaestroQA’s integration with Amazon Bedrock for actionable insight</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_11/</link>
      <pubDate>Thu, 13 Mar 2025 14:01:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_11/</guid>
      <description>
        
          
            In this post, we dive deeper into one of MaestroQA’s key features—conversation analytics, which helps support teams uncover customer concerns, address points of friction, adapt support workflows, and identify areas for coaching through the use of Amazon Bedrock. We discuss the unique challenges MaestroQA overcame and how they use AWS to build new features, drive customer insights, and improve operational inefficiencies.
Link to article: https://aws.amazon.com/blogs/machine-learning/revolutionizing-customer-service-maestroqas-integration-with-amazon-bedrock-for-actionable-insight/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimize hosting DeepSeek-R1 distilled models with Hugging Face TGI on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_12/</link>
      <pubDate>Thu, 13 Mar 2025 13:57:58 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_12/</guid>
      <description>
        
          
            In this post, we demonstrate how to optimize hosting DeepSeek-R1 distilled models with Hugging Face Text Generation Inference (TGI) on Amazon SageMaker AI.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimize-hosting-deepseek-r1-distilled-models-with-hugging-face-tgi-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Exploring creative possibilities: A visual guide to Amazon Nova Canvas</title>
      <link>https://www.dotnetramblings.com/post/12_03_2025/12_03_2025_3/</link>
      <pubDate>Wed, 12 Mar 2025 18:10:17 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_03_2025/12_03_2025_3/</guid>
      <description>
        
          
            In this blog post, we showcase a curated gallery of visuals generated by Nova Canvas—categorized by real-world use cases—from marketing and product visualization to concept art and design exploration. Each image is paired with the prompt and parameters that generated it, providing a practical starting point for your own AI-driven creativity. Whether you&#39;re crafting specific types of images, optimizing workflows, or simply seeking inspiration, this guide will help you unlock the full potential of Amazon Nova Canvas.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Transforming financial analysis with CreditAI on Amazon Bedrock: Octus’s journey with AWS</title>
      <link>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_0/</link>
      <pubDate>Mon, 10 Mar 2025 20:59:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_0/</guid>
      <description>
        
          
            In this post, we demonstrate how Octus migrated its flagship product, CreditAI, to Amazon Bedrock, transforming how investment professionals access and analyze credit intelligence. We walk through the journey Octus took from managing multiple cloud providers and costly GPU instances to implementing a streamlined, cost-effective solution using AWS services including Amazon Bedrock, AWS Fargate, and Amazon OpenSearch Service.
Link to article: https://aws.amazon.com/blogs/machine-learning/transforming-financial-analysis-with-creditai-on-amazon-bedrock-octuss-journey-with-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimize reasoning models like DeepSeek with prompt optimization on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_1/</link>
      <pubDate>Mon, 10 Mar 2025 20:53:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to optimize reasoning models like DeepSeek-R1 using prompt optimization on Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimize-reasoning-models-like-deepseek-with-prompt-optimization-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock announces general availability of multi-agent collaboration</title>
      <link>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_3/</link>
      <pubDate>Mon, 10 Mar 2025 16:08:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_03_2025/10_03_2025_3/</guid>
      <description>
        
          
            Today, we’re announcing the general availability (GA) of multi-agent collaboration on Amazon Bedrock. This capability allows developers to build, deploy, and manage networks of AI agents that work together to execute complex, multi-step workflows efficiently.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-announces-general-availability-of-multi-agent-collaboration/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerating insurance policy reviews with generative AI: Verisk’s Mozart companion</title>
      <link>https://www.dotnetramblings.com/post/07_03_2025/07_03_2025_1/</link>
      <pubDate>Fri, 07 Mar 2025 20:52:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_03_2025/07_03_2025_1/</guid>
      <description>
        
          
            This post is co-authored with Sundeep Sardana, Malolan Raman, Joseph Lam, Maitri Shah and Vaibhav Singh from Verisk. Verisk (Nasdaq: VRSK) is a leading strategic data analytics and technology partner to the global insurance industry, empowering clients to strengthen operating efficiency, improve underwriting and claims outcomes, combat fraud, and make informed decisions about global risks. […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerating-insurance-policy-reviews-with-generative-ai-verisks-mozart-companion/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Announcing general availability of Amazon Bedrock Knowledge Bases GraphRAG with Amazon Neptune Analytics</title>
      <link>https://www.dotnetramblings.com/post/07_03_2025/07_03_2025_3/</link>
      <pubDate>Fri, 07 Mar 2025 18:23:14 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_03_2025/07_03_2025_3/</guid>
      <description>
        
          
            Today, Amazon Web Services (AWS) announced the general availability of Amazon Bedrock Knowledge Bases GraphRAG (GraphRAG), a capability in Amazon Bedrock Knowledge Bases that enhances Retrieval-Augmented Generation (RAG) with graph data in Amazon Neptune Analytics. In this post, we discuss the benefits of GraphRAG and how to get started with it in Amazon Bedrock Knowledge Bases.
Link to article: https://aws.amazon.com/blogs/machine-learning/announcing-general-availability-of-amazon-bedrock-knowledge-bases-graphrag-with-amazon-neptune-analytics/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a Multi-Agent System with LangGraph and Mistral on AWS</title>
      <link>https://www.dotnetramblings.com/post/06_03_2025/06_03_2025_4/</link>
      <pubDate>Thu, 06 Mar 2025 17:02:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_03_2025/06_03_2025_4/</guid>
      <description>
        
          
            In this post, we explore how to use LangGraph and Mistral models on Amazon Bedrock to create a powerful multi-agent system that can handle sophisticated workflows through collaborative problem-solving. This integration enables the creation of AI agents that can work together to solve complex problems, mimicking humanlike reasoning and collaboration.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-multi-agent-system-with-langgraph-and-mistral-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluate RAG responses with Amazon Bedrock, LlamaIndex and RAGAS</title>
      <link>https://www.dotnetramblings.com/post/06_03_2025/06_03_2025_6/</link>
      <pubDate>Thu, 06 Mar 2025 16:52:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_03_2025/06_03_2025_6/</guid>
      <description>
        
          
            In this post, we’ll explore how to leverage Amazon Bedrock, LlamaIndex, and RAGAS to enhance your RAG implementations. You’ll learn practical techniques to evaluate and optimize your AI systems, enabling more accurate, context-aware responses that align with your organization’s specific needs.
Link to article: https://aws.amazon.com/blogs/machine-learning/evaluate-rag-responses-with-amazon-bedrock-llamaindex-and-ragas/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
