<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 30 Oct 2025 21:55:03 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Reduce CAPTCHAs for AI agents browsing the web with Web Bot Auth (Preview) in Amazon Bedrock AgentCore Browser</title>
      <link>https://www.dotnetramblings.com/post/30_10_2025/30_10_2025_0/</link>
      <pubDate>Thu, 30 Oct 2025 21:55:03 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_10_2025/30_10_2025_0/</guid>
      <description>
        
          
            AI agents need to browse the web on your behalf. When your agent visits a website to gather information, complete a form, or verify data, it encounters the same defenses designed to stop unwanted bots: CAPTCHAs, rate limits, and outright blocks. Today, we are excited to share that AWS has a solution. Amazon Bedrock AgentCore […]
Link to article: https://aws.amazon.com/blogs/machine-learning/reduce-captchas-for-ai-agents-browsing-the-web-with-web-bot-auth-preview-in-amazon-bedrock-agentcore-browser/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Hosting NVIDIA speech NIM models on Amazon SageMaker AI: Parakeet ASR</title>
      <link>https://www.dotnetramblings.com/post/28_10_2025/28_10_2025_3/</link>
      <pubDate>Tue, 28 Oct 2025 18:09:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_10_2025/28_10_2025_3/</guid>
      <description>
        
          
            In this post, we explore how to deploy NVIDIA&#39;s Parakeet ASR model on Amazon SageMaker AI using asynchronous inference endpoints to create a scalable, cost-effective pipeline for processing large volumes of audio data. The solution combines state-of-the-art speech recognition capabilities with AWS managed services like Lambda, S3, and Bedrock to automatically transcribe audio files and generate intelligent summaries, enabling organizations to unlock valuable insights from customer calls, meeting recordings, and other audio content at scale .
          
          
        
      </description>
    </item>
    
    <item>
      <title>Responsible AI design in healthcare and life sciences</title>
      <link>https://www.dotnetramblings.com/post/24_10_2025/24_10_2025_3/</link>
      <pubDate>Fri, 24 Oct 2025 17:25:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_10_2025/24_10_2025_3/</guid>
      <description>
        
          
            In this post, we explore the critical design considerations for building responsible AI systems in healthcare and life sciences, focusing on establishing governance mechanisms, transparency artifacts, and security measures that ensure safe and effective generative AI applications. The discussion covers essential policies for mitigating risks like confabulation and bias while promoting trust, accountability, and patient safety throughout the AI development lifecycle.
Link to article: https://aws.amazon.com/blogs/machine-learning/responsible-ai-design-in-healthcare-and-life-sciences/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Beyond pilots: A proven framework for scaling AI to production</title>
      <link>https://www.dotnetramblings.com/post/24_10_2025/24_10_2025_4/</link>
      <pubDate>Fri, 24 Oct 2025 14:42:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_10_2025/24_10_2025_4/</guid>
      <description>
        
          
            In this post, we explore the Five V&#39;s Framework—a field-tested methodology that has helped 65% of AWS Generative AI Innovation Center customer projects successfully transition from concept to production, with some launching in just 45 days. The framework provides a structured approach through Value, Visualize, Validate, Verify, and Venture phases, shifting focus from &amp;quot;What can AI do?&amp;quot; to &amp;quot;What do we need AI to do?&amp;quot; while ensuring solutions deliver measurable business outcomes and sustainable operational excellence.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Generate Gremlin queries using Amazon Bedrock models</title>
      <link>https://www.dotnetramblings.com/post/23_10_2025/23_10_2025_1/</link>
      <pubDate>Thu, 23 Oct 2025 20:57:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_10_2025/23_10_2025_1/</guid>
      <description>
        
          
            In this post, we explore an innovative approach that converts natural language to Gremlin queries using Amazon Bedrock models such as Amazon Nova Pro, helping business analysts and data scientists access graph databases without requiring deep technical expertise. The methodology involves three key steps: extracting graph knowledge, structuring the graph similar to text-to-SQL processing, and generating executable Gremlin queries through an iterative refinement process that achieved 74.17% overall accuracy in testing.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Incorporating responsible AI into generative AI project prioritization</title>
      <link>https://www.dotnetramblings.com/post/23_10_2025/23_10_2025_2/</link>
      <pubDate>Thu, 23 Oct 2025 20:51:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_10_2025/23_10_2025_2/</guid>
      <description>
        
          
            In this post, we explore how companies can systematically incorporate responsible AI practices into their generative AI project prioritization methodology to better evaluate business value against costs while addressing novel risks like hallucination and regulatory compliance. The post demonstrates through a practical example how conducting upfront responsible AI risk assessments can significantly change project rankings by revealing substantial mitigation work that affects overall project complexity and timeline.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
