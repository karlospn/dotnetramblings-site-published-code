<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 08 Apr 2025 17:37:35 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How iFood built a platform to run hundreds of machine learning models with Amazon SageMaker Inference</title>
      <link>https://www.dotnetramblings.com/post/08_04_2025/08_04_2025_1/</link>
      <pubDate>Tue, 08 Apr 2025 17:37:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_04_2025/08_04_2025_1/</guid>
      <description>
        
          
            In this post, we show how iFood uses SageMaker to revolutionize its ML operations. By harnessing the power of SageMaker, iFood streamlines the entire ML lifecycle, from model training to deployment. This integration not only simplifies complex processes but also automates critical tasks.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-ifood-built-a-platform-to-run-hundreds-of-machine-learning-models-with-amazon-sagemaker-inference/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an enterprise synthetic data strategy using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/08_04_2025/08_04_2025_2/</link>
      <pubDate>Tue, 08 Apr 2025 16:40:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_04_2025/08_04_2025_2/</guid>
      <description>
        
          
            In this post, we explore how to use Amazon Bedrock for synthetic data generation, considering these challenges alongside the potential benefits to develop effective strategies for various applications across multiple industries, including AI and machine learning (ML).
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-enterprise-synthetic-data-strategy-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Llama 4 family of models from Meta are now available in SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_0/</link>
      <pubDate>Mon, 07 Apr 2025 22:54:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_0/</guid>
      <description>
        
          
            Today, we’re excited to announce the availability of Llama 4 Scout and Maverick models in Amazon SageMaker JumpStart. In this blog post, we walk you through how to deploy and prompt a Llama-4-Scout-17B-16E-Instruct model using SageMaker JumpStart.
Link to article: https://aws.amazon.com/blogs/machine-learning/llama-4-family-of-models-from-meta-are-now-available-in-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Multi-tenancy in RAG applications in a single Amazon Bedrock knowledge base with metadata filtering</title>
      <link>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_1/</link>
      <pubDate>Mon, 07 Apr 2025 21:56:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_1/</guid>
      <description>
        
          
            This post demonstrates how Amazon Bedrock Knowledge Bases can help you scale your data management effectively while maintaining proper access controls on different management levels.
Link to article: https://aws.amazon.com/blogs/machine-learning/multi-tenancy-in-rag-applications-in-a-single-amazon-bedrock-knowledge-base-with-metadata-filtering/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Effectively use prompt caching on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_2/</link>
      <pubDate>Mon, 07 Apr 2025 21:53:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_2/</guid>
      <description>
        
          
            Prompt caching, now generally available on Amazon Bedrock with Anthropic’s Claude 3.5 Haiku and Claude 3.7 Sonnet, along with Nova Micro, Nova Lite, and Nova Pro models, lowers response latency by up to 85% and reduces costs up to 90% by caching frequently used prompts across multiple API calls. This post provides a detailed overview of the prompt caching feature on Amazon Bedrock and offers guidance on how to effectively use this feature to achieve improved latency and cost savings.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Advanced tracing and evaluation of generative AI agents using LangChain and Amazon SageMaker AI MLFlow</title>
      <link>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_4/</link>
      <pubDate>Mon, 07 Apr 2025 17:45:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_4/</guid>
      <description>
        
          
            In this post, I show you how to combine LangChain&#39;s LangGraph, Amazon SageMaker AI, and MLflow to demonstrate a powerful workflow for developing, evaluating, and deploying sophisticated generative AI agents. This integration provides the tools needed to gain deep insights into the generative AI agent&#39;s performance, iterate quickly, and maintain version control throughout the development process.
Link to article: https://aws.amazon.com/blogs/machine-learning/advanced-tracing-and-evaluation-of-generative-ai-agents-using-langchain-and-amazon-sagemaker-ai-mlflow/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prompting for the best price-performance</title>
      <link>https://www.dotnetramblings.com/post/04_04_2025/04_04_2025_1/</link>
      <pubDate>Fri, 04 Apr 2025 20:03:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_04_2025/04_04_2025_1/</guid>
      <description>
        
          
            In this blog, we discuss how to optimize prompting in Amazon Nova for the best price-performance.
Link to article: https://aws.amazon.com/blogs/machine-learning/prompting-for-the-best-price-performance/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluate models or RAG systems using Amazon Bedrock Evaluations – Now generally available</title>
      <link>https://www.dotnetramblings.com/post/04_04_2025/04_04_2025_5/</link>
      <pubDate>Fri, 04 Apr 2025 15:23:02 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_04_2025/04_04_2025_5/</guid>
      <description>
        
          
            Today, we’re excited to announce the general availability of these evaluation features in Amazon Bedrock Evaluations, along with significant enhancements that make them fully environment-agnostic. In this post, we explore these new features in detail, showing you how to evaluate both RAG systems and models with practical examples. We demonstrate how to use the comparison capabilities to benchmark different implementations and make data-driven decisions about your AI deployments.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine-tune large language models with reinforcement learning from human or AI feedback</title>
      <link>https://www.dotnetramblings.com/post/04_04_2025/04_04_2025_6/</link>
      <pubDate>Fri, 04 Apr 2025 14:42:45 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_04_2025/04_04_2025_6/</guid>
      <description>
        
          
            In this post, we introduce a state-of-the-art method to fine-tune LLMs by reinforcement learning, reviewed the pros and cons of RLHF vs. RLAIF vs. DPO, and saw how to scale LLM fine-tuning efforts with RLAIF. We also see how to implement an end-to-end RLAIF pipeline on SageMaker using the Hugging Face Transformer and TRL libraries, and using either off-the-shelf toxicity reward models to align responses during PPO or by directly prompting an LLM to generate quantitative reward feedback during PPO.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Lumi streamlines loan approvals with Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/04_04_2025/04_04_2025_7/</link>
      <pubDate>Fri, 04 Apr 2025 14:39:37 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_04_2025/04_04_2025_7/</guid>
      <description>
        
          
            Lumi is a leading Australian fintech lender empowering small businesses with fast, flexible, and transparent funding solutions. They use real-time data and machine learning (ML) to offer customized loans that fuel sustainable growth and solve the challenges of accessing capital. This post explores how Lumi uses Amazon SageMaker AI to meet this goal, enhance their transaction processing and classification capabilities, and ultimately grow their business by providing faster processing of loan applications, more accurate credit decisions, and improved customer experience.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How AWS Sales uses generative AI to streamline account planning</title>
      <link>https://www.dotnetramblings.com/post/03_04_2025/03_04_2025_8/</link>
      <pubDate>Thu, 03 Apr 2025 15:41:34 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_04_2025/03_04_2025_8/</guid>
      <description>
        
          
            Every year, AWS Sales personnel draft in-depth, forward looking strategy documents for established AWS customers. These documents help the AWS Sales team to align with our customer growth strategy and to collaborate with the entire sales team on long-term growth ideas for AWS customers. In this post, we showcase how the AWS Sales product team built the generative AI account plans draft assistant.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-aws-sales-uses-generative-ai-to-streamline-account-planning/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Shaping the future: OMRON’s data-driven journey with AWS</title>
      <link>https://www.dotnetramblings.com/post/03_04_2025/03_04_2025_9/</link>
      <pubDate>Thu, 03 Apr 2025 15:38:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_04_2025/03_04_2025_9/</guid>
      <description>
        
          
            OMRON Corporation is a leading technology provider in industrial automation, healthcare, and electronic components. In their Shaping the Future 2030 (SF2030) strategic plan, OMRON aims to address diverse social issues, drive sustainable business growth, transform business models and capabilities, and accelerate digital transformation. At the heart of this transformation is the OMRON Data &amp;amp; Analytics Platform (ODAP), an innovative initiative designed to revolutionize how the company harnesses its data assets. This post explores how OMRON Europe is using Amazon Web Services (AWS) to build its advanced ODAP and its progress toward harnessing the power of generative AI.
          
          
        
      </description>
    </item>
    
    <item>
      <title>AI Workforce: using AI and Drones to simplify infrastructure inspections</title>
      <link>https://www.dotnetramblings.com/post/03_04_2025/03_04_2025_10/</link>
      <pubDate>Thu, 03 Apr 2025 15:20:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_04_2025/03_04_2025_10/</guid>
      <description>
        
          
            Inspecting wind turbines, power lines, 5G towers, and pipelines is a tough job. It’s often dangerous, time-consuming, and prone to human error. This post is the first in a three-part series exploring AI Workforce, the AWS AI-powered drone inspection system. In this post, we introduce the concept and key benefits. The second post dives into the AWS architecture that powers AI Workforce, and the third focuses on the drone setup and integration.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Ray jobs on Amazon SageMaker HyperPod: scalable and resilient distributed AI</title>
      <link>https://www.dotnetramblings.com/post/02_04_2025/02_04_2025_2/</link>
      <pubDate>Wed, 02 Apr 2025 19:18:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_04_2025/02_04_2025_2/</guid>
      <description>
        
          
            Ray is an open source framework that makes it straightforward to create, deploy, and optimize distributed Python jobs. In this post, we demonstrate the steps involved in running Ray jobs on SageMaker HyperPod.
Link to article: https://aws.amazon.com/blogs/machine-learning/ray-jobs-on-amazon-sagemaker-hyperpod-scalable-and-resilient-distributed-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Using Large Language Models on Amazon Bedrock for multi-step task execution</title>
      <link>https://www.dotnetramblings.com/post/02_04_2025/02_04_2025_3/</link>
      <pubDate>Wed, 02 Apr 2025 19:12:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_04_2025/02_04_2025_3/</guid>
      <description>
        
          
            This post explores the application of LLMs in executing complex analytical queries through an API, with specific focus on Amazon Bedrock. To demonstrate this process, we present a use case where the system identifies the patient with the least number of vaccines by retrieving, grouping, and sorting data, and ultimately presenting the final result.
Link to article: https://aws.amazon.com/blogs/machine-learning/using-large-language-models-on-amazon-bedrock-for-multi-step-task-execution/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Introducing AWS MCP Servers for code assistants (Part 1)</title>
      <link>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_0/</link>
      <pubDate>Tue, 01 Apr 2025 20:22:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_0/</guid>
      <description>
        
          
            We’re excited to announce the open source release of AWS MCP Servers for code assistants — a suite of specialized Model Context Protocol (MCP) servers that bring Amazon Web Services (AWS) best practices directly to your development workflow. This post is the first in a series covering AWS MCP Servers. In this post, we walk through how these specialized MCP servers can dramatically reduce your development time while incorporating security controls, cost optimizations, and AWS Well-Architected best practices into your code.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Harness the power of MCP servers with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_1/</link>
      <pubDate>Tue, 01 Apr 2025 19:58:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_1/</guid>
      <description>
        
          
            Today, MCP is providing agents standard access to an expanding list of accessible tools that you can use to accomplish a variety of tasks. In this post, we show you how to build an Amazon Bedrock agent that uses MCP to access data sources to quickly build generative AI applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/harness-the-power-of-mcp-servers-with-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Generate compliant content with Amazon Bedrock and ConstitutionalChain</title>
      <link>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_7/</link>
      <pubDate>Tue, 01 Apr 2025 16:12:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_7/</guid>
      <description>
        
          
            In this post, we explore practical strategies for using Constitutional AI to produce compliant content efficiently and effectively using Amazon Bedrock and LangGraph to build ConstitutionalChain for rapid content creation in highly regulated industries like finance and healthcare
Link to article: https://aws.amazon.com/blogs/machine-learning/generate-compliant-content-with-amazon-bedrock-and-constitutionalchain/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Minimize generative AI hallucinations with Amazon Bedrock Automated Reasoning checks</title>
      <link>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_9/</link>
      <pubDate>Tue, 01 Apr 2025 15:59:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_9/</guid>
      <description>
        
          
            To improve factual accuracy of large language model (LLM) responses, AWS announced Amazon Bedrock Automated Reasoning checks (in gated preview) at AWS re:Invent 2024. In this post, we discuss how to help prevent generative AI hallucinations using Amazon Bedrock Automated Reasoning checks.
Link to article: https://aws.amazon.com/blogs/machine-learning/minimize-generative-ai-hallucinations-with-amazon-bedrock-automated-reasoning-checks/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS App Studio introduces a prebuilt solutions catalog and cross-instance Import and Export</title>
      <link>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_11/</link>
      <pubDate>Tue, 01 Apr 2025 14:02:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_04_2025/01_04_2025_11/</guid>
      <description>
        
          
            In a recent AWS What’s New Post, App Studio announced two new features to accelerate application building: Prebuilt solutions catalog and cross-instance Import and Export. In this post, we walk through how to use the prebuilt solutions catalog to get started quickly and use the Import and Export feature
Link to article: https://aws.amazon.com/blogs/machine-learning/aws-app-studio-introduces-a-prebuilt-solutions-catalog-and-cross-instance-import-and-export/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
