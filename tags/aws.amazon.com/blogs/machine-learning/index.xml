<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Mon, 28 Jul 2025 17:54:35 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Amazon Nova Act SDK (preview): Path to production for browser automation agents</title>
      <link>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_0/</link>
      <pubDate>Mon, 28 Jul 2025 17:54:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_0/</guid>
      <description>
        
          
            In this post, we’ll walk through what makes Nova Act SDK unique, how it works, and how teams across industries are already using it to automate browser-based workflows at scale.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-nova-act-sdk-preview-path-to-production-for-browser-automation-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimizing enterprise AI assistants: How Crypto.com uses LLM reasoning and feedback for enhanced efficiency</title>
      <link>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_1/</link>
      <pubDate>Mon, 28 Jul 2025 17:53:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_1/</guid>
      <description>
        
          
            In this post, we explore how Crypto.com used user and system feedback to continuously improve and optimize our instruction prompts. This feedback-driven approach has enabled us to create more effective prompts that adapt to various subsystems while maintaining high performance across different use cases.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimizing-enterprise-ai-assistants-how-crypto-com-uses-llm-reasoning-and-feedback-for-enhanced-efficiency/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build modern serverless solutions following best practices using Amazon Q Developer CLI and MCP</title>
      <link>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_2/</link>
      <pubDate>Mon, 28 Jul 2025 17:42:38 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_2/</guid>
      <description>
        
          
            This post explores how the AWS Serverless MCP server accelerates development throughout the serverless lifecycle, from making architectural decisions with tools like get_iac_guidance and get_lambda_guidance, to streamlining development with get_serverless_templates, sam_init, to deployment with SAM integration, webapp_deployment_help, and configure_domain. We show how this conversational AI approach transforms the entire process, from architecture design through operations, dramatically accelerating AWS serverless projects while adhering to architectural principles.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-modern-serverless-solutions-following-best-practices-using-amazon-q-developer-cli-and-mcp/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an intelligent eDiscovery solution using Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/25_07_2025/25_07_2025_2/</link>
      <pubDate>Fri, 25 Jul 2025 17:22:37 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_07_2025/25_07_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to build an intelligent eDiscovery solution using Amazon Bedrock Agents for real-time document analysis. We show how to deploy specialized agents for document classification, contract analysis, email review, and legal document processing, all working together through a multi-agent architecture. We walk through the implementation details, deployment steps, and best practices to create an extensible foundation that organizations can adapt to their specific eDiscovery requirements.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How PerformLine uses prompt engineering on Amazon Bedrock to detect compliance violations</title>
      <link>https://www.dotnetramblings.com/post/25_07_2025/25_07_2025_3/</link>
      <pubDate>Fri, 25 Jul 2025 17:03:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_07_2025/25_07_2025_3/</guid>
      <description>
        
          
            PerformLine operates within the marketing compliance industry, a specialized subset of the broader compliance software market, which includes various compliance solutions like anti-money laundering (AML), know your customer (KYC), and others. In this post, PerformLine and AWS explore how PerformLine used Amazon Bedrock to accelerate compliance processes, generate actionable insights, and provide contextual data—delivering the speed and accuracy essential for large-scale oversight.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-performline-uses-prompt-engineering-on-amazon-bedrock-to-detect-compliance-violations/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Boost cold-start recommendations with vLLM on AWS Trainium</title>
      <link>https://www.dotnetramblings.com/post/24_07_2025/24_07_2025_1/</link>
      <pubDate>Thu, 24 Jul 2025 20:17:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2025/24_07_2025_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to use vLLM for scalable inference and use AWS Deep Learning Containers (DLC) to streamline model packaging and deployment. We’ll generate interest expansions through structured prompts, encode them into embeddings, retrieve candidates with FAISS, apply validation to keep results grounded, and frame the cold-start challenge as a scientific experiment—benchmarking LLM and encoder pairings, iterating rapidly on recommendation metrics, and showing clear ROI for each configuration
          
          
        
      </description>
    </item>
    
    <item>
      <title>Benchmarking Amazon Nova: A comprehensive analysis through MT-Bench and Arena-Hard-Auto</title>
      <link>https://www.dotnetramblings.com/post/24_07_2025/24_07_2025_2/</link>
      <pubDate>Thu, 24 Jul 2025 18:39:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2025/24_07_2025_2/</guid>
      <description>
        
          
            The repositories for MT-Bench and Arena-Hard were originally developed using OpenAI’s GPT API, primarily employing GPT-4 as the judge. Our team has expanded its functionality by integrating it with the Amazon Bedrock API to enable using Anthropic’s Claude Sonnet on Amazon as judge. In this post, we use both MT-Bench and Arena-Hard to benchmark Amazon Nova models by comparing them to other leading LLMs available through Amazon Bedrock.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Customize Amazon Nova in Amazon SageMaker AI using Direct Preference Optimization</title>
      <link>https://www.dotnetramblings.com/post/23_07_2025/23_07_2025_2/</link>
      <pubDate>Wed, 23 Jul 2025 19:08:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2025/23_07_2025_2/</guid>
      <description>
        
          
            At the AWS Summit in New York City, we introduced a comprehensive suite of model customization capabilities for Amazon Nova foundation models. Available as ready-to-use recipes on Amazon SageMaker AI, you can use them to adapt Nova Micro, Nova Lite, and Nova Pro across the model training lifecycle, including pre-training, supervised fine-tuning, and alignment. In this post, we present a streamlined approach to customize Nova Micro in SageMaker training jobs.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Multi-tenant RAG implementation with Amazon Bedrock and Amazon OpenSearch Service for SaaS using JWT</title>
      <link>https://www.dotnetramblings.com/post/23_07_2025/23_07_2025_4/</link>
      <pubDate>Wed, 23 Jul 2025 16:44:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2025/23_07_2025_4/</guid>
      <description>
        
          
            In this post, we introduce a solution that uses OpenSearch Service as a vector data store in multi-tenant RAG, achieving data isolation and routing using JWT and FGAC. This solution uses a combination of JWT and FGAC to implement strict tenant data access isolation and routing, necessitating the use of OpenSearch Service.
Link to article: https://aws.amazon.com/blogs/machine-learning/multi-tenant-rag-implementation-with-amazon-bedrock-and-amazon-opensearch-service-for-saas-using-jwt/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhance generative AI solutions using Amazon Q index with Model Context Protocol – Part 1</title>
      <link>https://www.dotnetramblings.com/post/23_07_2025/23_07_2025_5/</link>
      <pubDate>Wed, 23 Jul 2025 16:40:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2025/23_07_2025_5/</guid>
      <description>
        
          
            In this post, we explore best practices and integration patterns for combining Amazon Q index and MCP, enabling enterprises to build secure, scalable, and actionable AI search-and-retrieval architectures.
Link to article: https://aws.amazon.com/blogs/machine-learning/enhance-generative-ai-solutions-using-amazon-q-index-with-model-context-protocol-part-1/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Beyond accelerators: Lessons from building foundation models on AWS with Japan’s GENIAC program</title>
      <link>https://www.dotnetramblings.com/post/22_07_2025/22_07_2025_1/</link>
      <pubDate>Tue, 22 Jul 2025 16:42:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_07_2025/22_07_2025_1/</guid>
      <description>
        
          
            In 2024, the Ministry of Economy, Trade and Industry (METI) launched the Generative AI Accelerator Challenge (GENIAC)—a Japanese national program to boost generative AI by providing companies with funding, mentorship, and massive compute resources for foundation model (FM) development. AWS was selected as the cloud provider for GENIAC’s second cycle (cycle 2). It provided infrastructure and technical guidance for 12 participating organizations.
Link to article: https://aws.amazon.com/blogs/machine-learning/beyond-accelerators-lessons-from-building-foundation-models-on-aws-with-japans-geniac-program/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline deep learning environments with Amazon Q Developer and MCP</title>
      <link>https://www.dotnetramblings.com/post/22_07_2025/22_07_2025_3/</link>
      <pubDate>Tue, 22 Jul 2025 14:52:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_07_2025/22_07_2025_3/</guid>
      <description>
        
          
            In this post, we explore how to use Amazon Q Developer and Model Context Protocol (MCP) servers to streamline DLC workflows to automate creation, execution, and customization of DLC containers.
Link to article: https://aws.amazon.com/blogs/machine-learning/streamline-deep-learning-environments-with-amazon-q-developer-and-mcp/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an AI-powered automated summarization system with Amazon Bedrock and Amazon Transcribe using Terraform</title>
      <link>https://www.dotnetramblings.com/post/21_07_2025/21_07_2025_2/</link>
      <pubDate>Mon, 21 Jul 2025 17:34:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_07_2025/21_07_2025_2/</guid>
      <description>
        
          
            This post introduces a serverless meeting summarization system that harnesses the advanced capabilities of Amazon Bedrock and Amazon Transcribe to transform audio recordings into concise, structured, and actionable summaries. By automating this process, organizations can reclaim countless hours while making sure key insights, action items, and decisions are systematically captured and made accessible to stakeholders.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-ai-powered-automated-summarization-system-with-amazon-bedrock-and-amazon-transcribe-using-terraform/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kyruus builds a generative AI provider matching solution on AWS</title>
      <link>https://www.dotnetramblings.com/post/21_07_2025/21_07_2025_3/</link>
      <pubDate>Mon, 21 Jul 2025 17:23:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_07_2025/21_07_2025_3/</guid>
      <description>
        
          
            In this post, we demonstrate how Kyruus Health uses AWS services to build Guide. We show how Amazon Bedrock, a fully managed service that provides access to foundation models (FMs) from leading AI companies and Amazon through a single API, and Amazon OpenSearch Service, a managed search and analytics service, work together to understand everyday language about health concerns and connect members with the right providers.
Link to article: https://aws.amazon.com/blogs/machine-learning/kyruus-builds-a-generative-ai-provider-matching-solution-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use generative AI in Amazon Bedrock for enhanced recommendation generation in equipment maintenance</title>
      <link>https://www.dotnetramblings.com/post/21_07_2025/21_07_2025_4/</link>
      <pubDate>Mon, 21 Jul 2025 17:10:55 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_07_2025/21_07_2025_4/</guid>
      <description>
        
          
            In the manufacturing world, valuable insights from service reports often remain underutilized in document storage systems. This post explores how Amazon Web Services (AWS) customers can build a solution that automates the digitisation and extraction of crucial information from many reports using generative AI.
Link to article: https://aws.amazon.com/blogs/machine-learning/use-generative-ai-in-amazon-bedrock-for-enhanced-recommendation-generation-in-equipment-maintenance/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
