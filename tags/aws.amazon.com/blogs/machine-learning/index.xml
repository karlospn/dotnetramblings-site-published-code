<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 12 Sep 2024 22:37:35 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Build a RAG-based QnA application using Llama3 models from SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_0/</link>
      <pubDate>Thu, 12 Sep 2024 22:37:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_0/</guid>
      <description>
        
          
            In this post, we provide a step-by-step guide for creating an enterprise ready RAG application such as a question answering bot. We use the Llama3-8B FM for text generation and the BGE Large EN v1.5 text embedding model for generating embeddings from Amazon SageMaker JumpStart.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-rag-based-qna-application-using-llama3-models-from-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Best prompting practices for using Meta Llama 3 with Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_1/</link>
      <pubDate>Thu, 12 Sep 2024 22:32:05 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_1/</guid>
      <description>
        
          
            In this post, we dive into the best practices and techniques for prompting Meta Llama 3 using Amazon SageMaker JumpStart to generate high-quality, relevant outputs. We discuss how to use system prompts and few-shot examples, and how to optimize inference parameters, so you can get the most out of Meta Llama 3.
Link to article: https://aws.amazon.com/blogs/machine-learning/best-prompting-practices-for-using-meta-llama-3-with-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How healthcare payers and plans can empower members with generative AI</title>
      <link>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_3/</link>
      <pubDate>Thu, 12 Sep 2024 19:13:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_3/</guid>
      <description>
        
          
            In this post, we discuss how generative artificial intelligence (AI) can help health insurance plan members get the information they need. The solution presented in this post not only enhances the member experience by providing a more intuitive and user-friendly interface, but also has the potential to reduce call volumes and operational costs for healthcare payers and plans.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-healthcare-payers-and-plans-can-empower-members-with-generative-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enabling production-grade generative AI: New capabilities lower costs, streamline production, and boost security</title>
      <link>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_4/</link>
      <pubDate>Thu, 12 Sep 2024 18:46:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_4/</guid>
      <description>
        
          
            As generative AI moves from proofs of concept (POCs) to production, we’re seeing a massive shift in how businesses and consumers interact with data, information—and each other. In what we consider “Act 1” of the generative AI story, we saw previously unimaginable amounts of data and compute create models that showcase the power of generative […]
Link to article: https://aws.amazon.com/blogs/machine-learning/enabling-production-grade-generative-ai-new-capabilities-lower-costs-streamline-production-and-boost-security/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Scaling Thomson Reuters’ language model research with Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_10/</link>
      <pubDate>Thu, 12 Sep 2024 15:32:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_09_2024/12_09_2024_10/</guid>
      <description>
        
          
            In this post, we explore the journey that Thomson Reuters took to enable cutting-edge research in training domain-adapted large language models (LLMs) using Amazon SageMaker HyperPod, an Amazon Web Services (AWS) feature focused on providing purpose-built infrastructure for distributed training at scale.
Link to article: https://aws.amazon.com/blogs/machine-learning/scaling-thomson-reuters-language-model-research-with-amazon-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>A review of purpose-built accelerators for financial services</title>
      <link>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_2/</link>
      <pubDate>Wed, 11 Sep 2024 19:38:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_2/</guid>
      <description>
        
          
            In this post, we aim to provide business leaders with a non-technical overview of purpose-built accelerators (PBAs) and their role within the financial services industry (FSI).
Link to article: https://aws.amazon.com/blogs/machine-learning/a-review-of-purpose-built-accelerators-for-financial-services/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Anomaly detection in streaming time series data with online learning using Amazon Managed Service for Apache Flink</title>
      <link>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_3/</link>
      <pubDate>Wed, 11 Sep 2024 19:27:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_3/</guid>
      <description>
        
          
            In this post, we demonstrate how to build a robust real-time anomaly detection solution for streaming time series data using Amazon Managed Service for Apache Flink and other AWS managed services.
Link to article: https://aws.amazon.com/blogs/machine-learning/anomaly-detection-in-streaming-time-series-data-with-online-learning-using-amazon-managed-service-for-apache-flink/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Generative AI-powered technology operations</title>
      <link>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_4/</link>
      <pubDate>Wed, 11 Sep 2024 19:22:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_4/</guid>
      <description>
        
          
            In this post we describe how AWS generative AI solutions (including Amazon Bedrock, Amazon Q Developer, and Amazon Q Business) can further enhance TechOps productivity, reduce time to resolve issues, enhance customer experience, standardize operating procedures, and augment knowledge bases.
Link to article: https://aws.amazon.com/blogs/machine-learning/generative-ai-powered-technology-operations/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimizing MLOps for Sustainability</title>
      <link>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_5/</link>
      <pubDate>Wed, 11 Sep 2024 18:45:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_5/</guid>
      <description>
        
          
            In this post, we review the guidance for optimizing MLOps for Sustainability on AWS, providing service-specific practices to understand and reduce the environmental impact of these workloads.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimizing-mlops-for-sustainability/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enabling complex generative AI applications with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_10/</link>
      <pubDate>Wed, 11 Sep 2024 14:02:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_10/</guid>
      <description>
        
          
            In this post, we take a closer look at Amazon Bedrock Agents. They empower you to build intelligent and context-aware generative AI applications, streamlining complex workflows and delivering natural, conversational user experiences.
Link to article: https://aws.amazon.com/blogs/machine-learning/enabling-complex-generative-ai-applications-with-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Genomics England uses Amazon SageMaker to predict cancer subtypes and patient survival from multi-modal data</title>
      <link>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_17/</link>
      <pubDate>Wed, 11 Sep 2024 00:13:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_09_2024/11_09_2024_17/</guid>
      <description>
        
          
            In this post, we detail our collaboration in creating two proof of concept (PoC) exercises around multi-modal machine learning for survival analysis and cancer sub-typing, using genomic (gene expression, mutation and copy number variant data) and imaging (histopathology slides) data. We provide insights on interpretability, robustness, and best practices of architecting complex ML workflows on AWS with Amazon SageMaker. These multi-modal pipelines are being used on the Genomics England cancer cohort to enhance our understanding of cancer biomarkers and biology.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Align Meta Llama 3 to human preferences with DPO, Amazon SageMaker Studio, and Amazon SageMaker Ground Truth</title>
      <link>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_0/</link>
      <pubDate>Mon, 09 Sep 2024 22:40:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_0/</guid>
      <description>
        
          
            In this post, we show you how to enhance the performance of Meta Llama 3 8B Instruct by fine-tuning it using direct preference optimization (DPO) on data collected with SageMaker Ground Truth.
Link to article: https://aws.amazon.com/blogs/machine-learning/align-meta-llama-3-to-human-preferences-with-dpo-amazon-sagemaker-studio-and-amazon-sagemaker-ground-truth/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon EC2 P5e instances are generally available</title>
      <link>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_1/</link>
      <pubDate>Mon, 09 Sep 2024 22:20:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_1/</guid>
      <description>
        
          
            In this post, we discuss the core capabilities of Amazon Elastic Compute Cloud (Amazon EC2) P5e instances and the use cases they’re well-suited for. We walk you through an example of how to get started with these instances and carry out inference deployment of Meta Llama 3.1 70B and 405B models on them.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-ec2-p5e-instances-are-generally-available/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Exploring data using AI chat at Domo with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_2/</link>
      <pubDate>Mon, 09 Sep 2024 21:51:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_2/</guid>
      <description>
        
          
            In this post, we share how Domo, a cloud-centered data experiences innovator is using Amazon Bedrock to provide a flexible and powerful AI solution.
Link to article: https://aws.amazon.com/blogs/machine-learning/exploring-data-using-ai-chat-at-domo-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Vidmob is using generative AI to transform its creative data landscape</title>
      <link>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_0/</link>
      <pubDate>Fri, 06 Sep 2024 21:12:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_0/</guid>
      <description>
        
          
            In this post, we illustrate how Vidmob, a creative data company, worked with the AWS Generative AI Innovation Center (GenAIIC) team to uncover meaningful insights at scale within creative data using Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-vidmob-is-using-generative-ai-to-transform-its-creative-data-landscape/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine-tune Llama 3 for text generation on Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_1/</link>
      <pubDate>Fri, 06 Sep 2024 20:22:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to fine-tune the recently released Llama 3 models from Meta, specifically the llama-3-8b and llama-3-70b variants, using Amazon SageMaker JumpStart.
Link to article: https://aws.amazon.com/blogs/machine-learning/fine-tune-llama-3-for-text-generation-on-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Ground truth curation and metric interpretation best practices for evaluating generative AI question answering using FMEval</title>
      <link>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_3/</link>
      <pubDate>Fri, 06 Sep 2024 20:11:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_3/</guid>
      <description>
        
          
            In this post, we discuss best practices for working with Foundation Model Evaluations Library (FMEval) in ground truth curation and metric interpretation for evaluating question answering applications for factual knowledge and quality.
Link to article: https://aws.amazon.com/blogs/machine-learning/ground-truth-curation-and-metric-interpretation-best-practices-for-evaluating-generative-ai-question-answering-using-fmeval/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
