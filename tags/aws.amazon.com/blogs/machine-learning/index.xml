<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 23 Oct 2025 20:57:29 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Generate Gremlin queries using Amazon Bedrock models</title>
      <link>https://www.dotnetramblings.com/post/23_10_2025/23_10_2025_0/</link>
      <pubDate>Thu, 23 Oct 2025 20:57:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_10_2025/23_10_2025_0/</guid>
      <description>
        
          
            In this post, we explore an innovative approach that converts natural language to Gremlin queries using Amazon Bedrock models such as Amazon Nova Pro, helping business analysts and data scientists access graph databases without requiring deep technical expertise. The methodology involves three key steps: extracting graph knowledge, structuring the graph similar to text-to-SQL processing, and generating executable Gremlin queries through an iterative refinement process that achieved 74.17% overall accuracy in testing.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Incorporating responsible AI into generative AI project prioritization</title>
      <link>https://www.dotnetramblings.com/post/23_10_2025/23_10_2025_1/</link>
      <pubDate>Thu, 23 Oct 2025 20:51:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_10_2025/23_10_2025_1/</guid>
      <description>
        
          
            In this post, we explore how companies can systematically incorporate responsible AI practices into their generative AI project prioritization methodology to better evaluate business value against costs while addressing novel risks like hallucination and regulatory compliance. The post demonstrates through a practical example how conducting upfront responsible AI risk assessments can significantly change project rankings by revealing substantial mitigation work that affects overall project complexity and timeline.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build scalable creative solutions for product teams with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_0/</link>
      <pubDate>Wed, 22 Oct 2025 23:02:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_0/</guid>
      <description>
        
          
            In this post, we explore how product teams can leverage Amazon Bedrock and AWS services to transform their creative workflows through generative AI, enabling rapid content iteration across multiple formats while maintaining brand consistency and compliance. The solution demonstrates how teams can deploy a scalable generative AI application that accelerates everything from product descriptions and marketing copy to visual concepts and video content, significantly reducing time to market while enhancing creative quality.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a proactive AI cost management system for Amazon Bedrock – Part 2</title>
      <link>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_1/</link>
      <pubDate>Wed, 22 Oct 2025 18:58:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_1/</guid>
      <description>
        
          
            In this post, we explore advanced cost monitoring strategies for Amazon Bedrock deployments, introducing granular custom tagging approaches for precise cost allocation and comprehensive reporting mechanisms that build upon the proactive cost management foundation established in Part 1. The solution demonstrates how to implement invocation-level tagging, application inference profiles, and integration with AWS Cost Explorer to create a complete 360-degree view of generative AI usage and expenses.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a proactive AI cost management system for Amazon Bedrock – Part 1</title>
      <link>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_2/</link>
      <pubDate>Wed, 22 Oct 2025 18:58:05 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_2/</guid>
      <description>
        
          
            In this post, we introduce a comprehensive solution for proactively managing Amazon Bedrock inference costs through a cost sentry mechanism designed to establish and enforce token usage limits, providing organizations with a robust framework for controlling generative AI expenses. The solution uses serverless workflows and native Amazon Bedrock integration to deliver a predictable, cost-effective approach that aligns with organizational financial constraints while preventing runaway costs through leading indicators and real-time budget enforcement.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline code migration using Amazon Nova Premier with an agentic workflow</title>
      <link>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_3/</link>
      <pubDate>Wed, 22 Oct 2025 18:48:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_3/</guid>
      <description>
        
          
            In this post, we demonstrate how Amazon Nova Premier with Amazon Bedrock can systematically migrate legacy C code to modern Java/Spring applications using an intelligent agentic workflow that breaks down complex conversions into specialized agent roles. The solution reduces migration time and costs while improving code quality through automated validation, security assessment, and iterative refinement processes that handle even large codebases exceeding token limitations.
Link to article: https://aws.amazon.com/blogs/machine-learning/streamline-code-migration-using-amazon-nova-premier-with-an-agentic-workflow/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Metagenomi generates millions of novel enzymes cost-effectively using AWS Inferentia</title>
      <link>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_11/</link>
      <pubDate>Wed, 22 Oct 2025 13:53:20 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_10_2025/22_10_2025_11/</guid>
      <description>
        
          
            In this post, we detail how Metagenomi partnered with AWS to implement the Progen2 protein language model on AWS Inferentia, achieving up to 56% cost reduction for high-throughput enzyme generation workflows. The implementation enabled cost-effective generation of millions of novel enzyme variants using EC2 Inf2 Spot Instances and AWS Batch, demonstrating how cloud-based generative AI can make large-scale protein design more accessible for biotechnology applications .
Link to article: https://aws.amazon.com/blogs/machine-learning/metagenomi-generates-millions-of-novel-enzymes-cost-effectively-using-aws-inferentia/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Serverless deployment for your Amazon SageMaker Canvas models</title>
      <link>https://www.dotnetramblings.com/post/21_10_2025/21_10_2025_0/</link>
      <pubDate>Tue, 21 Oct 2025 19:03:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_10_2025/21_10_2025_0/</guid>
      <description>
        
          
            In this post, we walk through how to take an ML model built in SageMaker Canvas and deploy it using SageMaker Serverless Inference, helping you go from model creation to production-ready predictions quickly and efficiently without managing any infrastructure. This solution demonstrates a complete workflow from adding your trained model to the SageMaker Model Registry through creating serverless endpoint configurations and deploying endpoints that automatically scale based on demand .
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building a multi-agent voice assistant with Amazon Nova Sonic and Amazon Bedrock AgentCore</title>
      <link>https://www.dotnetramblings.com/post/21_10_2025/21_10_2025_1/</link>
      <pubDate>Tue, 21 Oct 2025 17:31:05 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_10_2025/21_10_2025_1/</guid>
      <description>
        
          
            In this post, we explore how Amazon Nova Sonic&#39;s speech-to-speech capabilities can be combined with Amazon Bedrock AgentCore to create sophisticated multi-agent voice assistants that break complex tasks into specialized, manageable components. The approach demonstrates how to build modular, scalable voice applications using a banking assistant example with dedicated sub-agents for authentication, banking inquiries, and mortgage services, offering a more maintainable alternative to monolithic voice assistant designs.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate large-scale AI training with Amazon SageMaker HyperPod training operator</title>
      <link>https://www.dotnetramblings.com/post/21_10_2025/21_10_2025_2/</link>
      <pubDate>Tue, 21 Oct 2025 17:26:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_10_2025/21_10_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to deploy and manage machine learning training workloads using the Amazon SageMaker HyperPod training operator, which enhances training resilience for Kubernetes workloads through pinpoint recovery and customizable monitoring capabilities. The Amazon SageMaker HyperPod training operator helps accelerate generative AI model development by efficiently managing distributed training across large GPU clusters, offering benefits like centralized training process monitoring, granular process recovery, and hanging job detection that can reduce recovery times from tens of minutes to seconds.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How TP ICAP transformed CRM data into real-time insights with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/17_10_2025/17_10_2025_2/</link>
      <pubDate>Fri, 17 Oct 2025 16:15:25 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_10_2025/17_10_2025_2/</guid>
      <description>
        
          
            This post shows how TP ICAP used Amazon Bedrock Knowledge Bases and Amazon Bedrock Evaluations to build ClientIQ, an enterprise-grade solution with enhanced security features for extracting CRM insights using AI, delivering immediate business value.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-tp-icap-transformed-crm-data-into-real-time-insights-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Principal Financial Group accelerates build, test, and deployment of Amazon Lex V2 bots through automation</title>
      <link>https://www.dotnetramblings.com/post/17_10_2025/17_10_2025_3/</link>
      <pubDate>Fri, 17 Oct 2025 16:13:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_10_2025/17_10_2025_3/</guid>
      <description>
        
          
            In the post Principal Financial Group increases Voice Virtual Assistant performance using Genesys, Amazon Lex, and Amazon QuickSight, we discussed the overall Principal Virtual Assistant solution using Genesys Cloud, Amazon Lex V2, multiple AWS services, and a custom reporting and analytics solution using Amazon QuickSight.
Link to article: https://aws.amazon.com/blogs/machine-learning/principal-financial-group-accelerates-build-test-and-deployment-of-amazon-lex-v2-bots-through-automation/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Beyond vibes: How to properly select the right LLM for the right task</title>
      <link>https://www.dotnetramblings.com/post/17_10_2025/17_10_2025_4/</link>
      <pubDate>Fri, 17 Oct 2025 16:09:22 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_10_2025/17_10_2025_4/</guid>
      <description>
        
          
            In this post, we discuss an approach that can guide you to build comprehensive and empirically driven evaluations that can help you make better decisions when selecting the right model for your task.
Link to article: https://aws.amazon.com/blogs/machine-learning/beyond-vibes-how-to-properly-select-the-right-llm-for-the-right-task/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Splash Music transforms music generation using AWS Trainium and Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/17_10_2025/17_10_2025_5/</link>
      <pubDate>Fri, 17 Oct 2025 16:06:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_10_2025/17_10_2025_5/</guid>
      <description>
        
          
            In this post, we show how Splash Music is setting a new standard for AI-powered music creation by using its advanced HummingLM model with AWS Trainium on Amazon SageMaker HyperPod. As a selected startup in the 2024 AWS Generative AI Accelerator, Splash Music collaborated closely with AWS Startups and the AWS Generative AI Innovation Center (GenAIIC) to fast-track innovation and accelerate their music generation FM development lifecycle.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Iterative fine-tuning on Amazon Bedrock for strategic model improvement</title>
      <link>https://www.dotnetramblings.com/post/16_10_2025/16_10_2025_0/</link>
      <pubDate>Thu, 16 Oct 2025 23:11:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_10_2025/16_10_2025_0/</guid>
      <description>
        
          
            Organizations often face challenges when implementing single-shot fine-tuning approaches for their generative AI models. The single-shot fine-tuning method involves selecting training data, configuring hyperparameters, and hoping the results meet expectations without the ability to make incremental adjustments. Single-shot fine-tuning frequently leads to suboptimal results and requires starting the entire process from scratch when improvements are […]
Link to article: https://aws.amazon.com/blogs/machine-learning/iterative-fine-tuning-on-amazon-bedrock-for-strategic-model-improvement/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Voice AI-powered drive-thru ordering with Amazon Nova Sonic and dynamic menu displays</title>
      <link>https://www.dotnetramblings.com/post/16_10_2025/16_10_2025_2/</link>
      <pubDate>Thu, 16 Oct 2025 18:36:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_10_2025/16_10_2025_2/</guid>
      <description>
        
          
            In this post, we&#39;ll demonstrate how to implement a Quick Service Restaurants (QSRs) drive-thru solution using Amazon Nova Sonic and AWS services. We&#39;ll walk through building an intelligent system that combines voice AI with interactive menu displays, providing technical insights and implementation guidance to help restaurants modernize their drive-thru operations.
Link to article: https://aws.amazon.com/blogs/machine-learning/voice-ai-powered-drive-thru-ordering-with-amazon-nova-sonic-and-dynamic-menu-displays/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimizing document AI and structured outputs by fine-tuning Amazon Nova Models and on-demand inference</title>
      <link>https://www.dotnetramblings.com/post/16_10_2025/16_10_2025_3/</link>
      <pubDate>Thu, 16 Oct 2025 18:32:55 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_10_2025/16_10_2025_3/</guid>
      <description>
        
          
            This post provides a comprehensive hands-on guide to fine-tune Amazon Nova Lite for document processing tasks, with a focus on tax form data extraction. Using our open-source GitHub repository code sample, we demonstrate the complete workflow from data preparation to model deployment. Link to article: https://aws.amazon.com/blogs/machine-learning/optimizing-document-ai-and-structured-outputs-by-fine-tuning-amazon-nova-models-and-on-demand-inference/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
