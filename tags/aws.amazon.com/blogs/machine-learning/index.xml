<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Wed, 03 Apr 2024 04:37:15 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AWS and Mistral AI commit to democratizing generative AI with a strengthened collaboration</title>
      <link>https://www.dotnetramblings.com/post/03_04_2024/03_04_2024_0/</link>
      <pubDate>Wed, 03 Apr 2024 04:37:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_04_2024/03_04_2024_0/</guid>
      <description>
        
          
            Today, Mistral AI is bringing its latest and most capable model, Mistral Large, to Amazon Bedrock, and is committed to making future models accessible to AWS customers. Mistral AI will also use AWS AI-optimized AWS Trainium and AWS Inferentia to build and deploy its future foundation models on Amazon Bedrock, benefitting from the price, performance, scale, and security of AWS. Along with this announcement, starting today, customers can use Amazon Bedrock in the AWS Europe (Paris) Region.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Gradient makes LLM benchmarking cost-effective and effortless with AWS Inferentia</title>
      <link>https://www.dotnetramblings.com/post/02_04_2024/02_04_2024_3/</link>
      <pubDate>Tue, 02 Apr 2024 16:21:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_04_2024/02_04_2024_3/</guid>
      <description>
        
          
            This is a guest post co-written with Michael Feil at Gradient. Evaluating the performance of large language models (LLMs) is an important step of the pre-training and fine-tuning process before deployment. The faster and more frequent you’re able to validate performance, the higher the chances you’ll be able to improve the performance of the model. […]
Link to article: https://aws.amazon.com/blogs/machine-learning/gradient-makes-llm-benchmarking-cost-effective-and-effortless-with-aws-inferentia/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enable single sign-on access of Amazon SageMaker Canvas using AWS IAM Identity Center: Part 2</title>
      <link>https://www.dotnetramblings.com/post/02_04_2024/02_04_2024_4/</link>
      <pubDate>Tue, 02 Apr 2024 16:08:38 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_04_2024/02_04_2024_4/</guid>
      <description>
        
          
            Amazon SageMaker Canvas allows you to use machine learning (ML) to generate predictions without having to write any code. It does so by covering the end-to-end ML workflow: whether you’re looking for powerful data preparation and AutoML, managed endpoint deployment, simplified MLOps capabilities, or the ability to configure foundation models for generative AI, SageMaker Canvas […]
Link to article: https://aws.amazon.com/blogs/machine-learning/enable-single-sign-on-access-of-amazon-sagemaker-canvas-using-aws-iam-identity-center-part-2/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Solar models from Upstage are now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/02_04_2024/02_04_2024_5/</link>
      <pubDate>Tue, 02 Apr 2024 15:55:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_04_2024/02_04_2024_5/</guid>
      <description>
        
          
            This blog post is co-written with Hwalsuk Lee at Upstage. Today, we’re excited to announce that the Solar foundation model developed by Upstage is now available for customers using Amazon SageMaker JumpStart. Solar is a large language model (LLM) 100% pre-trained with Amazon SageMaker that outperforms and uses its compact size and powerful track records […]
Link to article: https://aws.amazon.com/blogs/machine-learning/solar-models-from-upstage-are-now-available-in-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Provide live agent assistance for your chatbot users with Amazon Lex and Talkdesk cloud contact center</title>
      <link>https://www.dotnetramblings.com/post/29_03_2024/29_03_2024_3/</link>
      <pubDate>Fri, 29 Mar 2024 14:56:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_03_2024/29_03_2024_3/</guid>
      <description>
        
          
            Amazon Lex provides advanced conversational artificial intelligence (AI) capabilities to enable self-service support for your organization’s contact center. With Amazon Lex, you can implement an omnichannel strategy where customers engage via phone, websites, and messaging platforms. The bots can answer FAQs, provide self-service experiences, or triage customer requests before transferring to a human agent. Amazon Lex integrates […]
Link to article: https://aws.amazon.com/blogs/machine-learning/provide-live-agent-assistance-for-your-chatbot-users-with-amazon-lex-and-talkdesk-cloud-contact-center/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Advanced RAG patterns on Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/28_03_2024/28_03_2024_1/</link>
      <pubDate>Thu, 28 Mar 2024 16:18:02 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_03_2024/28_03_2024_1/</guid>
      <description>
        
          
            Today, customers of all industries—whether it’s financial services, healthcare and life sciences, travel and hospitality, media and entertainment, telecommunications, software as a service (SaaS), and even proprietary model providers—are using large language models (LLMs) to build applications like question and answering (QnA) chatbots, search engines, and knowledge bases. These generative AI applications are not only […]
Link to article: https://aws.amazon.com/blogs/machine-learning/advanced-rag-patterns-on-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Efficient continual pre-training LLMs for financial domains</title>
      <link>https://www.dotnetramblings.com/post/28_03_2024/28_03_2024_2/</link>
      <pubDate>Thu, 28 Mar 2024 16:08:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_03_2024/28_03_2024_2/</guid>
      <description>
        
          
            Large language models (LLMs) are generally trained on large publicly available datasets that are domain agnostic. For example, Meta’s Llama models are trained on datasets such as CommonCrawl, C4, Wikipedia, and ArXiv. These datasets encompass a broad range of topics and domains. Although the resulting models yield amazingly good results for general tasks, such as […]
Link to article: https://aws.amazon.com/blogs/machine-learning/efficient-continual-pre-training-llms-for-financial-domains/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Achieve DevOps maturity with BMC AMI zAdviser Enterprise and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/27_03_2024/27_03_2024_0/</link>
      <pubDate>Wed, 27 Mar 2024 16:37:05 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/27_03_2024/27_03_2024_0/</guid>
      <description>
        
          
            This blog post discusses how BMC Software added AWS Generative AI capabilities to its product BMC AMI zAdviser Enterprise. The zAdviser uses Amazon Bedrock to provide summarization, analysis, and recommendations for improvement based on the DORA metrics data.
Link to article: https://aws.amazon.com/blogs/machine-learning/achieve-devops-maturity-with-bmc-ami-zadviser-enterprise-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine-tune your Amazon Titan Image Generator G1 model using Amazon Bedrock model customization</title>
      <link>https://www.dotnetramblings.com/post/27_03_2024/27_03_2024_1/</link>
      <pubDate>Wed, 27 Mar 2024 16:14:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/27_03_2024/27_03_2024_1/</guid>
      <description>
        
          
            Amazon Titan lmage Generator G1 is a cutting-edge text-to-image model, available via Amazon Bedrock, that is able to understand prompts describing multiple objects in various contexts and captures these relevant details in the images it generates. It is available in US East (N. Virginia) and US West (Oregon) AWS Regions and can perform advanced image […]
Link to article: https://aws.amazon.com/blogs/machine-learning/fine-tune-your-amazon-titan-image-generator-g1-model-using-amazon-bedrock-model-customization/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
