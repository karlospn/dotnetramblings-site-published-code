<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 23 Jul 2024 16:18:57 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AWS AI chips deliver high performance and low cost for Llama 3.1 models on AWS</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_3/</link>
      <pubDate>Tue, 23 Jul 2024 16:18:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_3/</guid>
      <description>
        
          
            Today, we are excited to announce AWS Trainium and AWS Inferentia support for fine-tuning and inference of the Llama 3.1 models. The Llama 3.1 family of multilingual large language models (LLMs) is a collection of pre-trained and instruction tuned generative models in 8B, 70B, and 405B sizes. In a previous post, we covered how to deploy Llama 3 models on AWS Trainium and Inferentia based instances in Amazon SageMaker JumpStart. In this post, we outline how to get started with fine-tuning and deploying the Llama 3.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use Llama 3.1 405B to generate synthetic data for fine-tuning tasks</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_4/</link>
      <pubDate>Tue, 23 Jul 2024 16:18:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_4/</guid>
      <description>
        
          
            Today, we are excited to announce the availability of the Llama 3.1 405B model on Amazon SageMaker JumpStart, and Amazon Bedrock in preview. The Llama 3.1 models are a collection of state-of-the-art pre-trained and instruct fine-tuned generative artificial intelligence (AI) models in 8B, 70B, and 405B sizes. Amazon SageMaker JumpStart is a machine learning (ML) hub that provides access to algorithms, models, and ML solutions so you can quickly get started with ML.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Llama 3.1 models are now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_5/</link>
      <pubDate>Tue, 23 Jul 2024 16:16:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_5/</guid>
      <description>
        
          
            Today, we are excited to announce that the state-of-the-art Llama 3.1 collection of multilingual large language models (LLMs), which includes pre-trained and instruction tuned generative AI models in 8B, 70B, and 405B sizes, is available through Amazon SageMaker JumpStart to deploy for inference. Llama is a publicly accessible LLM designed for developers, researchers, and businesses to build, experiment, and responsibly scale their generative artificial intelligence (AI) ideas. In this post, we walk through how to discover and deploy Llama 3.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Intelligent document processing using Amazon Bedrock and Anthropic Claude</title>
      <link>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_1/</link>
      <pubDate>Thu, 18 Jul 2024 18:21:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_1/</guid>
      <description>
        
          
            In this post, we show how to develop an IDP solution using Anthropic Claude 3 Sonnet on Amazon Bedrock. We demonstrate how to extract data from a scanned document and insert it into a database.
Link to article: https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-using-amazon-bedrock-and-anthropic-claude/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Metadata filtering for tabular data with Knowledge Bases for Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_2/</link>
      <pubDate>Thu, 18 Jul 2024 18:19:38 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_2/</guid>
      <description>
        
          
            Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading artificial intelligence (AI) companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon through a single API. To equip FMs with up-to-date and proprietary information, organizations use Retrieval Augmented Generation (RAG), a technique that […]
Link to article: https://aws.amazon.com/blogs/machine-learning/metadata-filtering-for-tabular-data-with-knowledge-bases-for-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Secure AccountantAI Chatbot: Lili’s journey with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_7/</link>
      <pubDate>Thu, 18 Jul 2024 16:20:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_7/</guid>
      <description>
        
          
            This post was written in collaboration with Liran Zelkha and Eyal Solnik from Lili. Small business proprietors tend to prioritize the operational aspects of their enterprises over administrative tasks, such as maintaining financial records and accounting. While hiring a professional accountant can provide valuable guidance and expertise, it can be cost-prohibitive for many small businesses. […]
Link to article: https://aws.amazon.com/blogs/machine-learning/secure-accountantai-chatbot-lilis-journey-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Mend.io unlocked hidden patterns in CVE data with Anthropic Claude on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_8/</link>
      <pubDate>Thu, 18 Jul 2024 16:14:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_8/</guid>
      <description>
        
          
            This post is co-written with Maciej Mensfeld from Mend.io. In the ever-evolving landscape of cybersecurity, the ability to effectively analyze and categorize Common Vulnerabilities and Exposures (CVEs) is crucial. This post explores how Mend.io, a cybersecurity firm, used Anthropic Claude on Amazon Bedrock to classify and identify CVEs containing specific attack requirements details. By using […]
Link to article: https://aws.amazon.com/blogs/machine-learning/how-mend-io-unlocked-hidden-patterns-in-cve-data-with-anthropic-claude-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Deloitte Italy built a digital payments fraud detection solution using quantum machine learning and Amazon Braket</title>
      <link>https://www.dotnetramblings.com/post/17_07_2024/17_07_2024_4/</link>
      <pubDate>Wed, 17 Jul 2024 16:58:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_07_2024/17_07_2024_4/</guid>
      <description>
        
          
            As digital commerce expands, fraud detection has become critical in protecting businesses and consumers engaging in online transactions. Implementing machine learning (ML) algorithms enables real-time analysis of high-volume transactional data to rapidly identify fraudulent activity. This advanced capability helps mitigate financial risks and safeguard customer privacy within expanding digital markets. Deloitte is a strategic global […]
Link to article: https://aws.amazon.com/blogs/machine-learning/how-deloitte-italy-built-a-digital-payments-fraud-detection-solution-using-quantum-machine-learning-and-amazon-braket/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon SageMaker unveils the Cohere Command R fine-tuning model</title>
      <link>https://www.dotnetramblings.com/post/17_07_2024/17_07_2024_5/</link>
      <pubDate>Wed, 17 Jul 2024 16:49:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_07_2024/17_07_2024_5/</guid>
      <description>
        
          
            AWS announced the availability of the Cohere Command R fine-tuning model on Amazon SageMaker. This latest addition to the SageMaker suite of machine learning (ML) capabilities empowers enterprises to harness the power of large language models (LLMs) and unlock their full potential for a wide range of applications. Cohere Command R is a scalable, frontier […]
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-unveils-the-cohere-command-r-fine-tuning-model/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Derive meaningful and actionable operational insights from AWS Using Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/17_07_2024/17_07_2024_6/</link>
      <pubDate>Wed, 17 Jul 2024 16:36:45 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_07_2024/17_07_2024_6/</guid>
      <description>
        
          
            As a customer, you rely on Amazon Web Services (AWS) expertise to be available and understand your specific environment and operations. Today, you might implement manual processes to summarize lessons learned, obtain recommendations, or expedite the resolution of an incident. This can be time consuming, inconsistent, and not readily accessible. This post shows how to […]
Link to article: https://aws.amazon.com/blogs/machine-learning/derive-meaningful-and-actionable-operational-insights-from-aws-using-amazon-q-business/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate your generative AI distributed training workloads with the NVIDIA NeMo Framework on Amazon EKS</title>
      <link>https://www.dotnetramblings.com/post/16_07_2024/16_07_2024_1/</link>
      <pubDate>Tue, 16 Jul 2024 19:56:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_07_2024/16_07_2024_1/</guid>
      <description>
        
          
            In today’s rapidly evolving landscape of artificial intelligence (AI), training large language models (LLMs) poses significant challenges. These models often require enormous computational resources and sophisticated infrastructure to handle the vast amounts of data and complex algorithms involved. Without a structured framework, the process can become prohibitively time-consuming, costly, and complex. Enterprises struggle with managing […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-your-generative-ai-distributed-training-workloads-with-the-nvidia-nemo-framework-on-amazon-eks/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Governing the ML lifecycle at scale, Part 2: Multi-account foundations</title>
      <link>https://www.dotnetramblings.com/post/16_07_2024/16_07_2024_3/</link>
      <pubDate>Tue, 16 Jul 2024 17:18:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_07_2024/16_07_2024_3/</guid>
      <description>
        
          
            Your multi-account strategy is the core of your foundational environment on AWS. Design decisions around your multi-account environment are critical for operating securely at scale. Grouping your workloads strategically into multiple AWS accounts enables you to apply different controls across workloads, track cost and usage, reduce the impact of account limits, and mitigate the complexity […]
Link to article: https://aws.amazon.com/blogs/machine-learning/governing-the-ml-lifecycle-at-scale-part-2-multi-account-foundations/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
