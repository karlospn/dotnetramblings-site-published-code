<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 16 Dec 2025 21:18:54 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Governance by design: The essential guide for successful AI scaling</title>
      <link>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_2/</link>
      <pubDate>Tue, 16 Dec 2025 21:18:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_2/</guid>
      <description>
        
          
            Picture this: Your enterprise has just deployed its first generative AI application. The initial results are promising, but as you plan to scale across departments, critical questions emerge. How will you enforce consistent security, prevent model bias, and maintain control as AI applications multiply?
Link to article: https://aws.amazon.com/blogs/machine-learning/governance-by-design-the-essential-guide-for-successful-ai-scaling/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Tata Power CoE built a scalable AI-powered solar panel inspection solution with Amazon SageMaker AI and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_4/</link>
      <pubDate>Tue, 16 Dec 2025 18:55:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_4/</guid>
      <description>
        
          
            In this post, we explore how Tata Power CoE and Oneture Technologies use AWS services to automate the inspection process end-to-end.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-tata-power-coe-built-a-scalable-ai-powered-solar-panel-inspection-solution-with-amazon-sagemaker-ai-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlocking video understanding with TwelveLabs Marengo on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_5/</link>
      <pubDate>Tue, 16 Dec 2025 18:51:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_5/</guid>
      <description>
        
          
            In this post, we&#39;ll show how the TwelveLabs Marengo embedding model, available on Amazon Bedrock, enhances video understanding through multimodal AI. We&#39;ll build a video semantic search and analysis solution using embeddings from the Marengo model with Amazon OpenSearch Serverless as the vector database, for semantic search capabilities that go beyond simple metadata matching to deliver intelligent content discovery.
Link to article: https://aws.amazon.com/blogs/machine-learning/unlocking-video-understanding-with-twelvelabs-marengo-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Checkpointless training on Amazon SageMaker HyperPod: Production-scale training with faster fault recovery</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_0/</link>
      <pubDate>Mon, 15 Dec 2025 19:45:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_0/</guid>
      <description>
        
          
            In this post, we introduce checkpointless training on Amazon SageMaker HyperPod, a paradigm shift in model training that reduces the need for traditional checkpointing by enabling peer-to-peer state recovery. Results from production-scale validation show 80–93% reduction in recovery time (from 15–30 minutes or more to under 2 minutes) and enables up to 95% training goodput on cluster sizes with thousands of AI accelerators.
Link to article: https://aws.amazon.com/blogs/machine-learning/checkpointless-training-on-amazon-sagemaker-hyperpod-production-scale-training-with-faster-fault-recovery/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Adaptive infrastructure for foundation model training with elastic training on SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_2/</link>
      <pubDate>Mon, 15 Dec 2025 18:12:22 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_2/</guid>
      <description>
        
          
            Amazon SageMaker HyperPod now supports elastic training, enabling your machine learning (ML) workloads to automatically scale based on resource availability. In this post, we demonstrate how elastic training helps you maximize GPU utilization, reduce costs, and accelerate model development through dynamic resource adaptation, while maintain training quality and minimizing manual intervention.
Link to article: https://aws.amazon.com/blogs/machine-learning/adaptive-infrastructure-for-foundation-model-training-with-elastic-training-on-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Customize agent workflows with advanced orchestration techniques using Strands Agents</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_4/</link>
      <pubDate>Mon, 15 Dec 2025 17:35:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_4/</guid>
      <description>
        
          
            In this post, we explore two powerful orchestration patterns implemented with Strands Agents. Using a common set of travel planning tools, we demonstrate how different orchestration strategies can solve the same problem through distinct reasoning approaches,
Link to article: https://aws.amazon.com/blogs/machine-learning/customize-agent-workflows-with-advanced-orchestration-techniques-using-strands-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Operationalize generative AI workloads and scale to hundreds of use cases with Amazon Bedrock – Part 1: GenAIOps</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_5/</link>
      <pubDate>Mon, 15 Dec 2025 17:31:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_5/</guid>
      <description>
        
          
            In this first part of our two-part series, you&#39;ll learn how to evolve your existing DevOps architecture for generative AI workloads and implement GenAIOps practices. We&#39;ll showcase practical implementation strategies for different generative AI adoption levels, focusing on consuming foundation models.
Link to article: https://aws.amazon.com/blogs/machine-learning/operationalize-generative-ai-workloads-and-scale-to-hundreds-of-use-cases-with-amazon-bedrock-part-1-genaiops/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Applying data loading best practices for ML training with Amazon S3 clients</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_6/</link>
      <pubDate>Mon, 15 Dec 2025 17:29:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_6/</guid>
      <description>
        
          
            In this post, we present practical techniques and recommendations for optimizing throughput in ML training workloads that read data directly from Amazon S3 general purpose buckets.
Link to article: https://aws.amazon.com/blogs/machine-learning/applying-data-loading-best-practices-for-ml-training-with-amazon-s3-clients/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building a voice-driven AWS assistant with Amazon Nova Sonic</title>
      <link>https://www.dotnetramblings.com/post/12_12_2025/12_12_2025_1/</link>
      <pubDate>Fri, 12 Dec 2025 18:07:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_12_2025/12_12_2025_1/</guid>
      <description>
        
          
            In this post, we explore how to build a sophisticated voice-powered AWS operations assistant using Amazon Nova Sonic for speech processing and Strands Agents for multi-agent orchestration. This solution demonstrates how natural language voice interactions can transform cloud operations, making AWS services more accessible and operations more efficient.
Link to article: https://aws.amazon.com/blogs/machine-learning/building-a-voice-driven-aws-assistant-with-amazon-nova-sonic/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Harmonic Security improved their data-leakage detection system with low-latency fine-tuned models using Amazon SageMaker, Amazon Bedrock, and Amazon Nova Pro</title>
      <link>https://www.dotnetramblings.com/post/11_12_2025/11_12_2025_0/</link>
      <pubDate>Thu, 11 Dec 2025 18:28:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_12_2025/11_12_2025_0/</guid>
      <description>
        
          
            This post walks through how Harmonic Security used Amazon SageMaker AI, Amazon Bedrock, and Amazon Nova Pro to fine-tune a ModernBERT model, achieving low-latency, accurate, and scalable data leakage detection.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-harmonic-security-improved-their-data-leakage-detection-system-with-low-latency-fine-tuned-models-using-amazon-sagemaker-amazon-bedrock-and-amazon-nova-pro/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Swisscom builds enterprise agentic AI for customer support and sales using Amazon Bedrock AgentCore</title>
      <link>https://www.dotnetramblings.com/post/11_12_2025/11_12_2025_1/</link>
      <pubDate>Thu, 11 Dec 2025 18:24:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_12_2025/11_12_2025_1/</guid>
      <description>
        
          
            In this post, we&#39;ll show how Swisscom implemented Amazon Bedrock AgentCore to build and scale their enterprise AI agents for customer support and sales operations. As an early adopter of Amazon Bedrock in the AWS Europe Region (Zurich), Swisscom leads in enterprise AI implementation with their Chatbot Builder system and various AI initiatives. Their successful deployments include Conversational AI powered by Rasa and fine-tuned LLMs on Amazon SageMaker, and the Swisscom Swisscom myAI assistant, built to meet Swiss data protection standards.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Scaling MLflow for enterprise AI: What’s New in SageMaker AI with MLflow</title>
      <link>https://www.dotnetramblings.com/post/11_12_2025/11_12_2025_3/</link>
      <pubDate>Thu, 11 Dec 2025 18:16:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_12_2025/11_12_2025_3/</guid>
      <description>
        
          
            Today we’re announcing Amazon SageMaker AI with MLflow, now including a serverless capability that dynamically manages infrastructure provisioning, scaling, and operations for artificial intelligence and machine learning (AI/ML) development tasks. In this post, we explore how these new capabilities help you run large MLflow workloads—from generative AI agents to large language model (LLM) experimentation—with improved performance, automation, and security using SageMaker AI with MLflow.
Link to article: https://aws.amazon.com/blogs/machine-learning/scaling-mlflow-for-enterprise-ai-whats-new-in-sagemaker-ai-with-mlflow/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock AgentCore Observability with Langfuse</title>
      <link>https://www.dotnetramblings.com/post/11_12_2025/11_12_2025_4/</link>
      <pubDate>Thu, 11 Dec 2025 18:12:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_12_2025/11_12_2025_4/</guid>
      <description>
        
          
            In this post, we explain how to integrate Langfuse observability with Amazon Bedrock AgentCore to gain deep visibility into an AI agent&#39;s performance, debug issues faster, and optimize costs. We walk through a complete implementation using Strands agents deployed on AgentCore Runtime followed by step-by-step code examples.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agentcore-observability-with-langfuse/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implement automated smoke testing using Amazon Nova Act headless mode</title>
      <link>https://www.dotnetramblings.com/post/10_12_2025/10_12_2025_1/</link>
      <pubDate>Wed, 10 Dec 2025 19:04:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_12_2025/10_12_2025_1/</guid>
      <description>
        
          
            This post shows how to implement automated smoke testing using Amazon Nova Act headless mode in CI/CD pipelines. We use SauceDemo, a sample ecommerce application, as our target for demonstration. We demonstrate setting up Amazon Nova Act for headless browser automation in CI/CD environments and creating smoke tests that validate key user workflows. We then show how to implement parallel execution to maximize testing efficiency, configure GitLab CI/CD for automatic test execution on every deployment, and apply best practices for maintainable and scalable test automation.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Real-world reasoning: How Amazon Nova Lite 2.0 handles complex customer support scenarios</title>
      <link>https://www.dotnetramblings.com/post/09_12_2025/09_12_2025_0/</link>
      <pubDate>Tue, 09 Dec 2025 20:50:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_12_2025/09_12_2025_0/</guid>
      <description>
        
          
            This post evaluates the reasoning capabilities of our latest offering in the Nova family, Amazon Nova Lite 2.0, using practical scenarios that test these critical dimensions. We compare its performance against other models in the Nova family—Lite 1.0, Micro, Pro 1.0, and Premier—to elucidate how the latest version advances reasoning quality and consistency.
Link to article: https://aws.amazon.com/blogs/machine-learning/real-world-reasoning-how-amazon-nova-lite-2-0-handles-complex-customer-support-scenarios/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Create AI-powered chat assistants for your enterprise with Amazon Quick Suite</title>
      <link>https://www.dotnetramblings.com/post/09_12_2025/09_12_2025_10/</link>
      <pubDate>Tue, 09 Dec 2025 17:07:22 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_12_2025/09_12_2025_10/</guid>
      <description>
        
          
            In this post, we show how to build chat agents in Amazon Quick Suite. We walk through a three-layer framework—identity, instructions, and knowledge—that transforms Quick Suite chat agents into intelligent enterprise AI assistants. In our example, we demonstrate how our chat agent guides feature discovery, use enterprise data to inform recommendations, and tailors solutions based on potential to impact and your team’s adoption readiness.
Link to article: https://aws.amazon.com/blogs/machine-learning/create-ai-powered-chat-assistants-for-your-enterprise-with-amazon-quick-suite/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
