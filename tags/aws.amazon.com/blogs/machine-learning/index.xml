<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Wed, 23 Apr 2025 16:06:35 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Build an AI-powered document processing platform with open source NER model and LLM on Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/23_04_2025/23_04_2025_2/</link>
      <pubDate>Wed, 23 Apr 2025 16:06:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_04_2025/23_04_2025_2/</guid>
      <description>
        
          
            In this post, we discuss how you can build an AI-powered document processing platform with open source NER and LLMs on SageMaker.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-ai-powered-document-processing-platform-with-open-source-ner-model-and-llm-on-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Protect sensitive data in RAG applications with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/23_04_2025/23_04_2025_3/</link>
      <pubDate>Wed, 23 Apr 2025 16:00:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_04_2025/23_04_2025_3/</guid>
      <description>
        
          
            In this post, we explore two approaches for securing sensitive data in RAG applications using Amazon Bedrock. The first approach focused on identifying and redacting sensitive data before ingestion into an Amazon Bedrock knowledge base, and the second demonstrated a fine-grained RBAC pattern for managing access to sensitive information during retrieval. These solutions represent just two possible approaches among many for securing sensitive data in generative AI applications.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Supercharge your LLM performance with Amazon SageMaker Large Model Inference container v15</title>
      <link>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_0/</link>
      <pubDate>Tue, 22 Apr 2025 17:28:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_0/</guid>
      <description>
        
          
            Today, we’re excited to announce the launch of Amazon SageMaker Large Model Inference (LMI) container v15, powered by vLLM 0.8.4 with support for the vLLM V1 engine. This release introduces significant performance improvements, expanded model compatibility with multimodality (that is, the ability to understand and analyze text-to-text, images-to-text, and text-to-images data), and provides built-in integration with vLLM to help you seamlessly deploy and serve large language models (LLMs) with the highest performance at scale.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accuracy evaluation framework for Amazon Q Business – Part 2</title>
      <link>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_1/</link>
      <pubDate>Tue, 22 Apr 2025 17:18:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_1/</guid>
      <description>
        
          
            In the first post of this series, we introduced a comprehensive evaluation framework for Amazon Q Business, a fully managed Retrieval Augmented Generation (RAG) solution that uses your company’s proprietary data without the complexity of managing large language models (LLMs). The first post focused on selecting appropriate use cases, preparing data, and implementing metrics to […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accuracy-evaluation-framework-for-amazon-q-business-part-2/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use Amazon Bedrock Intelligent Prompt Routing for cost and latency benefits</title>
      <link>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_2/</link>
      <pubDate>Tue, 22 Apr 2025 17:15:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_2/</guid>
      <description>
        
          
            Today, we’re happy to announce the general availability of Amazon Bedrock Intelligent Prompt Routing. In this blog post, we detail various highlights from our internal testing, how you can get started, and point out some caveats and best practices. We encourage you to incorporate Amazon Bedrock Intelligent Prompt Routing into your new and existing generative AI applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/use-amazon-bedrock-intelligent-prompt-routing-for-cost-and-latency-benefits/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Infosys improved accessibility for Event Knowledge using Amazon Nova Pro, Amazon Bedrock and Amazon Elemental Media Services</title>
      <link>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_3/</link>
      <pubDate>Tue, 22 Apr 2025 17:12:46 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_3/</guid>
      <description>
        
          
            In this post, we explore how Infosys developed Infosys Event AI to unlock the insights generated from events and conferences. Through its suite of features—including real-time transcription, intelligent summaries, and an interactive chat assistant—Infosys Event AI makes event knowledge accessible and provides an immersive engagement solution for the attendees, during and after the event.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-infosys-improved-accessibility-for-event-knowledge-using-amazon-nova-pro-amazon-bedrock-and-amazon-elemental-media-services/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock Prompt Optimization Drives LLM Applications Innovation for Yuewen Group</title>
      <link>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_0/</link>
      <pubDate>Mon, 21 Apr 2025 22:57:14 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_0/</guid>
      <description>
        
          
            Today, we are excited to announce the availability of Prompt Optimization on Amazon Bedrock. With this capability, you can now optimize your prompts for several use cases with a single API call or a click of a button on the Amazon Bedrock console. In this blog post, we discuss how Prompt Optimization improves the performance of large language models (LLMs) for intelligent text processing task in Yuewen Group.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a location-aware agent using Amazon Bedrock Agents and Foursquare APIs</title>
      <link>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_3/</link>
      <pubDate>Mon, 21 Apr 2025 18:45:27 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_3/</guid>
      <description>
        
          
            In this post, we combine Amazon Bedrock Agents and Foursquare APIs to demonstrate how you can use a location-aware agent to bring personalized responses to your users.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-location-aware-agent-using-amazon-bedrock-agents-and-foursquare-apis/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an automated generative AI solution evaluation pipeline with Amazon Nova</title>
      <link>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_5/</link>
      <pubDate>Mon, 21 Apr 2025 17:16:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_5/</guid>
      <description>
        
          
            In this post, we explore the importance of evaluating LLMs in the context of generative AI applications, highlighting the challenges posed by issues like hallucinations and biases. We introduced a comprehensive solution using AWS services to automate the evaluation process, allowing for continuous monitoring and assessment of LLM performance. By using tools like the FMeval Library, Ragas, LLMeter, and Step Functions, the solution provides flexibility and scalability, meeting the evolving needs of LLM consumers.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a FinOps agent using Amazon Bedrock with multi-agent capability and Amazon Nova as the foundation model</title>
      <link>https://www.dotnetramblings.com/post/18_04_2025/18_04_2025_2/</link>
      <pubDate>Fri, 18 Apr 2025 17:38:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_04_2025/18_04_2025_2/</guid>
      <description>
        
          
            In this post, we use the multi-agent feature of Amazon Bedrock to demonstrate a powerful and innovative approach to AWS cost management. By using the advanced capabilities of Amazon Nova FMs, we’ve developed a solution that showcases how AI-driven agents can revolutionize the way organizations analyze, optimize, and manage their AWS costs.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-finops-agent-using-amazon-bedrock-with-multi-agent-capability-and-amazon-nova-as-the-foundation-model/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Stream ingest data from Kafka to Amazon Bedrock Knowledge Bases using custom connectors</title>
      <link>https://www.dotnetramblings.com/post/18_04_2025/18_04_2025_3/</link>
      <pubDate>Fri, 18 Apr 2025 17:21:58 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_04_2025/18_04_2025_3/</guid>
      <description>
        
          
            For this post, we implement a RAG architecture with Amazon Bedrock Knowledge Bases using a custom connector and topics built with Amazon Managed Streaming for Apache Kafka (Amazon MSK) for a user who may be interested to understand stock price trends.
Link to article: https://aws.amazon.com/blogs/machine-learning/stream-ingest-data-from-kafka-to-amazon-bedrock-knowledge-bases-using-custom-connectors/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Add Zoom as a data accessor to your Amazon Q index</title>
      <link>https://www.dotnetramblings.com/post/17_04_2025/17_04_2025_2/</link>
      <pubDate>Thu, 17 Apr 2025 18:19:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_04_2025/17_04_2025_2/</guid>
      <description>
        
          
            This post demonstrates how Zoom users can access their Amazon Q Business enterprise data directly within their Zoom interface, alleviating the need to switch between applications while maintaining enterprise security boundaries. Organizations can now configure Zoom as a data accessor in Amazon Q Business, enabling seamless integration between their Amazon Q index and Zoom AI Companion. This integration allows users to access their enterprise knowledge in a controlled manner directly within the Zoom platform.
          
          
        
      </description>
    </item>
    
    <item>
      <title>The future of quality assurance: Shift-left testing with QyrusAI and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/17_04_2025/17_04_2025_4/</link>
      <pubDate>Thu, 17 Apr 2025 16:50:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_04_2025/17_04_2025_4/</guid>
      <description>
        
          
            In this post, we explore how QyrusAI and Amazon Bedrock are revolutionizing shift-left testing, enabling teams to deliver better software faster. Amazon Bedrock is a fully managed service that allows businesses to build and scale generative AI applications using foundation models (FMs) from leading AI providers. It enables seamless integration with AWS services, offering customization, security, and scalability without managing infrastructure.
Link to article: https://aws.amazon.com/blogs/machine-learning/the-future-of-quality-assurance-shift-left-testing-with-qyrusai-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate video insights for contextual advertising using Amazon Bedrock Data Automation</title>
      <link>https://www.dotnetramblings.com/post/17_04_2025/17_04_2025_5/</link>
      <pubDate>Thu, 17 Apr 2025 16:47:45 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_04_2025/17_04_2025_5/</guid>
      <description>
        
          
            Amazon Bedrock Data Automation (BDA) is a new managed feature powered by FMs in Amazon Bedrock. BDA extracts structured outputs from unstructured content—including documents, images, video, and audio—while alleviating the need for complex custom workflows. In this post, we demonstrate how BDA automatically extracts rich video insights such as chapter segments and audio segments, detects text in scenes, and classifies Interactive Advertising Bureau (IAB) taxonomies, and then uses these insights to build a nonlinear ads solution to enhance contextual advertising effectiveness.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Salesforce achieves high-performance model deployment with Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/17_04_2025/17_04_2025_6/</link>
      <pubDate>Thu, 17 Apr 2025 16:42:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_04_2025/17_04_2025_6/</guid>
      <description>
        
          
            This post is a joint collaboration between Salesforce and AWS and is being cross-published on both the Salesforce Engineering Blog and the AWS Machine Learning Blog. The Salesforce AI Model Serving team is working to push the boundaries of natural language processing and AI capabilities for enterprise applications. Their key focus areas include optimizing large […]
Link to article: https://aws.amazon.com/blogs/machine-learning/how-salesforce-achieves-high-performance-model-deployment-with-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate Amazon EKS troubleshooting using an Amazon Bedrock agentic workflow</title>
      <link>https://www.dotnetramblings.com/post/16_04_2025/16_04_2025_1/</link>
      <pubDate>Wed, 16 Apr 2025 20:13:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_04_2025/16_04_2025_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to orchestrate multiple Amazon Bedrock agents to create a sophisticated Amazon EKS troubleshooting system. By enabling collaboration between specialized agents—deriving insights from K8sGPT and performing actions through the ArgoCD framework—you can build a comprehensive automation that identifies, analyzes, and resolves cluster issues with minimal human intervention.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-amazon-eks-troubleshooting-using-an-amazon-bedrock-agentic-workflow/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Host concurrent LLMs with LoRAX</title>
      <link>https://www.dotnetramblings.com/post/16_04_2025/16_04_2025_3/</link>
      <pubDate>Wed, 16 Apr 2025 19:53:20 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_04_2025/16_04_2025_3/</guid>
      <description>
        
          
            In this post, we explore how Low-Rank Adaptation (LoRA) can be used to address these challenges effectively. Specifically, we discuss using LoRA serving with LoRA eXchange (LoRAX) and Amazon Elastic Compute Cloud (Amazon EC2) GPU instances, allowing organizations to efficiently manage and serve their growing portfolio of fine-tuned models, optimize costs, and provide seamless performance for their customers.
Link to article: https://aws.amazon.com/blogs/machine-learning/host-concurrent-llms-with-lorax/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a computer vision-based asset inventory application with low or no training</title>
      <link>https://www.dotnetramblings.com/post/16_04_2025/16_04_2025_4/</link>
      <pubDate>Wed, 16 Apr 2025 19:49:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_04_2025/16_04_2025_4/</guid>
      <description>
        
          
            In this post, we present a solution using generative AI and large language models (LLMs) to alleviate the time-consuming and labor-intensive tasks required to build a computer vision application, enabling you to immediately start taking pictures of your asset labels and extract the necessary information to update the inventory using AWS services
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-computer-vision-based-asset-inventory-application-with-low-or-no-training/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
