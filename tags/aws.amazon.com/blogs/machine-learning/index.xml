<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Wed, 24 Jul 2024 20:14:49 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mistral Large 2 is now available in Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_1/</link>
      <pubDate>Wed, 24 Jul 2024 20:14:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_1/</guid>
      <description>
        
          
            Mistral AI’s Mistral Large 2 (24.07) foundation model (FM) is now generally available in Amazon Bedrock. Mistral Large 2 is the newest version of Mistral Large, and according to Mistral AI offers significant improvements across multilingual capabilities, math, reasoning, coding, and much more. In this post, we discuss the benefits and capabilities of this new […]
Link to article: https://aws.amazon.com/blogs/machine-learning/mistral-large-2-is-now-available-in-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>LLM experimentation at scale using Amazon SageMaker Pipelines and MLflow</title>
      <link>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_2/</link>
      <pubDate>Wed, 24 Jul 2024 19:01:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_2/</guid>
      <description>
        
          
            Large language models (LLMs) have achieved remarkable success in various natural language processing (NLP) tasks, but they may not always generalize well to specific domains or tasks. You may need to customize an LLM to adapt to your unique use case, improving its performance on your specific dataset or task. You can customize the model […]
Link to article: https://aws.amazon.com/blogs/machine-learning/llm-experimentation-at-scale-using-amazon-sagemaker-pipelines-and-mlflow/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Discover insights from Amazon S3 with Amazon Q S3 connector</title>
      <link>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_3/</link>
      <pubDate>Wed, 24 Jul 2024 18:53:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_3/</guid>
      <description>
        
          
            Amazon Q is a fully managed, generative artificial intelligence (AI) powered assistant that you can configure to answer questions, provide summaries, generate content, gain insights, and complete tasks based on data in your enterprise. The enterprise data required for these generative-AI powered assistants can reside in varied repositories across your organization. One common repository to […]
Link to article: https://aws.amazon.com/blogs/machine-learning/discover-insights-from-amazon-s3-with-amazon-q-s3-connector/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Boosting Salesforce Einstein’s code generating model performance with Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_5/</link>
      <pubDate>Wed, 24 Jul 2024 16:52:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_5/</guid>
      <description>
        
          
            This post is a joint collaboration between Salesforce and AWS and is being cross-published on both the Salesforce Engineering Blog and the AWS Machine Learning Blog. Salesforce, Inc. is an American cloud-based software company headquartered in San Francisco, California. It provides customer relationship management (CRM) software and applications focused on sales, customer service, marketing automation, […]
Link to article: https://aws.amazon.com/blogs/machine-learning/boosting-salesforce-einsteins-code-generating-model-performance-with-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Detect and protect sensitive data with Amazon Lex and Amazon CloudWatch Logs</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_2/</link>
      <pubDate>Tue, 23 Jul 2024 20:01:37 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_2/</guid>
      <description>
        
          
            In today’s digital landscape, the protection of personally identifiable information (PII) is not just a regulatory requirement, but a cornerstone of consumer trust and business integrity. Organizations use advanced natural language detection services like Amazon Lex for building conversational interfaces and Amazon CloudWatch for monitoring and analyzing operational data. One risk many organizations face is […]
Link to article: https://aws.amazon.com/blogs/machine-learning/detect-and-protect-sensitive-data-with-amazon-lex-and-amazon-cloudwatch-logs/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS AI chips deliver high performance and low cost for Llama 3.1 models on AWS</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_7/</link>
      <pubDate>Tue, 23 Jul 2024 16:18:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_7/</guid>
      <description>
        
          
            Today, we are excited to announce AWS Trainium and AWS Inferentia support for fine-tuning and inference of the Llama 3.1 models. The Llama 3.1 family of multilingual large language models (LLMs) is a collection of pre-trained and instruction tuned generative models in 8B, 70B, and 405B sizes. In a previous post, we covered how to deploy Llama 3 models on AWS Trainium and Inferentia based instances in Amazon SageMaker JumpStart. In this post, we outline how to get started with fine-tuning and deploying the Llama 3.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use Llama 3.1 405B to generate synthetic data for fine-tuning tasks</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_8/</link>
      <pubDate>Tue, 23 Jul 2024 16:18:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_8/</guid>
      <description>
        
          
            Today, we are excited to announce the availability of the Llama 3.1 405B model on Amazon SageMaker JumpStart, and Amazon Bedrock in preview. The Llama 3.1 models are a collection of state-of-the-art pre-trained and instruct fine-tuned generative artificial intelligence (AI) models in 8B, 70B, and 405B sizes. Amazon SageMaker JumpStart is a machine learning (ML) hub that provides access to algorithms, models, and ML solutions so you can quickly get started with ML.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Llama 3.1 models are now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_9/</link>
      <pubDate>Tue, 23 Jul 2024 16:16:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_9/</guid>
      <description>
        
          
            Today, we are excited to announce that the state-of-the-art Llama 3.1 collection of multilingual large language models (LLMs), which includes pre-trained and instruction tuned generative AI models in 8B, 70B, and 405B sizes, is available through Amazon SageMaker JumpStart to deploy for inference. Llama is a publicly accessible LLM designed for developers, researchers, and businesses to build, experiment, and responsibly scale their generative artificial intelligence (AI) ideas. In this post, we walk through how to discover and deploy Llama 3.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Intelligent document processing using Amazon Bedrock and Anthropic Claude</title>
      <link>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_1/</link>
      <pubDate>Thu, 18 Jul 2024 18:21:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_1/</guid>
      <description>
        
          
            In this post, we show how to develop an IDP solution using Anthropic Claude 3 Sonnet on Amazon Bedrock. We demonstrate how to extract data from a scanned document and insert it into a database.
Link to article: https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-using-amazon-bedrock-and-anthropic-claude/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Metadata filtering for tabular data with Knowledge Bases for Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_2/</link>
      <pubDate>Thu, 18 Jul 2024 18:19:38 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_2/</guid>
      <description>
        
          
            Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading artificial intelligence (AI) companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon through a single API. To equip FMs with up-to-date and proprietary information, organizations use Retrieval Augmented Generation (RAG), a technique that […]
Link to article: https://aws.amazon.com/blogs/machine-learning/metadata-filtering-for-tabular-data-with-knowledge-bases-for-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Secure AccountantAI Chatbot: Lili’s journey with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_7/</link>
      <pubDate>Thu, 18 Jul 2024 16:20:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_7/</guid>
      <description>
        
          
            This post was written in collaboration with Liran Zelkha and Eyal Solnik from Lili. Small business proprietors tend to prioritize the operational aspects of their enterprises over administrative tasks, such as maintaining financial records and accounting. While hiring a professional accountant can provide valuable guidance and expertise, it can be cost-prohibitive for many small businesses. […]
Link to article: https://aws.amazon.com/blogs/machine-learning/secure-accountantai-chatbot-lilis-journey-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Mend.io unlocked hidden patterns in CVE data with Anthropic Claude on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_8/</link>
      <pubDate>Thu, 18 Jul 2024 16:14:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_07_2024/18_07_2024_8/</guid>
      <description>
        
          
            This post is co-written with Maciej Mensfeld from Mend.io. In the ever-evolving landscape of cybersecurity, the ability to effectively analyze and categorize Common Vulnerabilities and Exposures (CVEs) is crucial. This post explores how Mend.io, a cybersecurity firm, used Anthropic Claude on Amazon Bedrock to classify and identify CVEs containing specific attack requirements details. By using […]
Link to article: https://aws.amazon.com/blogs/machine-learning/how-mend-io-unlocked-hidden-patterns-in-cve-data-with-anthropic-claude-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
