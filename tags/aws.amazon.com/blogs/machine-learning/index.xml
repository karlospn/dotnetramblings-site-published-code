<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Wed, 26 Nov 2025 19:50:03 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Optimizing Mobileye’s REM™ with AWS Graviton: A focus on ML inference and Triton integration</title>
      <link>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_1/</link>
      <pubDate>Wed, 26 Nov 2025 19:50:03 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_1/</guid>
      <description>
        
          
            This post is written by Chaim Rand, Principal Engineer, Pini Reisman, Software Senior Principal Engineer, and Eliyah Weinberg, Performance and Technology Innovation Engineer, at Mobileye. The Mobileye team would like to thank Sunita Nadampalli and Guy Almog from AWS for their contributions to this solution and this post. Mobileye is driving the global evolution toward […]
Link to article: https://aws.amazon.com/blogs/machine-learning/optimizing-mobileyes-rem-with-aws-graviton-a-focus-on-ml-inference-and-triton-integration/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluate models with the Amazon Nova evaluation container using Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_2/</link>
      <pubDate>Wed, 26 Nov 2025 19:39:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_2/</guid>
      <description>
        
          
            This blog post introduces the new Amazon Nova model evaluation features in Amazon SageMaker AI. This release adds custom metrics support, LLM-based preference testing, log probability capture, metadata analysis, and multi-node scaling for large evaluations.
Link to article: https://aws.amazon.com/blogs/machine-learning/evaluate-models-with-the-amazon-nova-evaluation-container-using-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Beyond the technology: Workforce changes for AI</title>
      <link>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_3/</link>
      <pubDate>Wed, 26 Nov 2025 18:42:45 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_3/</guid>
      <description>
        
          
            In this post, we explore three essential strategies for successfully integrating AI into your organization: addressing organizational debt before it compounds, embracing distributed decision-making through the &amp;quot;octopus organization&amp;quot; model, and redefining management roles to align with AI-powered workflows. Organizations must invest in both technology and workforce preparation, focusing on streamlining processes, empowering teams with autonomous decision-making within defined parameters, and evolving each management layer from traditional oversight to mentorship, quality assurance, and strategic vision-setting.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhanced performance for Amazon Bedrock Custom Model Import</title>
      <link>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_6/</link>
      <pubDate>Wed, 26 Nov 2025 16:46:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_6/</guid>
      <description>
        
          
            You can now achieve significant performance improvements when using Amazon Bedrock Custom Model Import, with reduced end-to-end latency, faster time-to-first-token, and improved throughput through advanced PyTorch compilation and CUDA graph optimizations. With Amazon Bedrock Custom Model Import you can to bring your own foundation models to Amazon Bedrock for deployment and inference at scale. In this post, we introduce how to use the improvements in Amazon Bedrock Custom Model Import.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon SageMaker AI introduces EAGLE based adaptive speculative decoding to accelerate generative AI inference</title>
      <link>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_12/</link>
      <pubDate>Wed, 26 Nov 2025 00:29:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_11_2025/26_11_2025_12/</guid>
      <description>
        
          
            Amazon SageMaker AI now supports EAGLE-based adaptive speculative decoding, a technique that accelerates large language model inference by up to 2.5x while maintaining output quality. In this post, we explain how to use EAGLE 2 and EAGLE 3 speculative decoding in Amazon SageMaker AI, covering the solution architecture, optimization workflows using your own datasets or SageMaker&#39;s built-in data, and benchmark results demonstrating significant improvements in throughput and latency.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Train custom computer vision defect detection model using Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_2/</link>
      <pubDate>Tue, 25 Nov 2025 22:44:22 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to migrate computer vision workloads from Amazon Lookout for Vision to Amazon SageMaker AI by training custom defect detection models using pre-trained models available on AWS Marketplace. We provide step-by-step guidance on labeling datasets with SageMaker Ground Truth, training models with flexible hyperparameter configurations, and deploying them for real-time or batch inference—giving you greater control and flexibility for automated quality inspection use cases.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Practical implementation considerations to close the AI value gap</title>
      <link>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_5/</link>
      <pubDate>Tue, 25 Nov 2025 20:19:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_5/</guid>
      <description>
        
          
            The AWS Customer Success Center of Excellence (CS COE) helps customers get tangible value from their AWS investments. We&#39;ve seen a pattern: customers who build AI strategies that address people, process, and technology together succeed more often. In this post, we share practical considerations that can help close the AI value gap.
Link to article: https://aws.amazon.com/blogs/machine-learning/practical-implementation-considerations-to-close-the-ai-value-gap/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Introducing bidirectional streaming for real-time inference on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_6/</link>
      <pubDate>Tue, 25 Nov 2025 19:09:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_6/</guid>
      <description>
        
          
            We&#39;re introducing bidirectional streaming for Amazon SageMaker AI Inference, which transforms inference from a transactional exchange into a continuous conversation. This post shows you how to build and deploy a container with bidirectional streaming capability to a SageMaker AI endpoint. We also demonstrate how you can bring your own container or use our partner Deepgram&#39;s pre-built models and containers on SageMaker AI to enable bi-directional streaming feature for real-time inference.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Warner Bros. Discovery achieves 60% cost savings and faster ML inference with AWS Graviton</title>
      <link>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_7/</link>
      <pubDate>Tue, 25 Nov 2025 17:26:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_7/</guid>
      <description>
        
          
            Warner Bros. Discovery (WBD) is a leading global media and entertainment company that creates and distributes the world’s most differentiated and complete portfolio of content and brands across television, film and streaming. In this post, we describe the scale of our offerings, artificial intelligence (AI)/machine learning (ML) inference infrastructure requirements for our real time recommender systems, and how we used AWS Graviton-based Amazon SageMaker AI instances for our ML inference workloads and achieved 60% cost savings and 7% to 60% latency improvements across different models.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Physical AI in practice: Technical foundations that fuel human-machine interactions</title>
      <link>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_8/</link>
      <pubDate>Tue, 25 Nov 2025 17:00:25 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_8/</guid>
      <description>
        
          
            In this post, we explore the complete development lifecycle of physical AI—from data collection and model training to edge deployment—and examine how these intelligent systems learn to understand, reason, and interact with the physical world through continuous feedback loops. We illustrate this workflow through Diligent Robotics&#39; Moxi, a mobile manipulation robot that has completed over 1.2 million deliveries in hospitals, saving nearly 600,000 hours for clinical staff while transforming healthcare logistics and returning valuable time to patient care.
          
          
        
      </description>
    </item>
    
    <item>
      <title>HyperPod now supports Multi-Instance GPU to maximize GPU utilization for generative AI tasks</title>
      <link>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_9/</link>
      <pubDate>Tue, 25 Nov 2025 16:10:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_11_2025/25_11_2025_9/</guid>
      <description>
        
          
            In this post, we explore how Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG) technology, enabling you to partition powerful GPUs into multiple isolated instances for running concurrent workloads like inference, research, and interactive development. By maximizing GPU utilization and reducing wasted resources, MIG helps organizations optimize costs while maintaining performance isolation and predictable quality of service across diverse machine learning tasks.
Link to article: https://aws.amazon.com/blogs/machine-learning/hyperpod-now-supports-multi-instance-gpu-to-maximize-gpu-utilization-for-generative-ai-tasks/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Power up your ML workflows with interactive IDEs on SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/24_11_2025/24_11_2025_1/</link>
      <pubDate>Mon, 24 Nov 2025 21:25:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_11_2025/24_11_2025_1/</guid>
      <description>
        
          
            Amazon SageMaker HyperPod clusters with Amazon Elastic Kubernetes Service (EKS) orchestration now support creating and managing interactive development environments such as JupyterLab and open source Visual Studio Code, streamlining the ML development lifecycle by providing managed environments for familiar tools to data scientists. This post shows how HyperPod administrators can configure Spaces for their clusters, and how data scientists can create and connect to these Spaces.
Link to article: https://aws.amazon.com/blogs/machine-learning/power-up-your-ml-workflows-with-interactive-ides-on-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Claude Opus 4.5 now in Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/24_11_2025/24_11_2025_3/</link>
      <pubDate>Mon, 24 Nov 2025 19:22:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_11_2025/24_11_2025_3/</guid>
      <description>
        
          
            Anthropic&#39;s newest foundation model, Claude Opus 4.5, is now available in Amazon Bedrock, a fully managed service that offers a choice of high-performing foundation models from leading AI companies. In this post, I&#39;ll show you what makes this model different, walk through key business applications, and demonstrate how to use Opus 4.5&#39;s new tool use capabilities on Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/claude-opus-4-5-now-in-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deploy GPT-OSS models with Amazon Bedrock Custom Model Import</title>
      <link>https://www.dotnetramblings.com/post/24_11_2025/24_11_2025_4/</link>
      <pubDate>Mon, 24 Nov 2025 17:49:05 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_11_2025/24_11_2025_4/</guid>
      <description>
        
          
            In this post, we show how to deploy the GPT-OSS-20B model on Amazon Bedrock using Custom Model Import while maintaining complete API compatibility with your current applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/deploy-gpt-oss-models-with-amazon-bedrock-custom-model-import/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline AI operations with the Multi-Provider Generative AI Gateway reference architecture</title>
      <link>https://www.dotnetramblings.com/post/21_11_2025/21_11_2025_1/</link>
      <pubDate>Fri, 21 Nov 2025 20:34:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_11_2025/21_11_2025_1/</guid>
      <description>
        
          
            In this post, we introduce the Multi-Provider Generative AI Gateway reference architecture, which provides guidance for deploying LiteLLM into an AWS environment to streamline the management and governance of production generative AI workloads across multiple model providers. This centralized gateway solution addresses common enterprise challenges including provider fragmentation, decentralized governance, operational complexity, and cost management by offering a unified interface that supports Amazon Bedrock, Amazon SageMaker AI, and external providers while maintaining comprehensive security, monitoring, and control capabilities.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deploy geospatial agents with Foursquare Spatial H3 Hub and Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/21_11_2025/21_11_2025_5/</link>
      <pubDate>Fri, 21 Nov 2025 17:15:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_11_2025/21_11_2025_5/</guid>
      <description>
        
          
            In this post, you&#39;ll learn how to deploy geospatial AI agents that can answer complex spatial questions in minutes instead of months. By combining Foursquare Spatial H3 Hub&#39;s analysis-ready geospatial data with reasoning models deployed on Amazon SageMaker AI, you can build agents that enable nontechnical domain experts to perform sophisticated spatial analysis through natural language queries—without requiring geographic information system (GIS) expertise or custom data engineering pipelines.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Wipro PARI accelerates PLC code generation using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/21_11_2025/21_11_2025_6/</link>
      <pubDate>Fri, 21 Nov 2025 16:10:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_11_2025/21_11_2025_6/</guid>
      <description>
        
          
            In this post, we share how Wipro implemented advanced prompt engineering techniques, custom validation logic, and automated code rectification to streamline the development of industrial automation code at scale using Amazon Bedrock. We walk through the architecture along with the key use cases, explain core components and workflows, and share real-world results that show the transformative impact on manufacturing operations.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-wipro-pari-accelerates-plc-code-generation-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>MSD explores applying generative Al to improve the deviation management process using AWS services</title>
      <link>https://www.dotnetramblings.com/post/20_11_2025/20_11_2025_2/</link>
      <pubDate>Thu, 20 Nov 2025 18:21:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_11_2025/20_11_2025_2/</guid>
      <description>
        
          
            This blog post has explores how MSD is harnessing the power of generative AI and databases to optimize and transform its manufacturing deviation management process. By creating an accurate and multifaceted knowledge base of past events, deviations, and findings, the company aims to significantly reduce the time and effort required for each new case while maintaining the highest standards of quality and compliance.
Link to article: https://aws.amazon.com/blogs/machine-learning/msd-explores-applying-generative-al-to-improve-the-deviation-management-process-using-aws-services/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerating genomics variant interpretation with AWS HealthOmics and Amazon Bedrock AgentCore</title>
      <link>https://www.dotnetramblings.com/post/20_11_2025/20_11_2025_3/</link>
      <pubDate>Thu, 20 Nov 2025 18:18:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_11_2025/20_11_2025_3/</guid>
      <description>
        
          
            In this blog post, we show you how agentic workflows can accelerate the processing and interpretation of genomics pipelines at scale with a natural language interface. We demonstrate a comprehensive genomic variant interpreter agent that combines automated data processing with intelligent analysis to address the entire workflow from raw VCF file ingestion to conversational query interfaces.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerating-genomics-variant-interpretation-with-aws-healthomics-and-amazon-bedrock-agentcore/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Rufus scales conversational shopping experiences to millions of Amazon customers with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/20_11_2025/20_11_2025_4/</link>
      <pubDate>Thu, 20 Nov 2025 18:13:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_11_2025/20_11_2025_4/</guid>
      <description>
        
          
            Our team at Amazon builds Rufus, an AI-powered shopping assistant which delivers intelligent, conversational experiences to delight our customers. More than 250 million customers have used Rufus this year. Monthly users are up 140% YoY and interactions are up 210% YoY. Additionally, customers that use Rufus during a shopping journey are 60% more likely to […]
Link to article: https://aws.amazon.com/blogs/machine-learning/how-rufus-scales-conversational-shopping-experiences-to-millions-of-amazon-customers-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Care Access achieved 86% data processing cost reductions and 66% faster data processing with Amazon Bedrock prompt caching</title>
      <link>https://www.dotnetramblings.com/post/20_11_2025/20_11_2025_11/</link>
      <pubDate>Thu, 20 Nov 2025 16:15:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_11_2025/20_11_2025_11/</guid>
      <description>
        
          
            In this post, we demonstrate how healthcare organizations can securely implement prompt caching technology to streamline medical record processing while maintaining compliance requirements.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-care-access-achieved-86-data-processing-cost-reductions-and-66-faster-data-processing-with-amazon-bedrock-prompt-caching/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock Guardrails expands support for code domain</title>
      <link>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_0/</link>
      <pubDate>Wed, 19 Nov 2025 22:27:14 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_0/</guid>
      <description>
        
          
            Amazon Bedrock Guardrails now extends its safety controls to protect code generation across twelve programming languages, addressing critical security challenges in AI-assisted software development. In this post, we explore how to configure content filters, prompt attack detection, denied topics, and sensitive information filters to safeguard against threats like prompt injection, data exfiltration, and malicious code generation while maintaining developer productivity .
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-guardrails-expands-support-for-code-domain/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Announcing the AWS Well-Architected Responsible AI Lens</title>
      <link>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_1/</link>
      <pubDate>Wed, 19 Nov 2025 20:03:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_1/</guid>
      <description>
        
          
            Today, we&#39;re announcing the AWS Well-Architected Responsible AI Lens—a set of thoughtful questions and corresponding best practices that help builders address responsible AI concerns throughout development and operation.
Link to article: https://aws.amazon.com/blogs/machine-learning/announcing-the-aws-well-architected-responsible-ai-lens/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Amazon uses AI agents to support compliance screening of billions of transactions per day</title>
      <link>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_2/</link>
      <pubDate>Wed, 19 Nov 2025 19:39:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_2/</guid>
      <description>
        
          
            Amazon&#39;s AI-powered Amazon Compliance Screening system tackles complex compliance challenges through autonomous agents that analyze, reason through, and resolve cases with precision. This blog post explores how Amazon’s Compliance team built its AI-powered investigation system through a series of AI agents built on AWS.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-amazon-uses-ai-agents-to-support-compliance-screening-of-billions-of-transactions-per-day/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an agentic solution with Amazon Nova, Snowflake, and LangGraph</title>
      <link>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_8/</link>
      <pubDate>Wed, 19 Nov 2025 16:16:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_8/</guid>
      <description>
        
          
            In this post, we cover how you can use tools from Snowflake AI Data Cloud and Amazon Web Services (AWS) to build generative AI solutions that organizations can use to make data-driven decisions, increase operational efficiency, and ultimately gain a competitive edge.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-agentic-solution-with-amazon-nova-snowflake-and-langgraph/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Using Spectrum fine-tuning to improve FM training efficiency on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_10/</link>
      <pubDate>Wed, 19 Nov 2025 15:51:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2025/19_11_2025_10/</guid>
      <description>
        
          
            In this post you will learn how to use Spectrum to optimize resource use and shorten training times without sacrificing quality, as well as how to implement Spectrum fine-tuning with Amazon SageMaker AI training jobs. We will also discuss the tradeoff between QLoRA and Spectrum fine-tuning, showing that while QLoRA is more resource efficient, Spectrum results in higher performance overall.
Link to article: https://aws.amazon.com/blogs/machine-learning/using-spectrum-fine-tuning-to-improve-fm-training-efficiency-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
