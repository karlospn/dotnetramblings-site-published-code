<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 10 Jun 2025 16:19:09 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Automate customer support with Amazon Bedrock, LangGraph, and Mistral models</title>
      <link>https://www.dotnetramblings.com/post/10_06_2025/10_06_2025_2/</link>
      <pubDate>Tue, 10 Jun 2025 16:19:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_06_2025/10_06_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to use Amazon Bedrock and LangGraph to build a personalized customer support experience for an ecommerce retailer. By integrating the Mistral Large 2 and Pixtral Large models, we guide you through automating key customer support workflows such as ticket categorization, order details extraction, damage assessment, and generating contextual responses.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-customer-support-with-amazon-bedrock-langgraph-and-mistral-models/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build responsible AI applications with Amazon Bedrock Guardrails</title>
      <link>https://www.dotnetramblings.com/post/10_06_2025/10_06_2025_3/</link>
      <pubDate>Tue, 10 Jun 2025 16:16:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_06_2025/10_06_2025_3/</guid>
      <description>
        
          
            In this post, we demonstrate how Amazon Bedrock Guardrails helps block harmful and undesirable multimodal content. Using a healthcare insurance call center scenario, we walk through the process of configuring and testing various guardrails.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-responsible-ai-applications-with-amazon-bedrock-guardrails/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Effective cost optimization strategies for Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/10_06_2025/10_06_2025_4/</link>
      <pubDate>Tue, 10 Jun 2025 16:13:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_06_2025/10_06_2025_4/</guid>
      <description>
        
          
            With the increasing adoption of Amazon Bedrock, optimizing costs is a must to help keep the expenses associated with deploying and running generative AI applications manageable and aligned with your organization’s budget. In this post, you’ll learn about strategic cost optimization techniques while using Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/effective-cost-optimization-strategies-for-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How E.ON saves £10 million annually with AI diagnostics for smart meters powered by Amazon Textract</title>
      <link>https://www.dotnetramblings.com/post/10_06_2025/10_06_2025_5/</link>
      <pubDate>Tue, 10 Jun 2025 16:11:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_06_2025/10_06_2025_5/</guid>
      <description>
        
          
            E.ON’s story highlights how a creative application of Amazon Textract, combined with custom image analysis and pulse counting, can solve a real-world challenge at scale. By diagnosing smart meter errors through brief smartphone videos, E.ON aims to lower costs, improve customer satisfaction, and enhance overall energy service reliability. In this post, we dive into how this solution works and the impact it’s making.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-e-on-saves-10-million-annually-with-ai-diagnostics-for-smart-meters-powered-by-amazon-textract/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building intelligent AI voice agents with Pipecat and Amazon Bedrock – Part 1</title>
      <link>https://www.dotnetramblings.com/post/09_06_2025/09_06_2025_1/</link>
      <pubDate>Mon, 09 Jun 2025 15:50:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_06_2025/09_06_2025_1/</guid>
      <description>
        
          
            In this series of posts, you will learn how to build intelligent AI voice agents using Pipecat, an open-source framework for voice and multimodal conversational AI agents, with foundation models on Amazon Bedrock. It includes high-level reference architectures, best practices and code samples to guide your implementation.
Link to article: https://aws.amazon.com/blogs/machine-learning/building-intelligent-ai-voice-agents-with-pipecat-and-amazon-bedrock-part-1/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Stream multi-channel audio to Amazon Transcribe using the Web Audio API</title>
      <link>https://www.dotnetramblings.com/post/09_06_2025/09_06_2025_2/</link>
      <pubDate>Mon, 09 Jun 2025 15:47:17 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_06_2025/09_06_2025_2/</guid>
      <description>
        
          
            In this post, we explore the implementation details of a web application that uses the browser’s Web Audio API and Amazon Transcribe streaming to enable real-time dual-channel transcription. By using the combination of AudioContext, ChannelMergerNode, and AudioWorklet, we were able to seamlessly process and encode the audio data from two microphones before sending it to Amazon Transcribe for transcription.
Link to article: https://aws.amazon.com/blogs/machine-learning/stream-multi-channel-audio-to-amazon-transcribe-using-the-web-audio-api/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Kepler democratized AI access and enhanced client services with Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/09_06_2025/09_06_2025_3/</link>
      <pubDate>Mon, 09 Jun 2025 15:39:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_06_2025/09_06_2025_3/</guid>
      <description>
        
          
            At Kepler, a global full-service digital marketing agency serving Fortune 500 brands, we understand the delicate balance between creative marketing strategies and data-driven precision. In this post, we share how implementing Amazon Q Business transformed our operations by democratizing AI access across our organization while maintaining stringent security standards, resulting in an average savings of 2.7 hours per week per employee in manual work and improved client service delivery.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a serverless audio summarization solution with Amazon Bedrock and Whisper</title>
      <link>https://www.dotnetramblings.com/post/06_06_2025/06_06_2025_1/</link>
      <pubDate>Fri, 06 Jun 2025 17:34:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_06_2025/06_06_2025_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to use the Open AI Whisper foundation model (FM) Whisper Large V3 Turbo, available in Amazon Bedrock Marketplace, which offers access to over 140 models through a dedicated offering, to produce near real-time transcription. These transcriptions are then processed by Amazon Bedrock for summarization and redaction of sensitive information.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-serverless-audio-summarization-solution-with-amazon-bedrock-and-whisper/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implement semantic video search using open source large vision models on Amazon SageMaker and Amazon OpenSearch Serverless</title>
      <link>https://www.dotnetramblings.com/post/06_06_2025/06_06_2025_2/</link>
      <pubDate>Fri, 06 Jun 2025 17:13:27 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_06_2025/06_06_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to use large vision models (LVMs) for semantic video search using natural language and image queries. We introduce some use case-specific methods, such as temporal frame smoothing and clustering, to enhance the video search performance. Furthermore, we demonstrate the end-to-end functionality of this approach by using both asynchronous and real-time hosting options on Amazon SageMaker AI to perform video, image, and text processing using publicly available LVMs on the Hugging Face Model Hub.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Multi-account support for Amazon SageMaker HyperPod task governance</title>
      <link>https://www.dotnetramblings.com/post/06_06_2025/06_06_2025_3/</link>
      <pubDate>Fri, 06 Jun 2025 16:55:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_06_2025/06_06_2025_3/</guid>
      <description>
        
          
            In this post, we discuss how an enterprise with multiple accounts can access a shared Amazon SageMaker HyperPod cluster for running their heterogenous workloads. We use SageMaker HyperPod task governance to enable this feature.
Link to article: https://aws.amazon.com/blogs/machine-learning/multi-account-support-for-amazon-sagemaker-hyperpod-task-governance/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a Text-to-SQL solution for data consistency in generative AI using Amazon Nova</title>
      <link>https://www.dotnetramblings.com/post/06_06_2025/06_06_2025_4/</link>
      <pubDate>Fri, 06 Jun 2025 16:53:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_06_2025/06_06_2025_4/</guid>
      <description>
        
          
            This post evaluates the key options for querying data using generative AI, discusses their strengths and limitations, and demonstrates why Text-to-SQL is the best choice for deterministic, schema-specific tasks. We show how to effectively use Text-to-SQL using Amazon Nova, a foundation model (FM) available in Amazon Bedrock, to derive precise and reliable answers from your data.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-text-to-sql-solution-for-data-consistency-in-generative-ai-using-amazon-nova/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Modernize and migrate on-premises fraud detection machine learning workflows to Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_4/</link>
      <pubDate>Thu, 05 Jun 2025 16:40:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_4/</guid>
      <description>
        
          
            Radial is the largest 3PL fulfillment provider, also offering integrated payment, fraud detection, and omnichannel solutions to mid-market and enterprise brands. In this post, we share how Radial optimized the cost and performance of their fraud detection machine learning (ML) applications by modernizing their ML workflow using Amazon SageMaker.
Link to article: https://aws.amazon.com/blogs/machine-learning/modernize-and-migrate-on-premises-fraud-detection-machine-learning-workflows-to-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Contextual retrieval in Anthropic using Amazon Bedrock Knowledge Bases</title>
      <link>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_5/</link>
      <pubDate>Thu, 05 Jun 2025 16:30:55 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_5/</guid>
      <description>
        
          
            Contextual retrieval enhances traditional RAG by adding chunk-specific explanatory context to each chunk before generating embeddings. This approach enriches the vector representation with relevant contextual information, enabling more accurate retrieval of semantically related content when responding to user queries. In this post, we demonstrate how to use contextual retrieval with Anthropic and Amazon Bedrock Knowledge Bases.
Link to article: https://aws.amazon.com/blogs/machine-learning/contextual-retrieval-in-anthropic-using-amazon-bedrock-knowledge-bases/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Run small language models cost-efficiently with AWS Graviton and Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_6/</link>
      <pubDate>Thu, 05 Jun 2025 16:16:20 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_06_2025/05_06_2025_6/</guid>
      <description>
        
          
            In this post, we demonstrate how to deploy a small language model on SageMaker AI by extending our pre-built containers to be compatible with AWS Graviton instances. We first provide an overview of the solution, and then provide detailed implementation steps to help you get started. You can find the example notebook in the GitHub repo.
Link to article: https://aws.amazon.com/blogs/machine-learning/run-small-language-models-cost-efficiently-with-aws-graviton-and-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Impel enhances automotive dealership customer experience with fine-tuned LLMs on Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_0/</link>
      <pubDate>Wed, 04 Jun 2025 21:20:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_0/</guid>
      <description>
        
          
            In this post, we share how Impel enhances the automotive dealership customer experience with fine-tuned LLMs on SageMaker.
Link to article: https://aws.amazon.com/blogs/machine-learning/impel-enhances-automotive-dealership-customer-experience-with-fine-tuned-llms-on-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How climate tech startups are building foundation models with Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_2/</link>
      <pubDate>Wed, 04 Jun 2025 16:07:46 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_2/</guid>
      <description>
        
          
            In this post, we show how climate tech startups are developing foundation models (FMs) that use extensive environmental datasets to tackle issues such as carbon capture, carbon-negative fuels, new materials design for microplastics destruction, and ecosystem preservation. These specialized models require advanced computational capabilities to process and analyze vast amounts of data effectively.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-climate-tech-startups-are-building-foundation-models-with-amazon-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Supercharge your development with Claude Code and Amazon Bedrock prompt caching</title>
      <link>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_3/</link>
      <pubDate>Wed, 04 Jun 2025 16:04:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_06_2025/04_06_2025_3/</guid>
      <description>
        
          
            In this post, we&#39;ll explore how to combine Amazon Bedrock prompt caching with Claude Code—a coding agent released by Anthropic that is now generally available. This powerful combination transforms your development workflow by delivering lightning-fast responses from reducing inference response latency, as well as lowering input token costs.
Link to article: https://aws.amazon.com/blogs/machine-learning/supercharge-your-development-with-claude-code-and-amazon-bedrock-prompt-caching/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlocking the power of Model Context Protocol (MCP) on AWS</title>
      <link>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_4/</link>
      <pubDate>Tue, 03 Jun 2025 16:53:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_4/</guid>
      <description>
        
          
            We’ve witnessed remarkable advances in model capabilities as generative AI companies have invested in developing their offerings. Language models such as Anthropic’s Claude Opus 4 &amp;amp; Sonnet 4 and Amazon Nova on Amazon Bedrock can reason, write, and generate responses with increasing sophistication. But even as these models grow more powerful, they can only work […]
Link to article: https://aws.amazon.com/blogs/machine-learning/unlocking-the-power-of-model-context-protocol-mcp-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a scalable AI assistant to help refugees using AWS</title>
      <link>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_5/</link>
      <pubDate>Tue, 03 Jun 2025 15:35:07 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_5/</guid>
      <description>
        
          
            The Danish humanitarian organization Bevar Ukraine has developed a comprehensive virtual generative AI-powered assistant called Victor, aimed at addressing the pressing needs of Ukrainian refugees integrating into Danish society. This post details our technical implementation using AWS services to create a scalable, multilingual AI assistant system that provides automated assistance while maintaining data security and GDPR compliance.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-scalable-ai-assistant-to-help-refugees-using-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhanced diagnostics flow with LLM and Amazon Bedrock agent integration</title>
      <link>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_6/</link>
      <pubDate>Tue, 03 Jun 2025 15:25:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_06_2025/03_06_2025_6/</guid>
      <description>
        
          
            In this post, we explore how Noodoe uses AI and Amazon Bedrock to optimize EV charging operations. By integrating LLMs, Noodoe enhances station diagnostics, enables dynamic pricing, and delivers multilingual support. These innovations reduce downtime, maximize efficiency, and improve sustainability. Read on to discover how AI is transforming EV charging management.
Link to article: https://aws.amazon.com/blogs/machine-learning/enhanced-diagnostics-flow-with-llm-and-amazon-bedrock-agent-integration/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
