<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Wed, 19 Feb 2025 17:30:22 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Build verifiable explainability into financial services workflows with Automated Reasoning checks for Amazon Bedrock Guardrails</title>
      <link>https://www.dotnetramblings.com/post/19_02_2025/19_02_2025_3/</link>
      <pubDate>Wed, 19 Feb 2025 17:30:22 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_02_2025/19_02_2025_3/</guid>
      <description>
        
          
            In this post, we explore how Automated Reasoning checks work through various common FSI scenarios such as insurance legal triaging, underwriting rules validation, and claims processing.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-verifiable-explainability-into-financial-services-workflows-with-automated-reasoning-checks-for-amazon-bedrock-guardrails/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Best practices for Amazon SageMaker HyperPod task governance</title>
      <link>https://www.dotnetramblings.com/post/19_02_2025/19_02_2025_4/</link>
      <pubDate>Wed, 19 Feb 2025 17:28:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_02_2025/19_02_2025_4/</guid>
      <description>
        
          
            In this post, we provide best practices to maximize the value of SageMaker HyperPod task governance and make the administration and data science experiences seamless. We also discuss common governance scenarios when administering and running generative AI development tasks.
Link to article: https://aws.amazon.com/blogs/machine-learning/best-practices-for-amazon-sagemaker-hyperpod-task-governance/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Formula 1Â® uses generative AI to accelerate race-day issue resolution</title>
      <link>https://www.dotnetramblings.com/post/18_02_2025/18_02_2025_0/</link>
      <pubDate>Tue, 18 Feb 2025 21:08:58 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_02_2025/18_02_2025_0/</guid>
      <description>
        
          
            In this post, we explain how F1 and AWS have developed a root cause analysis (RCA) assistant powered by Amazon Bedrock to reduce manual intervention and accelerate the resolution of recurrent operational issues during races from weeks to minutes. The RCA assistant enables the F1 team to spend more time on innovation and improving its services, ultimately delivering an exceptional experience for fans and partners. The successful collaboration between F1 and AWS showcases the transformative potential of generative AI in empowering teams to accomplish more in less time.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Using Amazon Rekognition to improve bicycle safety</title>
      <link>https://www.dotnetramblings.com/post/17_02_2025/17_02_2025_3/</link>
      <pubDate>Mon, 17 Feb 2025 16:51:45 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_02_2025/17_02_2025_3/</guid>
      <description>
        
          
            To better protect themselves, many cyclists are starting to ride with cameras mounted to the front or back of their bicycle. In this blog post, I will demonstrate a machine learning solution that cyclists can use to better identify close calls. The architecture of the solution uses Amazon Rekognition to detect vehicles in recorded bike ride videos. It then analyzes the video to determine if any vehicles are passing too close to the cyclist, within the 3-foot safe distance required by law.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a dynamic, role-based AI agent using Amazon Bedrock inline agents</title>
      <link>https://www.dotnetramblings.com/post/13_02_2025/13_02_2025_3/</link>
      <pubDate>Thu, 13 Feb 2025 20:56:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_02_2025/13_02_2025_3/</guid>
      <description>
        
          
            In this post, we explore how to build an application using Amazon Bedrock inline agents, demonstrating how a single AI assistant can adapt its capabilities dynamically based on user roles.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-dynamic-role-based-ai-agent-using-amazon-bedrock-inline-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use language embeddings for zero-shot classification and semantic search with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/13_02_2025/13_02_2025_4/</link>
      <pubDate>Thu, 13 Feb 2025 20:53:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_02_2025/13_02_2025_4/</guid>
      <description>
        
          
            In this post, we explore what language embeddings are and how they can be used to enhance your application. We show how, by using the properties of embeddings, we can implement a real-time zero-shot classifier and can add powerful features such as semantic search.
Link to article: https://aws.amazon.com/blogs/machine-learning/use-language-embeddings-for-zero-shot-classification-and-semantic-search-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine-tune LLMs with synthetic data for context-based Q&amp;A using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/12_02_2025/12_02_2025_3/</link>
      <pubDate>Wed, 12 Feb 2025 17:44:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_02_2025/12_02_2025_3/</guid>
      <description>
        
          
            In this post, we explore how to use Amazon Bedrock to generate synthetic training data to fine-tune an LLM. Additionally, we provide concrete evaluation results that showcase the power of synthetic data in fine-tuning when data is scarce.
Link to article: https://aws.amazon.com/blogs/machine-learning/fine-tune-llms-with-synthetic-data-for-context-based-qa-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Achieve ~2x speed-up in LLM inference with Medusa-1 on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/12_02_2025/12_02_2025_4/</link>
      <pubDate>Wed, 12 Feb 2025 17:41:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_02_2025/12_02_2025_4/</guid>
      <description>
        
          
            Researchers developed Medusa, a framework to speed up LLM inference by adding extra heads to predict multiple tokens simultaneously. This post demonstrates how to use Medusa-1, the first version of the framework, to speed up an LLM by fine-tuning it on Amazon SageMaker AI and confirms the speed up with deployment and a simple load test. Medusa-1 achieves an inference speedup of around two times without sacrificing model quality, with the exact improvement varying based on model size and data used.
          
          
        
      </description>
    </item>
    
    <item>
      <title>LLM-as-a-judge on Amazon Bedrock Model Evaluation</title>
      <link>https://www.dotnetramblings.com/post/12_02_2025/12_02_2025_5/</link>
      <pubDate>Wed, 12 Feb 2025 17:36:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_02_2025/12_02_2025_5/</guid>
      <description>
        
          
            This blog post explores LLM-as-a-judge on Amazon Bedrock Model Evaluation, providing comprehensive guidance on feature setup, evaluating job initiation through both the console and Python SDK and APIs, and demonstrating how this innovative evaluation feature can enhance generative AI applications across multiple metric categories including quality, user experience, instruction following, and safety.
Link to article: https://aws.amazon.com/blogs/machine-learning/llm-as-a-judge-on-amazon-bedrock-model-evaluation/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>From concept to reality: Navigating the Journey of RAG from proof of concept to production</title>
      <link>https://www.dotnetramblings.com/post/12_02_2025/12_02_2025_7/</link>
      <pubDate>Wed, 12 Feb 2025 17:27:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_02_2025/12_02_2025_7/</guid>
      <description>
        
          
            In this post, we explore the movement of RAG applications from their proof of concept or minimal viable product (MVP) phase to full-fledged production systems. When transitioning a RAG application from a proof of concept to a production-ready system, optimization becomes crucial to make sure the solution is reliable, cost-effective, and high-performing.
Link to article: https://aws.amazon.com/blogs/machine-learning/from-concept-to-reality-navigating-the-journey-of-rag-from-proof-of-concept-to-production/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
