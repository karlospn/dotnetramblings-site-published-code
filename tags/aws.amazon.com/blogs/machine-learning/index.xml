<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 09 Oct 2025 21:52:24 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Use Amazon SageMaker HyperPod and Anyscale for next-generation distributed computing</title>
      <link>https://www.dotnetramblings.com/post/09_10_2025/09_10_2025_0/</link>
      <pubDate>Thu, 09 Oct 2025 21:52:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_10_2025/09_10_2025_0/</guid>
      <description>
        
          
            In this post, we demonstrate how to integrate Amazon SageMaker HyperPod with Anyscale platform to address critical infrastructure challenges in building and deploying large-scale AI models. The combined solution provides robust infrastructure for distributed AI workloads with high-performance hardware, continuous monitoring, and seamless integration with Ray, the leading AI compute engine, enabling organizations to reduce time-to-market and lower total cost of ownership.
Link to article: https://aws.amazon.com/blogs/machine-learning/use-amazon-sagemaker-hyperpod-and-anyscale-for-next-generation-distributed-computing/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Customizing text content moderation with Amazon Nova</title>
      <link>https://www.dotnetramblings.com/post/09_10_2025/09_10_2025_1/</link>
      <pubDate>Thu, 09 Oct 2025 21:47:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_10_2025/09_10_2025_1/</guid>
      <description>
        
          
            In this post, we introduce Amazon Nova customization for text content moderation through Amazon SageMaker AI, enabling organizations to fine-tune models for their specific moderation needs. The evaluation across three benchmarks shows that customized Nova models achieve an average improvement of 7.3% in F1 scores compared to the baseline Nova Lite, with individual improvements ranging from 4.2% to 9.2% across different content moderation tasks.
Link to article: https://aws.amazon.com/blogs/machine-learning/customizing-text-content-moderation-with-amazon-nova/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Vxceed builds the perfect sales pitch for sales teams at scale using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/08_10_2025/08_10_2025_1/</link>
      <pubDate>Wed, 08 Oct 2025 16:26:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_10_2025/08_10_2025_1/</guid>
      <description>
        
          
            In this post, we show how Vxceed used Amazon Bedrock to develop this AI-powered multi-agent solution that generates personalized sales pitches for field sales teams at scale.
Link to article: https://aws.amazon.com/blogs/machine-learning/vxceed-builds-the-perfect-sales-pitch-for-sales-teams-at-scale-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implement a secure MLOps platform based on Terraform and GitHub</title>
      <link>https://www.dotnetramblings.com/post/08_10_2025/08_10_2025_3/</link>
      <pubDate>Wed, 08 Oct 2025 15:38:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_10_2025/08_10_2025_3/</guid>
      <description>
        
          
            Machine learning operations (MLOps) is the combination of people, processes, and technology to productionize ML use cases efficiently. To achieve this, enterprise customers must develop MLOps platforms to support reproducibility, robustness, and end-to-end observability of the ML use case’s lifecycle. Those platforms are based on a multi-account setup by adopting strict security constraints, development best […]
Link to article: https://aws.amazon.com/blogs/machine-learning/implement-a-secure-mlops-platform-based-on-terraform-and-github/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate Amazon QuickSight data stories creation with agentic AI using Amazon Nova Act</title>
      <link>https://www.dotnetramblings.com/post/07_10_2025/07_10_2025_3/</link>
      <pubDate>Tue, 07 Oct 2025 17:43:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_10_2025/07_10_2025_3/</guid>
      <description>
        
          
            In this post, we demonstrate how Amazon Nova Act automates QuickSight data story creation, saving time so you can focus on making critical, data-driven business decisions.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-amazon-quicksight-data-stories-creation-with-agentic-ai-using-amazon-nova-act/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implement automated monitoring for Amazon Bedrock batch inference</title>
      <link>https://www.dotnetramblings.com/post/07_10_2025/07_10_2025_4/</link>
      <pubDate>Tue, 07 Oct 2025 17:39:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_10_2025/07_10_2025_4/</guid>
      <description>
        
          
            In this post, we demonstrated how a financial services company can use an FM to process large volumes of customer records and get specific data-driven product recommendations. We also showed how to implement an automated monitoring solution for Amazon Bedrock batch inference jobs. By using EventBridge, Lambda, and DynamoDB, you can gain real-time visibility into batch processing operations, so you can efficiently generate personalized product recommendations based on customer credit data.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Responsible AI: How PowerSchool safeguards millions of students with AI-powered content filtering using Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/06_10_2025/06_10_2025_2/</link>
      <pubDate>Mon, 06 Oct 2025 19:14:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_10_2025/06_10_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how PowerSchool built and deployed a custom content filtering solution using Amazon SageMaker AI that achieved better accuracy while maintaining low false positive rates. We walk through our technical approach to fine tuning Llama 3.1 8B, our deployment architecture, and the performance results from internal validations.
Link to article: https://aws.amazon.com/blogs/machine-learning/responsible-ai-how-powerschool-safeguards-millions-of-students-with-ai-powered-content-filtering-using-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlock global AI inference scalability using new global cross-Region inference on Amazon Bedrock  with Anthropic’s Claude Sonnet 4.5</title>
      <link>https://www.dotnetramblings.com/post/03_10_2025/03_10_2025_0/</link>
      <pubDate>Fri, 03 Oct 2025 21:37:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_10_2025/03_10_2025_0/</guid>
      <description>
        
          
            Organizations are increasingly integrating generative AI capabilities into their applications to enhance customer experiences, streamline operations, and drive innovation. As generative AI workloads continue to grow in scale and importance, organizations face new challenges in maintaining consistent performance, reliability, and availability of their AI-powered applications. Customers are looking to scale their AI inference workloads across […]
Link to article: https://aws.amazon.com/blogs/machine-learning/unlock-global-ai-inference-scalability-using-new-global-cross-region-inference-on-amazon-bedrock-with-anthropics-claude-sonnet-4-5/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Secure ingress connectivity to Amazon Bedrock AgentCore Gateway using interface VPC endpoints</title>
      <link>https://www.dotnetramblings.com/post/03_10_2025/03_10_2025_1/</link>
      <pubDate>Fri, 03 Oct 2025 20:08:46 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_10_2025/03_10_2025_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to access AgentCore Gateway through a VPC interface endpoint from an Amazon Elastic Compute Cloud (Amazon EC2) instance in a VPC. We also show how to configure your VPC endpoint policy to provide secure access to the AgentCore Gateway while maintaining the principle of least privilege access.
Link to article: https://aws.amazon.com/blogs/machine-learning/secure-ingress-connectivity-to-amazon-bedrock-agentcore-gateway-using-interface-vpc-endpoints/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhance agentic workflows with enterprise search using Kore.ai and Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/02_10_2025/02_10_2025_0/</link>
      <pubDate>Thu, 02 Oct 2025 22:14:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_10_2025/02_10_2025_0/</guid>
      <description>
        
          
            In this post, we demonstrate how organizations can enhance their employee productivity by integrating Kore.ai’s AI for Work platform with Amazon Q Business. We show how to configure AI for Work as a data accessor for Amazon Q index for independent software vendors (ISVs), so employees can search enterprise knowledge and execute end-to-end agentic workflows involving search, reasoning, actions, and content generation.
Link to article: https://aws.amazon.com/blogs/machine-learning/enhance-agentic-workflows-with-enterprise-search-using-kore-ai-and-amazon-q-business/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate development with the Amazon Bedrock AgentCore MCP server</title>
      <link>https://www.dotnetramblings.com/post/02_10_2025/02_10_2025_1/</link>
      <pubDate>Thu, 02 Oct 2025 21:12:34 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_10_2025/02_10_2025_1/</guid>
      <description>
        
          
            Today, we’re excited to announce the Amazon Bedrock AgentCore Model Context Protocol (MCP) Server. With built-in support for runtime, gateway integration, identity management, and agent memory, the AgentCore MCP Server is purpose-built to speed up creation of components compatible with Bedrock AgentCore. You can use the AgentCore MCP server for rapid prototyping, production AI solutions, […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-development-with-the-amazon-bedrock-agentcore-mcpserver/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
