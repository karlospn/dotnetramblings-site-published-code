<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Fri, 15 Aug 2025 15:52:28 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building a RAG chat-based assistant on Amazon EKS Auto Mode and NVIDIA NIMs</title>
      <link>https://www.dotnetramblings.com/post/15_08_2025/15_08_2025_0/</link>
      <pubDate>Fri, 15 Aug 2025 15:52:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_08_2025/15_08_2025_0/</guid>
      <description>
        
          
            In this post, we demonstrate the implementation of a practical RAG chat-based assistant using a comprehensive stack of modern technologies. The solution uses NVIDIA NIMs for both LLM inference and text embedding services, with the NIM Operator handling their deployment and management. The architecture incorporates Amazon OpenSearch Serverless to store and query high-dimensional vector embeddings for similarity search.
Link to article: https://aws.amazon.com/blogs/machine-learning/building-a-rag-chat-based-assistant-on-amazon-eks-auto-mode-and-nvidia-nims/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Introducing Amazon Bedrock AgentCore Identity: Securing agentic AI at scale</title>
      <link>https://www.dotnetramblings.com/post/15_08_2025/15_08_2025_1/</link>
      <pubDate>Fri, 15 Aug 2025 15:28:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_08_2025/15_08_2025_1/</guid>
      <description>
        
          
            In this post, we explore Amazon Bedrock AgentCore Identity, a comprehensive identity and access management service purpose-built for AI agents that enables secure access to AWS resources and third-party tools. The service provides robust identity management features including agent identity directory, agent authorizer, resource credential provider, and resource token vault to help organizations deploy AI agents securely at scale.
Link to article: https://aws.amazon.com/blogs/machine-learning/introducing-amazon-bedrock-agentcore-identity-securing-agentic-ai-at-scale/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Scalable intelligent document processing using Amazon Bedrock Data Automation</title>
      <link>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_1/</link>
      <pubDate>Thu, 14 Aug 2025 17:53:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_1/</guid>
      <description>
        
          
            In the blog post Scalable intelligent document processing using Amazon Bedrock, we demonstrated how to build a scalable IDP pipeline using Anthropic foundation models on Amazon Bedrock. Although that approach delivered robust performance, the introduction of Amazon Bedrock Data Automation brings a new level of efficiency and flexibility to IDP solutions. This post explores how Amazon Bedrock Data Automation enhances document processing capabilities and streamlines the automation journey.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Whiteboard to cloud in minutes using Amazon Q, Amazon Bedrock Data Automation, and Model Context Protocol</title>
      <link>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_2/</link>
      <pubDate>Thu, 14 Aug 2025 17:31:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_2/</guid>
      <description>
        
          
            We’re excited to share the Amazon Bedrock Data Automation Model Context Protocol (MCP) server, for seamless integration between Amazon Q and your enterprise data. In this post, you will learn how to use the Amazon Bedrock Data Automation MCP server to securely integrate with AWS Services, use Bedrock Data Automation operations as callable MCP tools, and build a conversational development experience with Amazon Q.
Link to article: https://aws.amazon.com/blogs/machine-learning/whiteboard-to-cloud-in-minutes-using-amazon-q-amazon-bedrock-data-automation-and-model-context-protocol/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Bringing agentic Retrieval Augmented Generation to Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_3/</link>
      <pubDate>Thu, 14 Aug 2025 17:14:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_3/</guid>
      <description>
        
          
            In this blog post, we explore how Amazon Q Business is transforming enterprise data interaction through Agentic Retrieval Augmented Generation (RAG).
Link to article: https://aws.amazon.com/blogs/machine-learning/bringing-agentic-retrieval-augmented-generation-to-amazon-q-business/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Empowering students with disabilities: University Startups’ generative AI solution for personalized student pathways</title>
      <link>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_6/</link>
      <pubDate>Thu, 14 Aug 2025 16:10:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_6/</guid>
      <description>
        
          
            University Startups, headquartered in Bethesda, MD, was founded in 2020 to empower high school students to expand their education beyond a traditional curriculum. University Startups is focused on special education and related services in school districts throughout the US. In this post, we explain how University Startups uses generative AI technology on AWS to enable students to design a specific plan for their future either in education or the work force.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Citations with Amazon Nova understanding models</title>
      <link>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_8/</link>
      <pubDate>Thu, 14 Aug 2025 15:56:20 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_08_2025/14_08_2025_8/</guid>
      <description>
        
          
            In this post, we demonstrate how to prompt Amazon Nova understanding models to cite sources in responses. Further, we will also walk through how we can evaluate the responses (and citations) for accuracy.
Link to article: https://aws.amazon.com/blogs/machine-learning/citations-with-amazon-nova-understanding-models/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Securely launch and scale your agents and tools on Amazon Bedrock AgentCore Runtime</title>
      <link>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_0/</link>
      <pubDate>Wed, 13 Aug 2025 21:59:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_0/</guid>
      <description>
        
          
            In this post, we explore how Amazon Bedrock AgentCore Runtime simplifies the deployment and management of AI agents.
Link to article: https://aws.amazon.com/blogs/machine-learning/securely-launch-and-scale-your-agents-and-tools-on-amazon-bedrock-agentcore-runtime/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>PwC and AWS Build Responsible AI with Automated Reasoning on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_1/</link>
      <pubDate>Wed, 13 Aug 2025 19:32:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_1/</guid>
      <description>
        
          
            This post presents how AWS and PwC are developing new reasoning checks that combine deep industry expertise with Automated Reasoning checks in Amazon Bedrock Guardrails to support innovation.
Link to article: https://aws.amazon.com/blogs/machine-learning/pwc-and-aws-build-responsible-ai-with-automated-reasoning-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Amazon scaled Rufus by building multi-node inference using AWS Trainium chips and vLLM</title>
      <link>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_4/</link>
      <pubDate>Wed, 13 Aug 2025 17:01:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_4/</guid>
      <description>
        
          
            In this post, Amazon shares how they developed a multi-node inference solution for Rufus, their generative AI shopping assistant, using Amazon Trainium chips and vLLM to serve large language models at scale. The solution combines a leader/follower orchestration model, hybrid parallelism strategies, and a multi-node inference unit abstraction layer built on Amazon ECS to deploy models across multiple nodes while maintaining high performance and reliability.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-amazon-scaled-rufus-by-building-multi-node-inference-using-aws-trainium-chips-and-vllm/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an intelligent financial analysis agent with LangGraph and Strands Agents</title>
      <link>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_5/</link>
      <pubDate>Wed, 13 Aug 2025 16:32:20 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_5/</guid>
      <description>
        
          
            This post describes an approach of combining three powerful technologies to illustrate an architecture that you can adapt and build upon for your specific financial analysis needs: LangGraph for workflow orchestration, Strands Agents for structured reasoning, and Model Context Protocol (MCP) for tool integration.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-intelligent-financial-analysis-agent-with-langgraph-and-strands-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock AgentCore Memory: Building context-aware agents</title>
      <link>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_6/</link>
      <pubDate>Wed, 13 Aug 2025 16:30:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_6/</guid>
      <description>
        
          
            In this post, we explore Amazon Bedrock AgentCore Memory, a fully managed service that enables AI agents to maintain both immediate and long-term knowledge, transforming one-off conversations into continuous, evolving relationships between users and AI agents. The service eliminates complex memory infrastructure management while providing full control over what AI agents remember, offering powerful capabilities for maintaining both short-term working memory and long-term intelligent memory across sessions.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a conversational natural language interface for Amazon Athena queries using Amazon Nova</title>
      <link>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_7/</link>
      <pubDate>Wed, 13 Aug 2025 16:18:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_08_2025/13_08_2025_7/</guid>
      <description>
        
          
            In this post, we explore an innovative solution that uses Amazon Bedrock Agents, powered by Amazon Nova Lite, to create a conversational interface for Athena queries. We use AWS Cost and Usage Reports (AWS CUR) as an example, but this solution can be adapted for other databases you query using Athena. This approach democratizes data access while preserving the powerful analytical capabilities of Athena, so you can interact with your data using natural language.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Train and deploy AI models at trillion-parameter scale with Amazon SageMaker HyperPod support for P6e-GB200 UltraServers</title>
      <link>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_0/</link>
      <pubDate>Tue, 12 Aug 2025 19:57:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_0/</guid>
      <description>
        
          
            In this post, we review the technical specifications of P6e-GB200 UltraServers, discuss their performance benefits, and highlight key use cases. We then walk though how to purchase UltraServer capacity through flexible training plans and get started using UltraServers with SageMaker HyperPod.
Link to article: https://aws.amazon.com/blogs/machine-learning/train-and-deploy-ai-models-at-trillion-parameter-scale-with-amazon-sagemaker-hyperpod-support-for-p6e-gb200-ultraservers/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Indegene’s AI-powered social intelligence for life sciences turns social media conversations into insights</title>
      <link>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_2/</link>
      <pubDate>Tue, 12 Aug 2025 18:41:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_2/</guid>
      <description>
        
          
            This post explores how Indegene’s Social Intelligence Solution uses advanced AI to help life sciences companies extract valuable insights from digital healthcare conversations. Built on AWS technology, the solution addresses the growing preference of HCPs for digital channels while overcoming the challenges of analyzing complex medical discussions on a scale.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-indegenes-ai-powered-social-intelligence-for-life-sciences-turns-social-media-conversations-into-insights/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlocking enhanced legal document review with Lexbe and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_3/</link>
      <pubDate>Tue, 12 Aug 2025 18:38:03 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_3/</guid>
      <description>
        
          
            In this post, Lexbe, a legal document review software company, demonstrates how they integrated Amazon Bedrock and other AWS services to transform their document review process, enabling legal professionals to instantly query and extract insights from vast volumes of case documents using generative AI. Through collaboration with AWS, Lexbe achieved significant improvements in recall rates, reaching up to 90% by December 2024, and developed capabilities for broad human-style reporting and deep automated inference across multiple languages.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate AIOps with SageMaker Unified Studio Projects, Part 2: Technical implementation</title>
      <link>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_4/</link>
      <pubDate>Tue, 12 Aug 2025 18:31:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_4/</guid>
      <description>
        
          
            In this post, we focus on implementing this architecture with step-by-step guidance and reference code. We provide a detailed technical walkthrough that addresses the needs of two critical personas in the AI development lifecycle: the administrator who establishes governance and infrastructure through automated templates, and the data scientist who uses SageMaker Unified Studio for model development without managing the underlying infrastructure.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-aiops-with-sagemaker-unified-studio-projects-part-2-technical-implementation/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate AIOps with Amazon SageMaker Unified Studio projects, Part 1: Solution architecture</title>
      <link>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_5/</link>
      <pubDate>Tue, 12 Aug 2025 18:31:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_08_2025/12_08_2025_5/</guid>
      <description>
        
          
            This post presents architectural strategies and a scalable framework that helps organizations manage multi-tenant environments, automate consistently, and embed governance controls as they scale their AI initiatives with SageMaker Unified Studio.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-aiops-with-amazon-sagemaker-unified-studio-projects-part-1-solution-architecture/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Demystifying Amazon Bedrock Pricing for a Chatbot Assistant</title>
      <link>https://www.dotnetramblings.com/post/11_08_2025/11_08_2025_0/</link>
      <pubDate>Mon, 11 Aug 2025 19:33:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_08_2025/11_08_2025_0/</guid>
      <description>
        
          
            In this post, we&#39;ll look at Amazon Bedrock pricing through the lens of a practical, real-world example: building a customer service chatbot. We&#39;ll break down the essential cost components, walk through capacity planning for a mid-sized call center implementation, and provide detailed pricing calculations across different foundation models.
Link to article: https://aws.amazon.com/blogs/machine-learning/demystifying-amazon-bedrock-pricing-for-a-chatbot-assistant/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine-tune OpenAI GPT-OSS models on Amazon SageMaker AI using Hugging Face libraries</title>
      <link>https://www.dotnetramblings.com/post/11_08_2025/11_08_2025_1/</link>
      <pubDate>Mon, 11 Aug 2025 19:25:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_08_2025/11_08_2025_1/</guid>
      <description>
        
          
            Released on August 5, 2025, OpenAI’s GPT-OSS models, gpt-oss-20b and gpt-oss-120b, are now available on AWS through Amazon SageMaker AI and Amazon Bedrock. In this post, we walk through the process of fine-tuning a GPT-OSS model in a fully managed training environment using SageMaker AI training jobs.
Link to article: https://aws.amazon.com/blogs/machine-learning/fine-tune-openai-gpt-oss-models-on-amazon-sagemaker-ai-using-hugging-face-libraries/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
