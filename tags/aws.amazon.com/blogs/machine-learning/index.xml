<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Mon, 09 Sep 2024 22:40:48 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Align Meta Llama 3 to human preferences with DPO, Amazon SageMaker Studio, and Amazon SageMaker Ground Truth</title>
      <link>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_0/</link>
      <pubDate>Mon, 09 Sep 2024 22:40:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_0/</guid>
      <description>
        
          
            In this post, we show you how to enhance the performance of Meta Llama 3 8B Instruct by fine-tuning it using direct preference optimization (DPO) on data collected with SageMaker Ground Truth.
Link to article: https://aws.amazon.com/blogs/machine-learning/align-meta-llama-3-to-human-preferences-with-dpo-amazon-sagemaker-studio-and-amazon-sagemaker-ground-truth/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon EC2 P5e instances are generally available</title>
      <link>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_1/</link>
      <pubDate>Mon, 09 Sep 2024 22:20:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_1/</guid>
      <description>
        
          
            In this post, we discuss the core capabilities of Amazon Elastic Compute Cloud (Amazon EC2) P5e instances and the use cases they’re well-suited for. We walk you through an example of how to get started with these instances and carry out inference deployment of Meta Llama 3.1 70B and 405B models on them.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-ec2-p5e-instances-are-generally-available/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Exploring data using AI chat at Domo with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_2/</link>
      <pubDate>Mon, 09 Sep 2024 21:51:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_09_2024/09_09_2024_2/</guid>
      <description>
        
          
            In this post, we share how Domo, a cloud-centered data experiences innovator is using Amazon Bedrock to provide a flexible and powerful AI solution.
Link to article: https://aws.amazon.com/blogs/machine-learning/exploring-data-using-ai-chat-at-domo-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Vidmob is using generative AI to transform its creative data landscape</title>
      <link>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_0/</link>
      <pubDate>Fri, 06 Sep 2024 21:12:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_0/</guid>
      <description>
        
          
            In this post, we illustrate how Vidmob, a creative data company, worked with the AWS Generative AI Innovation Center (GenAIIC) team to uncover meaningful insights at scale within creative data using Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-vidmob-is-using-generative-ai-to-transform-its-creative-data-landscape/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine-tune Llama 3 for text generation on Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_1/</link>
      <pubDate>Fri, 06 Sep 2024 20:22:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to fine-tune the recently released Llama 3 models from Meta, specifically the llama-3-8b and llama-3-70b variants, using Amazon SageMaker JumpStart.
Link to article: https://aws.amazon.com/blogs/machine-learning/fine-tune-llama-3-for-text-generation-on-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Ground truth curation and metric interpretation best practices for evaluating generative AI question answering using FMEval</title>
      <link>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_3/</link>
      <pubDate>Fri, 06 Sep 2024 20:11:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_09_2024/06_09_2024_3/</guid>
      <description>
        
          
            In this post, we discuss best practices for working with Foundation Model Evaluations Library (FMEval) in ground truth curation and metric interpretation for evaluating question answering applications for factual knowledge and quality.
Link to article: https://aws.amazon.com/blogs/machine-learning/ground-truth-curation-and-metric-interpretation-best-practices-for-evaluating-generative-ai-question-answering-using-fmeval/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build powerful RAG pipelines with LlamaIndex and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/05_09_2024/05_09_2024_1/</link>
      <pubDate>Thu, 05 Sep 2024 21:53:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_09_2024/05_09_2024_1/</guid>
      <description>
        
          
            In this post, we show you how to use LlamaIndex with Amazon Bedrock to build robust and sophisticated RAG pipelines that unlock the full potential of LLMs for knowledge-intensive tasks.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-powerful-rag-pipelines-with-llamaindex-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluating prompts at scale with Prompt Management and Prompt Flows for Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/05_09_2024/05_09_2024_2/</link>
      <pubDate>Thu, 05 Sep 2024 20:11:05 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_09_2024/05_09_2024_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to implement an automated prompt evaluation system using Amazon Bedrock so you can streamline your prompt development process and improve the overall quality of your AI-generated content.
Link to article: https://aws.amazon.com/blogs/machine-learning/evaluating-prompts-at-scale-with-prompt-management-and-prompt-flows-for-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deploy Amazon SageMaker pipelines using AWS Controllers for Kubernetes</title>
      <link>https://www.dotnetramblings.com/post/04_09_2024/04_09_2024_0/</link>
      <pubDate>Wed, 04 Sep 2024 22:40:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_09_2024/04_09_2024_0/</guid>
      <description>
        
          
            In this post, we show how ML engineers familiar with Jupyter notebooks and SageMaker environments can efficiently work with DevOps engineers familiar with Kubernetes and related tools to design and maintain an ML pipeline with the right infrastructure for their organization. This enables DevOps engineers to manage all the steps of the ML lifecycle with the same set of tools and environment they are used to.
Link to article: https://aws.amazon.com/blogs/machine-learning/deploy-amazon-sagemaker-pipelines-using-aws-controllers-for-kubernetes/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Effectively manage foundation models for generative AI applications with Amazon SageMaker Model Registry</title>
      <link>https://www.dotnetramblings.com/post/04_09_2024/04_09_2024_1/</link>
      <pubDate>Wed, 04 Sep 2024 22:34:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_09_2024/04_09_2024_1/</guid>
      <description>
        
          
            In this post, we explore the new features of Model Registry that streamline foundation model (FM) management: you can now register unzipped model artifacts and pass an End User License Agreement (EULA) acceptance flag without needing users to intervene.
Link to article: https://aws.amazon.com/blogs/machine-learning/effectively-manage-foundation-models-for-generative-ai-applications-with-amazon-sagemaker-model-registry/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an ecommerce product recommendation chatbot with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/04_09_2024/04_09_2024_2/</link>
      <pubDate>Wed, 04 Sep 2024 21:10:07 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_09_2024/04_09_2024_2/</guid>
      <description>
        
          
            In this post, we show you how to build an ecommerce product recommendation chatbot using Amazon Bedrock Agents and foundation models (FMs) available in Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-ecommerce-product-recommendation-chatbot-with-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Thomson Reuters Labs achieved AI/ML innovation at pace with AWS MLOps services</title>
      <link>https://www.dotnetramblings.com/post/04_09_2024/04_09_2024_3/</link>
      <pubDate>Wed, 04 Sep 2024 20:22:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_09_2024/04_09_2024_3/</guid>
      <description>
        
          
            In this post, we show you how Thomson Reuters Labs (TR Labs) was able to develop an efficient, flexible, and powerful MLOps process by adopting a standardized MLOps framework that uses AWS SageMaker, SageMaker Experiments, SageMaker Model Registry, and SageMaker Pipelines. The goal being to accelerate how quickly teams can experiment and innovate using AI and machine learning (ML)—whether using natural language processing (NLP), generative AI, or other techniques. We discuss how this has helped decrease the time to market for fresh ideas and helped build a cost-efficient machine learning lifecycle.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a generative AI image description application with Anthropic’s Claude 3.5 Sonnet on Amazon Bedrock and AWS CDK</title>
      <link>https://www.dotnetramblings.com/post/03_09_2024/03_09_2024_1/</link>
      <pubDate>Tue, 03 Sep 2024 21:13:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_09_2024/03_09_2024_1/</guid>
      <description>
        
          
            In this post, we delve into the process of building and deploying a sample application capable of generating multilingual descriptions for multiple images with a Streamlit UI, AWS Lambda powered with the Amazon Bedrock SDK, and AWS AppSync driven by the open source Generative AI CDK Constructs.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-generative-ai-image-description-application-with-anthropics-claude-3-5-sonnet-on-amazon-bedrock-and-aws-cdk/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use LangChain with PySpark to process documents at massive scale with Amazon SageMaker Studio and Amazon EMR Serverless</title>
      <link>https://www.dotnetramblings.com/post/03_09_2024/03_09_2024_2/</link>
      <pubDate>Tue, 03 Sep 2024 19:05:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_09_2024/03_09_2024_2/</guid>
      <description>
        
          
            In this post, we explore how to build a scalable and efficient Retrieval Augmented Generation (RAG) system using the new EMR Serverless integration, Spark’s distributed processing, and an Amazon OpenSearch Service vector database powered by the LangChain orchestration framework. This solution enables you to process massive volumes of textual data, generate relevant embeddings, and store them in a powerful vector database for seamless retrieval and generation.
Link to article: https://aws.amazon.com/blogs/machine-learning/use-langchain-with-pyspark-to-process-documents-at-massive-scale-with-amazon-sagemaker-studio-and-amazon-emr-serverless/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
