<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 18 Mar 2025 16:30:26 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Unleash AI innovation with Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_0/</link>
      <pubDate>Tue, 18 Mar 2025 16:30:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_0/</guid>
      <description>
        
          
            In this post, we show how SageMaker HyperPod, and its new features introduced at AWS re:Invent 2024, is designed to meet the demands of modern AI workloads, offering a persistent and optimized cluster tailored for distributed training and accelerated inference at cloud scale and attractive price-performance.
Link to article: https://aws.amazon.com/blogs/machine-learning/unleash-ai-innovation-with-amazon-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Revolutionizing clinical trials with the power of voice and AI</title>
      <link>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_1/</link>
      <pubDate>Tue, 18 Mar 2025 16:25:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_03_2025/18_03_2025_1/</guid>
      <description>
        
          
            As the healthcare industry continues to embrace digital transformation, solutions that combine advanced technologies like audio-to-text translation and LLMs will become increasingly valuable in addressing key challenges, such as patient education, engagement, and empowerment. In this post, we discuss possible use cases for combining speech recognition technology with LLMs, and how the solution can revolutionize clinical trials.
Link to article: https://aws.amazon.com/blogs/machine-learning/revolutionizing-clinical-trials-with-the-power-of-voice-and-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Intelligent healthcare assistants: Empowering stakeholders with personalized support and data-driven insights</title>
      <link>https://www.dotnetramblings.com/post/17_03_2025/17_03_2025_1/</link>
      <pubDate>Mon, 17 Mar 2025 17:49:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_03_2025/17_03_2025_1/</guid>
      <description>
        
          
            Healthcare decisions often require integrating information from multiple sources, such as medical literature, clinical databases, and patient records. LLMs lack the ability to seamlessly access and synthesize data from these diverse and distributed sources. This limits their potential to provide comprehensive and well-informed insights for healthcare applications. In this blog post, we will explore how Mistral LLM on Amazon Bedrock can address these challenges and enable the development of intelligent healthcare agents with LLM function calling capabilities, while maintaining robust data security and privacy through Amazon Bedrock Guardrails.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Getting started with computer use in Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/14_03_2025/14_03_2025_2/</link>
      <pubDate>Fri, 14 Mar 2025 18:20:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_03_2025/14_03_2025_2/</guid>
      <description>
        
          
            Today, we’re announcing computer use support within Amazon Bedrock Agents using Anthropic’s Claude 3.5 Sonnet V2 and Anthropic’s Claude Sonnet 3.7 models on Amazon Bedrock. This integration brings Anthropic’s visual perception capabilities as a managed tool within Amazon Bedrock Agents, providing you with a secure, traceable, and managed way to implement computer use automation in your workflows.
Link to article: https://aws.amazon.com/blogs/machine-learning/getting-started-with-computer-use-in-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluating RAG applications with Amazon Bedrock knowledge base evaluation</title>
      <link>https://www.dotnetramblings.com/post/14_03_2025/14_03_2025_6/</link>
      <pubDate>Fri, 14 Mar 2025 15:39:25 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_03_2025/14_03_2025_6/</guid>
      <description>
        
          
            This post focuses on RAG evaluation with Amazon Bedrock Knowledge Bases, provides a guide to set up the feature, discusses nuances to consider as you evaluate your prompts and responses, and finally discusses best practices. By the end of this post, you will understand how the latest Amazon Bedrock evaluation features can streamline your approach to AI quality assurance, enabling more efficient and confident development of RAG applications.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How GoDaddy built a category generation system at scale with batch inference for Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_6/</link>
      <pubDate>Thu, 13 Mar 2025 16:43:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_6/</guid>
      <description>
        
          
            This post provides an overview of a custom solution developed by the for GoDaddy, a domain registrar, registry, web hosting, and ecommerce company that seeks to make entrepreneurship more accessible by using generative AI to provide personalized business insights to over 21 million customers. In this collaboration, the Generative AI Innovation Center team created an accurate and cost-efficient generative AI–based solution using batch inference in Amazon Bedrock, helping GoDaddy improve their existing product categorization system.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Benchmarking customized models on Amazon Bedrock using LLMPerf and LiteLLM</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_8/</link>
      <pubDate>Thu, 13 Mar 2025 14:09:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_8/</guid>
      <description>
        
          
            This post begins a blog series exploring DeepSeek and open FMs on Amazon Bedrock Custom Model Import. It covers the process of performance benchmarking of custom models in Amazon Bedrock using popular open source tools: LLMPerf and LiteLLM. It includes a notebook that includes step-by-step instructions to deploy a DeepSeek-R1-Distill-Llama-8B model, but the same steps apply for any other model supported by Amazon Bedrock Custom Model Import.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Creating asynchronous AI agents with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_9/</link>
      <pubDate>Thu, 13 Mar 2025 14:06:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_9/</guid>
      <description>
        
          
            The integration of generative AI agents into business processes is poised to accelerate as organizations recognize the untapped potential of these technologies. Advancements in multimodal artificial intelligence (AI), where agents can understand and generate not just text but also images, audio, and video, will further broaden their applications. This post will discuss agentic AI driven architecture and ways of implementing.
Link to article: https://aws.amazon.com/blogs/machine-learning/creating-asynchronous-ai-agents-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How to run Qwen 2.5 on AWS AI chips using Hugging Face libraries</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_10/</link>
      <pubDate>Thu, 13 Mar 2025 14:03:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_10/</guid>
      <description>
        
          
            In this post, we outline how to get started with deploying the Qwen 2.5 family of models on an Inferentia instance using Amazon Elastic Compute Cloud (Amazon EC2) and Amazon SageMaker using the Hugging Face Text Generation Inference (TGI) container and the Hugging Face Optimum Neuron library. Qwen2.5 Coder and Math variants are also supported.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-to-run-qwen-2-5-on-aws-ai-chips-using-hugging-face-libraries/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Revolutionizing customer service: MaestroQA’s integration with Amazon Bedrock for actionable insight</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_11/</link>
      <pubDate>Thu, 13 Mar 2025 14:01:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_11/</guid>
      <description>
        
          
            In this post, we dive deeper into one of MaestroQA’s key features—conversation analytics, which helps support teams uncover customer concerns, address points of friction, adapt support workflows, and identify areas for coaching through the use of Amazon Bedrock. We discuss the unique challenges MaestroQA overcame and how they use AWS to build new features, drive customer insights, and improve operational inefficiencies.
Link to article: https://aws.amazon.com/blogs/machine-learning/revolutionizing-customer-service-maestroqas-integration-with-amazon-bedrock-for-actionable-insight/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimize hosting DeepSeek-R1 distilled models with Hugging Face TGI on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_13/</link>
      <pubDate>Thu, 13 Mar 2025 13:57:58 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/13_03_2025/13_03_2025_13/</guid>
      <description>
        
          
            In this post, we demonstrate how to optimize hosting DeepSeek-R1 distilled models with Hugging Face Text Generation Inference (TGI) on Amazon SageMaker AI.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimize-hosting-deepseek-r1-distilled-models-with-hugging-face-tgi-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Exploring creative possibilities: A visual guide to Amazon Nova Canvas</title>
      <link>https://www.dotnetramblings.com/post/12_03_2025/12_03_2025_3/</link>
      <pubDate>Wed, 12 Mar 2025 18:10:17 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_03_2025/12_03_2025_3/</guid>
      <description>
        
          
            In this blog post, we showcase a curated gallery of visuals generated by Nova Canvas—categorized by real-world use cases—from marketing and product visualization to concept art and design exploration. Each image is paired with the prompt and parameters that generated it, providing a practical starting point for your own AI-driven creativity. Whether you&#39;re crafting specific types of images, optimizing workflows, or simply seeking inspiration, this guide will help you unlock the full potential of Amazon Nova Canvas.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
