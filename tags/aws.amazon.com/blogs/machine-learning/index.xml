<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Wed, 22 May 2024 19:33:45 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Generating fashion product descriptions by fine-tuning a vision-language model with SageMaker and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/22_05_2024/22_05_2024_2/</link>
      <pubDate>Wed, 22 May 2024 19:33:45 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_05_2024/22_05_2024_2/</guid>
      <description>
        
          
            This post shows you how to predict domain-specific product attributes from product images by fine-tuning a VLM on a fashion dataset using Amazon SageMaker, and then using Amazon Bedrock to generate product descriptions using the predicted attributes as input. So you can follow along, we’re sharing the code in a GitHub repository.
Link to article: https://aws.amazon.com/blogs/machine-learning/generating-fashion-product-descriptions-by-fine-tuning-a-vision-language-model-with-sagemaker-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Create a multimodal assistant with advanced RAG and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_4/</link>
      <pubDate>Tue, 21 May 2024 16:28:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_4/</guid>
      <description>
        
          
            In this post, we present a new approach named multimodal RAG (mmRAG) to tackle those existing limitations in greater detail. The solution intends to address these limitations for practical generative artificial intelligence (AI) assistant use cases. Additionally, we examine potential solutions to enhance the capabilities of large language models (LLMs) and visual language models (VLMs) with advanced LangChain capabilities, enabling them to generate more comprehensive, coherent, and accurate outputs while effectively handling multimodal data
          
          
        
      </description>
    </item>
    
    <item>
      <title>How 20 Minutes empowers journalists and boosts audience engagement with generative AI on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_5/</link>
      <pubDate>Tue, 21 May 2024 16:16:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_5/</guid>
      <description>
        
          
            This post is co-written with Aurélien Capdecomme and Bertrand d’Aure from 20 Minutes. With 19 million monthly readers, 20 Minutes is a major player in the French media landscape. The media organization delivers useful, relevant, and accessible information to an audience that consists primarily of young and active urban readers. Every month, nearly 8.3 million 25–49-year-olds choose […]
Link to article: https://aws.amazon.com/blogs/machine-learning/how-20-minutes-empowers-journalists-and-boosts-audience-engagement-with-generative-ai-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Efficient and cost-effective multi-tenant LoRA serving with Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_13/</link>
      <pubDate>Tue, 21 May 2024 15:33:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_05_2024/21_05_2024_13/</guid>
      <description>
        
          
            In this post, we explore a solution that addresses these challenges head-on using LoRA serving with Amazon SageMaker. By using the new performance optimizations of LoRA techniques in SageMaker large model inference (LMI) containers along with inference components, we demonstrate how organizations can efficiently manage and serve their growing portfolio of fine-tuned models, while optimizing costs and providing seamless performance for their customers. The latest SageMaker LMI container offers unmerged-LoRA inference, sped up with our LMI-Dist inference engine and OpenAI style chat schema.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Mixtral 8x22B is now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/17_05_2024/17_05_2024_3/</link>
      <pubDate>Fri, 17 May 2024 16:02:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_05_2024/17_05_2024_3/</guid>
      <description>
        
          
            Today, we are excited to announce the Mixtral-8x22B large language model (LLM), developed by Mistral AI, is available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. You can try out this model with SageMaker JumpStart, a machine learning (ML) hub that provides access to algorithms and models so you […]
Link to article: https://aws.amazon.com/blogs/machine-learning/mixtral-8x22b-is-now-available-in-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building Generative AI prompt chaining workflows with human in the loop</title>
      <link>https://www.dotnetramblings.com/post/17_05_2024/17_05_2024_4/</link>
      <pubDate>Fri, 17 May 2024 15:51:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_05_2024/17_05_2024_4/</guid>
      <description>
        
          
            While Generative AI can create highly realistic content, including text, images, and videos, it can also generate outputs that appear plausible but are verifiably incorrect. Incorporating human judgment is crucial, especially in complex and high-risk decision-making scenarios. This involves building a human-in-the-loop process where humans play an active role in decision making alongside the AI system. In this blog post, you will learn about prompt chaining, how to break a complex task into multiple tasks to use prompt chaining with an LLM in a specific order, and how to involve a human to review the response generated by the LLM.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How LotteON built a personalized recommendation system using Amazon SageMaker and MLOps</title>
      <link>https://www.dotnetramblings.com/post/16_05_2024/16_05_2024_6/</link>
      <pubDate>Thu, 16 May 2024 16:13:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_05_2024/16_05_2024_6/</guid>
      <description>
        
          
            This post is co-written with HyeKyung Yang, Jieun Lim, and SeungBum Shim from LotteON. LotteON aims to be a platform that not only sells products, but also provides a personalized recommendation experience tailored to your preferred lifestyle. LotteON operates various specialty stores, including fashion, beauty, luxury, and kids, and strives to provide a personalized shopping […]
Link to article: https://aws.amazon.com/blogs/machine-learning/how-lotteon-built-a-personalized-recommendation-system-using-amazon-sagemaker-and-mlops/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
