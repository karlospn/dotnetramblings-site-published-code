<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 31 Oct 2024 18:41:33 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Create a generative AI–powered custom Google Chat application using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/31_10_2024/31_10_2024_0/</link>
      <pubDate>Thu, 31 Oct 2024 18:41:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_10_2024/31_10_2024_0/</guid>
      <description>
        
          
            AWS offers powerful generative AI services, including Amazon Bedrock, which allows organizations to create tailored use cases such as AI chat-based assistants that give answers based on knowledge contained in the customers’ documents, and much more. Many businesses want to integrate these cutting-edge AI capabilities with their existing collaboration tools, such as Google Chat, to […]
Link to article: https://aws.amazon.com/blogs/machine-learning/create-a-generative-ai-powered-custom-google-chat-application-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Discover insights from Gmail using the Gmail connector for Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/31_10_2024/31_10_2024_1/</link>
      <pubDate>Thu, 31 Oct 2024 18:36:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_10_2024/31_10_2024_1/</guid>
      <description>
        
          
            A number of organizations use Gmail for their business email needs. Gmail for business is part of Google Workspace, which provides a set of productivity and collaboration tools like Google Drive, Gmail, and Google Calendar. Google Drive supports storing documents such as Emails contain a wealth of information found in different places, such as within […]
Link to article: https://aws.amazon.com/blogs/machine-learning/discover-insights-from-gmail-using-the-gmail-connector-for-amazon-q-business/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate custom labeling workflows in Amazon SageMaker Ground Truth without using AWS Lambda</title>
      <link>https://www.dotnetramblings.com/post/31_10_2024/31_10_2024_2/</link>
      <pubDate>Thu, 31 Oct 2024 18:34:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_10_2024/31_10_2024_2/</guid>
      <description>
        
          
            Amazon SageMaker Ground Truth enables the creation of high-quality, large-scale training datasets, essential for fine-tuning across a wide range of applications, including large language models (LLMs) and generative AI. By integrating human annotators with machine learning, SageMaker Ground Truth significantly reduces the cost and time required for data labeling. Whether it’s annotating images, videos, or […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-custom-labeling-workflows-in-amazon-sagemaker-ground-truth-without-using-aws-lambda/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlock organizational wisdom using voice-driven knowledge capture with Amazon Transcribe and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/30_10_2024/30_10_2024_3/</link>
      <pubDate>Wed, 30 Oct 2024 16:42:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_10_2024/30_10_2024_3/</guid>
      <description>
        
          
            This post introduces an innovative voice-based application workflow that harnesses the power of Amazon Bedrock, Amazon Transcribe, and React to systematically capture and document institutional knowledge through voice recordings from experienced staff members. Our solution uses Amazon Transcribe for real-time speech-to-text conversion, enabling accurate and immediate documentation of spoken knowledge. We then use generative AI, powered by Amazon Bedrock, to analyze and summarize the transcribed content, extracting key insights and generating comprehensive documentation.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Achieve multi-Region resiliency for your conversational AI chatbots with Amazon Lex</title>
      <link>https://www.dotnetramblings.com/post/30_10_2024/30_10_2024_4/</link>
      <pubDate>Wed, 30 Oct 2024 16:19:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_10_2024/30_10_2024_4/</guid>
      <description>
        
          
            Global Resiliency is a new Amazon Lex capability that enables near real-time replication of your Amazon Lex V2 bots in a second AWS Region. When you activate this feature, all resources, versions, and aliases associated after activation will be synchronized across the chosen Regions. With Global Resiliency, the replicated bot resources and aliases in the […]
Link to article: https://aws.amazon.com/blogs/machine-learning/achieve-multi-region-resiliency-for-your-conversational-ai-chatbots-with-amazon-lex/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Create and fine-tune sentence transformers for enhanced classification accuracy</title>
      <link>https://www.dotnetramblings.com/post/30_10_2024/30_10_2024_5/</link>
      <pubDate>Wed, 30 Oct 2024 16:12:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_10_2024/30_10_2024_5/</guid>
      <description>
        
          
            In this post, we showcase how to fine-tune a sentence transformer specifically for classifying an Amazon product into its product category (such as toys or sporting goods). We showcase two different sentence transformers, paraphrase-MiniLM-L6-v2 and a proprietary Amazon large language model (LLM) called M5_ASIN_SMALL_V2.0, and compare their results.
Link to article: https://aws.amazon.com/blogs/machine-learning/create-and-fine-tune-sentence-transformers-for-enhanced-classification-accuracy/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Empower your generative AI application with a comprehensive custom observability solution</title>
      <link>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_0/</link>
      <pubDate>Tue, 29 Oct 2024 22:14:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_0/</guid>
      <description>
        
          
            In this post, we set up the custom solution for observability and evaluation of Amazon Bedrock applications. Through code examples and step-by-step guidance, we demonstrate how you can seamlessly integrate this solution into your Amazon Bedrock application, unlocking a new level of visibility, control, and continual improvement for your generative AI applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/empower-your-generative-ai-application-with-a-comprehensive-custom-observability-solution/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate Amazon Bedrock batch inference: Building a scalable and efficient pipeline</title>
      <link>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_1/</link>
      <pubDate>Tue, 29 Oct 2024 19:41:58 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_1/</guid>
      <description>
        
          
            Although batch inference offers numerous benefits, it’s limited to 10 batch inference jobs submitted per model per Region. To address this consideration and enhance your use of batch inference, we’ve developed a scalable solution using AWS Lambda and Amazon DynamoDB. This post guides you through implementing a queue management system that automatically monitors available job slots and submits new jobs as slots become available.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-amazon-bedrock-batch-inference-building-a-scalable-and-efficient-pipeline/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a video insights and summarization engine using generative AI with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_7/</link>
      <pubDate>Tue, 29 Oct 2024 16:23:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_7/</guid>
      <description>
        
          
            This post presents a solution where you can upload a recording of your meeting (a feature available in most modern digital communication services such as Amazon Chime) to a centralized video insights and summarization engine. This engine uses artificial intelligence (AI) and machine learning (ML) services and generative AI on AWS to extract transcripts, produce a summary, and provide a sentiment for the call. The solution notes the logged actions per individual and provides suggested actions for the uploader.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate document processing with Amazon Bedrock Prompt Flows (preview)</title>
      <link>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_10/</link>
      <pubDate>Tue, 29 Oct 2024 15:53:43 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_10/</guid>
      <description>
        
          
            This post demonstrates how to build an IDP pipeline for automatically extracting and processing data from documents using Amazon Bedrock Prompt Flows, a fully managed service that enables you to build generative AI workflow using Amazon Bedrock and other services in an intuitive visual builder. Amazon Bedrock Prompt Flows allows you to quickly update your pipelines as your business changes, scaling your document processing workflows to help meet evolving demands.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Governing the ML lifecycle at scale: Centralized observability with Amazon SageMaker and Amazon CloudWatch</title>
      <link>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_11/</link>
      <pubDate>Tue, 29 Oct 2024 15:50:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_10_2024/29_10_2024_11/</guid>
      <description>
        
          
            This post is part of an ongoing series on governing the machine learning (ML) lifecycle at scale. To start from the beginning, refer to Governing the ML lifecycle at scale, Part 1: A framework for architecting ML workloads using Amazon SageMaker. A multi-account strategy is essential not only for improving governance but also for enhancing […]
Link to article: https://aws.amazon.com/blogs/machine-learning/governing-the-ml-lifecycle-at-scale-centralized-observability-with-amazon-sagemaker-and-amazon-cloudwatch/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Import data from Google Cloud Platform BigQuery for no-code machine learning with Amazon SageMaker Canvas</title>
      <link>https://www.dotnetramblings.com/post/28_10_2024/28_10_2024_3/</link>
      <pubDate>Mon, 28 Oct 2024 18:38:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_10_2024/28_10_2024_3/</guid>
      <description>
        
          
            This post presents an architectural approach to extract data from different cloud environments, such as Google Cloud Platform (GCP) BigQuery, without the need for data movement. This minimizes the complexity and overhead associated with moving data between cloud environments, enabling organizations to access and utilize their disparate data assets for ML projects. We highlight the process of using Amazon Athena Federated Query to extract data from GCP BigQuery, using Amazon SageMaker Data Wrangler to perform data preparation, and then using the prepared data to build ML models within Amazon SageMaker Canvas, a no-code ML interface.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Customized model monitoring for near real-time batch inference with Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/28_10_2024/28_10_2024_4/</link>
      <pubDate>Mon, 28 Oct 2024 17:22:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_10_2024/28_10_2024_4/</guid>
      <description>
        
          
            In this post, we present a framework to customize the use of Amazon SageMaker Model Monitor for handling multi-payload inference requests for near real-time inference scenarios. SageMaker Model Monitor monitors the quality of SageMaker ML models in production. Early and proactive detection of deviations in model quality enables you to take corrective actions, such as retraining models, auditing upstream systems, or fixing quality issues without having to monitor models manually or build additional tooling.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Planview built a scalable AI Assistant for portfolio and project management using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/25_10_2024/25_10_2024_2/</link>
      <pubDate>Fri, 25 Oct 2024 16:51:22 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_10_2024/25_10_2024_2/</guid>
      <description>
        
          
            In this post, we explore how Planview was able to develop a generative AI assistant to address complex work management process by adopting Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-planview-built-a-scalable-ai-assistant-for-portfolio-and-project-management-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Super charge your LLMs with RAG at scale using AWS Glue for Apache Spark</title>
      <link>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_3/</link>
      <pubDate>Thu, 24 Oct 2024 18:09:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_3/</guid>
      <description>
        
          
            In this post, we will explore building a reusable RAG data pipeline on LangChain—an open source framework for building applications based on LLMs—and integrating it with AWS Glue and Amazon OpenSearch Serverless. The end solution is a reference architecture for scalable RAG indexing and deployment.
Link to article: https://aws.amazon.com/blogs/machine-learning/super-charge-your-llms-with-rag-at-scale-using-aws-glue-for-apache-spark/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>From RAG to fabric: Lessons learned from building real-world RAGs at GenAIIC – Part 1</title>
      <link>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_4/</link>
      <pubDate>Thu, 24 Oct 2024 18:04:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_4/</guid>
      <description>
        
          
            In this post, we cover the core concepts behind RAG architectures and discuss strategies for evaluating RAG performance, both quantitatively through metrics and qualitatively by analyzing individual outputs. We outline several practical tips for improving text retrieval, including using hybrid search techniques, enhancing context through data preprocessing, and rewriting queries for better relevance.
Link to article: https://aws.amazon.com/blogs/machine-learning/from-rag-to-fabric-lessons-learned-from-building-real-world-rags-at-genaiic-part-1/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhance your Amazon Redshift cloud data warehouse with easier, simpler, and faster machine learning using Amazon SageMaker Canvas</title>
      <link>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_5/</link>
      <pubDate>Thu, 24 Oct 2024 17:52:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_5/</guid>
      <description>
        
          
            In this post, we dive into a business use case for a banking institution. We will show you how a financial or business analyst at a bank can easily predict if a customer’s loan will be fully paid, charged off, or current using a machine learning model that is best for the business problem at hand.
Link to article: https://aws.amazon.com/blogs/machine-learning/enhance-your-amazon-redshift-cloud-data-warehouse-with-easier-simpler-and-faster-machine-learning-using-amazon-sagemaker-canvas/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Create a generative AI-based application builder assistant using Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_6/</link>
      <pubDate>Thu, 24 Oct 2024 17:50:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_6/</guid>
      <description>
        
          
            Agentic workflows are a fresh new perspective in building dynamic and complex business use- case based workflows with the help of large language models (LLM) as their reasoning engine or brain. In this post, we set up an agent using Amazon Bedrock Agents to act as a software application builder assistant.
Link to article: https://aws.amazon.com/blogs/machine-learning/create-a-generative-ai-based-application-builder-assistant-using-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Transitioning from Amazon Rekognition people pathing: Exploring other alternatives</title>
      <link>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_10/</link>
      <pubDate>Thu, 24 Oct 2024 16:03:02 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_10_2024/24_10_2024_10/</guid>
      <description>
        
          
            After careful consideration, we made the decision to discontinue Rekognition people pathing on October 31, 2025. New customers will not be able to access the capability effective October 24, 2024, but existing customers will be able to use the capability as normal until October 31, 2025. This post discusses an alternative solution to Rekognition people pathing and how you can implement this solution in your applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/transitioning-from-amazon-rekognition-people-pathing-exploring-other-alternatives/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
