<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 15 Jul 2025 22:05:53 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Amazon Bedrock Knowledge Bases now supports Amazon OpenSearch Service Managed Cluster as vector store</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_0/</link>
      <pubDate>Tue, 15 Jul 2025 22:05:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_0/</guid>
      <description>
        
          
            Amazon Bedrock Knowledge Bases has extended its vector store options by enabling support for Amazon OpenSearch Service managed clusters, further strengthening its capabilities as a fully managed Retrieval Augmented Generation (RAG) solution. This enhancement builds on the core functionality of Amazon Bedrock Knowledge Bases , which is designed to seamlessly connect foundation models (FMs) with internal data sources. This post provides a comprehensive, step-by-step guide on integrating an Amazon Bedrock knowledge base with an OpenSearch Service managed cluster as its vector store.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Monitor agents built on Amazon Bedrock with Datadog LLM Observability</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_1/</link>
      <pubDate>Tue, 15 Jul 2025 22:02:38 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_1/</guid>
      <description>
        
          
            We’re excited to announce a new integration between Datadog LLM Observability and Amazon Bedrock Agents that helps monitor agentic applications built on Amazon Bedrock. In this post, we&#39;ll explore how Datadog&#39;s LLM Observability provides the visibility and control needed to successfully monitor, operate, and debug production-grade agentic applications built on Amazon Bedrock Agents.
Link to article: https://aws.amazon.com/blogs/machine-learning/monitor-agents-built-on-amazon-bedrock-with-datadog-llm-observability/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How PayU built a secure enterprise AI assistant using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_2/</link>
      <pubDate>Tue, 15 Jul 2025 21:54:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_2/</guid>
      <description>
        
          
            PayU offers a full-stack digital financial services system that serves the financial needs of merchants, banks, and consumers through technology. In this post, we explain how we equipped the PayU team with an enterprise AI solution and democratized AI access using Amazon Bedrock, without compromising on data residency requirements.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-payu-built-a-secure-enterprise-ai-assistant-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Supercharge generative AI workflows with NVIDIA DGX Cloud on AWS and Amazon Bedrock Custom Model Import</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_10/</link>
      <pubDate>Tue, 15 Jul 2025 13:32:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_10/</guid>
      <description>
        
          
            This post is co-written with Andrew Liu, Chelsea Isaac, Zoey Zhang, and Charlie Huang from NVIDIA. DGX Cloud on Amazon Web Services (AWS) represents a significant leap forward in democratizing access to high-performance AI infrastructure. By combining NVIDIA GPU expertise with AWS scalable cloud services, organizations can accelerate their time-to-train, reduce operational complexity, and unlock […]
Link to article: https://aws.amazon.com/blogs/machine-learning/supercharge-generative-ai-workflows-with-nvidia-dgx-cloud-on-aws-and-amazon-bedrock-custom-model-import/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate generative AI inference with NVIDIA Dynamo and Amazon EKS</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_11/</link>
      <pubDate>Tue, 15 Jul 2025 13:03:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_11/</guid>
      <description>
        
          
            This post introduces NVIDIA Dynamo and explains how to set it up on Amazon EKS for automated scaling and streamlined Kubernetes operations. We provide a hands-on walkthrough, which uses the NVIDIA Dynamo blueprint on the AI on EKS GitHub repo by AWS Labs to provision the infrastructure, configure monitoring, and install the NVIDIA Dynamo operator.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-generative-ai-inference-with-nvidia-dynamo-and-amazon-eks/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS doubles investment in AWS Generative AI Innovation Center, marking two years of customer success</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_12/</link>
      <pubDate>Tue, 15 Jul 2025 12:40:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_12/</guid>
      <description>
        
          
            In this post, AWS announces a $100 million additional investment in its AWS Generative AI Innovation Center, marking two years of successful customer collaborations across industries from financial services to healthcare. The investment comes as AI evolves toward more autonomous, agentic systems, with the center already helping thousands of customers drive millions in productivity gains and transform customer experiences.
Link to article: https://aws.amazon.com/blogs/machine-learning/aws-doubles-investment-in-aws-generative-ai-innovation-center-marking-two-years-of-customer-success/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build AI-driven policy creation for vehicle data collection and automation using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_1/</link>
      <pubDate>Mon, 14 Jul 2025 16:58:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_1/</guid>
      <description>
        
          
            Sonatus partnered with the AWS Generative AI Innovation Center to develop a natural language interface to generate data collection and automation policies using generative AI. This innovation aims to reduce the policy generation process from days to minutes while making it accessible to both engineers and non-experts alike. In this post, we explore how we built this system using Sonatus’s Collector AI and Amazon Bedrock. We discuss the background, challenges, and high-level solution architecture.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Rapid7 automates vulnerability risk scores with ML pipelines using Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_2/</link>
      <pubDate>Mon, 14 Jul 2025 16:55:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_2/</guid>
      <description>
        
          
            In this post, we share how Rapid7 implemented end-to-end automation for the training, validation, and deployment of ML models that predict CVSS vectors. Rapid7 customers have the information they need to accurately understand their risk and prioritize remediation measures.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-rapid7-automates-vulnerability-risk-scores-with-ml-pipelines-using-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build secure RAG applications with AWS serverless data lakes</title>
      <link>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_3/</link>
      <pubDate>Mon, 14 Jul 2025 16:51:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_3/</guid>
      <description>
        
          
            In this post, we explore how to build a secure RAG application using serverless data lake architecture, an important data strategy to support generative AI development. We use Amazon Web Services (AWS) services including Amazon S3, Amazon DynamoDB, AWS Lambda, and Amazon Bedrock Knowledge Bases to create a comprehensive solution supporting unstructured data assets which can be extended to structured data. The post covers how to implement fine-grained access controls for your enterprise data and design metadata-driven retrieval systems that respect security boundaries.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Advanced fine-tuning methods on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_3/</link>
      <pubDate>Fri, 11 Jul 2025 17:26:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_3/</guid>
      <description>
        
          
            When fine-tuning ML models on AWS, you can choose the right tool for your specific needs. AWS provides a comprehensive suite of tools for data scientists, ML engineers, and business users to achieve their ML goals. AWS has built solutions to support various levels of ML sophistication, from simple SageMaker training jobs for FM fine-tuning to the power of SageMaker HyperPod for cutting-edge research. We invite you to explore these options, starting with what suits your current needs, and evolve your approach as those needs change.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline machine learning workflows with SkyPilot on Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_4/</link>
      <pubDate>Fri, 11 Jul 2025 17:22:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_4/</guid>
      <description>
        
          
            This post is co-written with Zhanghao Wu, co-creator of SkyPilot. The rapid advancement of generative AI and foundation models (FMs) has significantly increased computational resource requirements for machine learning (ML) workloads. Modern ML pipelines require efficient systems for distributing workloads across accelerated compute resources, while making sure developer productivity remains high. Organizations need infrastructure solutions […]
Link to article: https://aws.amazon.com/blogs/machine-learning/streamline-machine-learning-workflows-with-skypilot-on-amazon-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Intelligent document processing at scale with generative AI and Amazon Bedrock Data Automation</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_5/</link>
      <pubDate>Fri, 11 Jul 2025 16:49:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_5/</guid>
      <description>
        
          
            This post presents an end-to-end IDP application powered by Amazon Bedrock Data Automation and other AWS services. It provides a reusable AWS infrastructure as code (IaC) that deploys an IDP pipeline and provides an intuitive UI for transforming documents into structured tables at scale. The application only requires the user to provide the input documents (such as contracts or emails) and a list of attributes to be extracted. It then performs IDP with generative AI.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a conversational data assistant, Part 2 – Embedding generative business intelligence with Amazon Q in QuickSight</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_6/</link>
      <pubDate>Fri, 11 Jul 2025 16:33:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_6/</guid>
      <description>
        
          
            In this post, we dive into how we integrated Amazon Q in QuickSight to transform natural language requests like “Show me how many items were returned in the US over the past 6 months” into meaningful data visualizations. We demonstrate how combining Amazon Bedrock Agents with Amazon Q in QuickSight creates a comprehensive data assistant that delivers both SQL code and visual insights through a single, intuitive conversational interface—democratizing data access across the enterprise.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a conversational data assistant, Part 1: Text-to-SQL with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_7/</link>
      <pubDate>Fri, 11 Jul 2025 16:32:44 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_7/</guid>
      <description>
        
          
            In this post, we focus on building a Text-to-SQL solution with Amazon Bedrock, a managed service for building generative AI applications. Specifically, we demonstrate the capabilities of Amazon Bedrock Agents. Part 2 explains how we extended the solution to provide business insights using Amazon Q in QuickSight, a business intelligence assistant that answers questions with auto-generated visualizations.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-conversational-data-assistant-part-1-text-to-sql-with-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implement user-level access control for multi-tenant ML platforms on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_8/</link>
      <pubDate>Fri, 11 Jul 2025 16:17:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_8/</guid>
      <description>
        
          
            In this post, we discuss permission management strategies, focusing on attribute-based access control (ABAC) patterns that enable granular user access control while minimizing the proliferation of AWS Identity and Access Management (IAM) roles. We also share proven best practices that help organizations maintain security and compliance without sacrificing operational efficiency in their ML workflows.
Link to article: https://aws.amazon.com/blogs/machine-learning/implement-user-level-access-control-for-multi-tenant-ml-platforms-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Long-running execution flows now supported in Amazon Bedrock Flows in public preview</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_9/</link>
      <pubDate>Fri, 11 Jul 2025 16:13:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_9/</guid>
      <description>
        
          
            We announce the public preview of long-running execution (asynchronous) flow support within Amazon Bedrock Flows. With Amazon Bedrock Flows, you can link foundation models (FMs), Amazon Bedrock Prompt Management, Amazon Bedrock Agents, Amazon Bedrock Knowledge Bases, Amazon Bedrock Guardrails, and other AWS services together to build and scale predefined generative AI workflows.
Link to article: https://aws.amazon.com/blogs/machine-learning/long-running-execution-flows-now-supported-in-amazon-bedrock-flows-in-public-preview/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fraud detection empowered by federated learning with the Flower framework on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_10/</link>
      <pubDate>Fri, 11 Jul 2025 16:03:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_10/</guid>
      <description>
        
          
            In this post, we explore how SageMaker and federated learning help financial institutions build scalable, privacy-first fraud detection systems.
Link to article: https://aws.amazon.com/blogs/machine-learning/fraud-detection-empowered-by-federated-learning-with-the-flower-framework-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building intelligent AI voice agents with Pipecat and Amazon Bedrock – Part 2</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_11/</link>
      <pubDate>Fri, 11 Jul 2025 15:56:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_11/</guid>
      <description>
        
          
            In Part 1 of this series, you learned how you can use the combination of Amazon Bedrock and Pipecat, an open source framework for voice and multimodal conversational AI agents to build applications with human-like conversational AI. You learned about common use cases of voice agents and the cascaded models approach, where you orchestrate several components to build your voice AI agent. In this post (Part 2), you explore how to use speech-to-speech foundation model, Amazon Nova Sonic, and the benefits of using a unified model.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Uphold ethical standards in fashion using multimodal toxicity detection with Amazon Bedrock Guardrails</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_12/</link>
      <pubDate>Fri, 11 Jul 2025 15:49:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_12/</guid>
      <description>
        
          
            In the fashion industry, teams are frequently innovating quickly, often utilizing AI. Sharing content, whether it be through videos, designs, or otherwise, can lead to content moderation challenges. There remains a risk (through intentional or unintentional actions) of inappropriate, offensive, or toxic content being produced and shared. In this post, we cover the use of the multimodal toxicity detection feature of Amazon Bedrock Guardrails to guard against toxic content. Whether you’re an enterprise giant in the fashion industry or an up-and-coming brand, you can use this solution to screen potentially harmful content before it impacts your brand’s reputation and ethical standards.
          
          
        
      </description>
    </item>
    
    <item>
      <title>New capabilities in Amazon SageMaker AI continue to transform how organizations develop AI models</title>
      <link>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_1/</link>
      <pubDate>Thu, 10 Jul 2025 19:08:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_1/</guid>
      <description>
        
          
            In this post, we share some of the new innovations in SageMaker AI that can accelerate how you build and train AI models. These innovations include new observability capabilities in SageMaker HyperPod, the ability to deploy JumpStart models on HyperPod, remote connections to SageMaker AI from local development environments, and fully managed MLflow 3.0.
Link to article: https://aws.amazon.com/blogs/machine-learning/new-capabilities-in-amazon-sagemaker-ai-continue-to-transform-how-organizations-develop-ai-models/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate foundation model development with one-click observability in Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_2/</link>
      <pubDate>Thu, 10 Jul 2025 18:37:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_2/</guid>
      <description>
        
          
            With a one-click installation of the Amazon Elastic Kubernetes Service (Amazon EKS) add-on for SageMaker HyperPod observability, you can consolidate health and performance data from NVIDIA DCGM, instance-level Kubernetes node exporters, Elastic Fabric Adapter (EFA), integrated file systems, Kubernetes APIs, Kueue, and SageMaker HyperPod task operators. In this post, we walk you through installing and using the unified dashboards of the out-of-the-box observability feature in SageMaker HyperPod. We cover the one-click installation from the Amazon SageMaker AI console, navigating the dashboard and metrics it consolidates, and advanced topics such as setting up custom alerts.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerating generative AI development with fully managed MLflow 3.0 on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_3/</link>
      <pubDate>Thu, 10 Jul 2025 18:35:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_3/</guid>
      <description>
        
          
            In this post, we explore how Amazon SageMaker now offers fully managed support for MLflow 3.0, streamlining AI experimentation and accelerating your generative AI journey from idea to production. This release transforms managed MLflow from experiment tracking to providing end-to-end observability, reducing time-to-market for generative AI development.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerating-generative-ai-development-with-fully-managed-mlflow-3-0-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon SageMaker HyperPod launches model deployments to accelerate the generative AI model development lifecycle</title>
      <link>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_4/</link>
      <pubDate>Thu, 10 Jul 2025 18:34:14 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_4/</guid>
      <description>
        
          
            In this post, we announce Amazon SageMaker HyperPod support for deploying foundation models from SageMaker JumpStart, as well as custom or fine-tuned models from Amazon S3 or Amazon FSx. This new capability allows customers to train, fine-tune, and deploy models on the same HyperPod compute resources, maximizing resource utilization across the entire model lifecycle.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-hyperpod-launches-model-deployments-to-accelerate-the-generative-ai-model-development-lifecycle/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Supercharge your AI workflows by connecting to SageMaker Studio from Visual Studio Code</title>
      <link>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_5/</link>
      <pubDate>Thu, 10 Jul 2025 18:33:58 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_5/</guid>
      <description>
        
          
            AI developers and machine learning (ML) engineers can now use the capabilities of Amazon SageMaker Studio directly from their local Visual Studio Code (VS Code). With this capability, you can use your customized local VS Code setup, including AI-assisted development tools, custom extensions, and debugging tools while accessing compute resources and your data in SageMaker Studio. In this post, we show you how to remotely connect your local VS Code to SageMaker Studio development environments to use your customized development environment while accessing Amazon SageMaker AI compute resources.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use K8sGPT and Amazon Bedrock for simplified Kubernetes cluster maintenance</title>
      <link>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_9/</link>
      <pubDate>Thu, 10 Jul 2025 15:26:22 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_9/</guid>
      <description>
        
          
            This post demonstrates the best practices to run K8sGPT in AWS with Amazon Bedrock in two modes: K8sGPT CLI and K8sGPT Operator. It showcases how the solution can help SREs simplify Kubernetes cluster management through continuous monitoring and operational intelligence.
Link to article: https://aws.amazon.com/blogs/machine-learning/use-k8sgpt-and-amazon-bedrock-for-simplified-kubernetes-cluster-maintenance/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Rocket streamlines the home buying experience with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_10/</link>
      <pubDate>Thu, 10 Jul 2025 15:23:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_10/</guid>
      <description>
        
          
            Rocket AI Agent is more than a digital assistant. It’s a reimagined approach to client engagement, powered by agentic AI. By combining Amazon Bedrock Agents with Rocket’s proprietary data and backend systems, Rocket has created a smarter, more scalable, and more human experience available 24/7, without the wait. This post explores how Rocket brought that vision to life using Amazon Bedrock Agents, powering a new era of AI-driven support that is consistently available, deeply personalized, and built to take action.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an MCP application with Mistral models on AWS</title>
      <link>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_11/</link>
      <pubDate>Thu, 10 Jul 2025 15:20:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_11/</guid>
      <description>
        
          
            This post demonstrates building an intelligent AI assistant using Mistral AI models on AWS and MCP, integrating real-time location services, time data, and contextual memory to handle complex multimodal queries. This use case, restaurant recommendations, serves as an example, but this extensible framework can be adapted for enterprise use cases by modifying MCP server configurations to connect with your specific data sources and business systems.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-mcp-application-with-mistral-models-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build real-time conversational AI experiences using Amazon Nova Sonic and LiveKit</title>
      <link>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_12/</link>
      <pubDate>Thu, 10 Jul 2025 15:09:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2025/10_07_2025_12/</guid>
      <description>
        
          
            mazon Nova Sonic is now integrated with LiveKit’s WebRTC framework, a widely used platform that enables developers to build real-time audio, video, and data communication applications. This integration makes it possible for developers to build conversational voice interfaces without needing to manage complex audio pipelines or signaling protocols. In this post, we explain how this integration works, how it addresses the historical challenges of voice-first applications, and some initial steps to start using this solution.
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS AI infrastructure with NVIDIA Blackwell: Two powerful compute solutions for the next frontier of AI</title>
      <link>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_0/</link>
      <pubDate>Wed, 09 Jul 2025 21:01:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_0/</guid>
      <description>
        
          
            In this post, we announce general availability of Amazon EC2 P6e-GB200 UltraServers and P6-B200 instances, powered by NVIDIA Blackwell GPUs, designed for training and deploying the largest, most sophisticated AI models.
Link to article: https://aws.amazon.com/blogs/machine-learning/aws-ai-infrastructure-with-nvidia-blackwell-two-powerful-compute-solutions-for-the-next-frontier-of-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlock retail intelligence by transforming data into actionable insights using generative AI with Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_1/</link>
      <pubDate>Wed, 09 Jul 2025 20:11:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_1/</guid>
      <description>
        
          
            Amazon Q Business for Retail Intelligence is an AI-powered assistant designed to help retail businesses streamline operations, improve customer service, and enhance decision-making processes. This solution is specifically engineered to be scalable and adaptable to businesses of various sizes, helping them compete more effectively. In this post, we show how you can use Amazon Q Business for Retail Intelligence to transform your data into actionable insights.
Link to article: https://aws.amazon.com/blogs/machine-learning/unlock-retail-intelligence-by-transforming-data-into-actionable-insights-using-generative-ai-with-amazon-q-business/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Democratize data for timely decisions with text-to-SQL at Parcel Perform</title>
      <link>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_4/</link>
      <pubDate>Wed, 09 Jul 2025 16:51:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_4/</guid>
      <description>
        
          
            The business team in Parcel Perform often needs access to data to answer questions related to merchants’ parcel deliveries, such as “Did we see a spike in delivery delays last week? If so, in which transit facilities were this observed, and what was the primary cause of the issue?” Previously, the data team had to manually form the query and run it to fetch the data. With the new generative AI-powered text-to-SQL capability in Parcel Perform, the business team can self-serve their data needs by using an AI assistant interface.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Query Amazon Aurora PostgreSQL using Amazon Bedrock Knowledge Bases structured data</title>
      <link>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_5/</link>
      <pubDate>Wed, 09 Jul 2025 16:48:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_5/</guid>
      <description>
        
          
            In this post, we discuss how to make your Amazon Aurora PostgreSQL-Compatible Edition data available for natural language querying through Amazon Bedrock Knowledge Bases while maintaining data freshness.
Link to article: https://aws.amazon.com/blogs/machine-learning/query-amazon-aurora-postgresql-using-amazon-bedrock-knowledge-bases-structured-data/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Configure fine-grained access to Amazon Bedrock models using Amazon SageMaker Unified Studio</title>
      <link>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_6/</link>
      <pubDate>Wed, 09 Jul 2025 16:45:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_6/</guid>
      <description>
        
          
            In this post, we demonstrate how to use SageMaker Unified Studio and AWS Identity and Access Management (IAM) to establish a robust permission framework for Amazon Bedrock models. We show how administrators can precisely manage which users and teams have access to specific models within a secure, collaborative environment. We guide you through creating granular permissions to control model access, with code examples for common enterprise governance scenarios.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Improve conversational AI response times for enterprise applications with the Amazon Bedrock streaming API and AWS AppSync</title>
      <link>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_7/</link>
      <pubDate>Wed, 09 Jul 2025 16:31:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_7/</guid>
      <description>
        
          
            This post demonstrates how integrating an Amazon Bedrock streaming API with AWS AppSync subscriptions significantly enhances AI assistant responsiveness and user satisfaction. By implementing this streaming approach, the global financial services organization reduced initial response times for complex queries by approximately 75%—from 10 seconds to just 2–3 seconds—empowering users to view responses as they’re generated rather than waiting for complete answers.
Link to article: https://aws.amazon.com/blogs/machine-learning/improve-conversational-ai-response-times-for-enterprise-applications-with-the-amazon-bedrock-streaming-api-and-aws-appsync/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Scale generative AI use cases, Part 1: Multi-tenant hub and spoke architecture using AWS Transit Gateway</title>
      <link>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_8/</link>
      <pubDate>Wed, 09 Jul 2025 16:29:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2025/09_07_2025_8/</guid>
      <description>
        
          
            n this two-part series, we discuss a hub and spoke architecture pattern for building a multi-tenant and multi-account architecture. This pattern supports abstractions for shared services across use cases and teams, helping create secure, scalable, and reliable generative AI systems. In Part 1, we present a centralized hub for generative AI service abstractions and tenant-specific spokes, using AWS Transit Gateway for cross-account interoperability.
Link to article: https://aws.amazon.com/blogs/machine-learning/scale-generative-ai-use-cases-part-1-multi-tenant-hub-and-spoke-architecture-using-aws-transit-gateway/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate AI development with Amazon Bedrock API keys</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_0/</link>
      <pubDate>Tue, 08 Jul 2025 20:04:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_0/</guid>
      <description>
        
          
            Today, we’re excited to announce a significant improvement to the developer experience of Amazon Bedrock: API keys. API keys provide quick access to the Amazon Bedrock APIs, streamlining the authentication process so that developers can focus on building rather than configuration.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-ai-development-with-amazon-bedrock-api-keys/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerating data science innovation: How Bayer Crop Science used AWS AI/ML services to build their next-generation MLOps service</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_5/</link>
      <pubDate>Tue, 08 Jul 2025 16:12:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_5/</guid>
      <description>
        
          
            In this post, we show how Bayer Crop Science manages large-scale data science operations by training models for their data analytics needs and maintaining high-quality code documentation to support developers. Through these solutions, Bayer Crop Science projects up to a 70% reduction in developer onboarding time and up to a 30% improvement in developer productivity.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerating-data-science-innovation-how-bayer-crop-science-used-aws-ai-ml-services-to-build-their-next-generation-mlops-service/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Combat financial fraud with GraphRAG on Amazon Bedrock Knowledge Bases</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_6/</link>
      <pubDate>Tue, 08 Jul 2025 16:10:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_6/</guid>
      <description>
        
          
            In this post, we show how to use Amazon Bedrock Knowledge Bases GraphRAG with Amazon Neptune Analytics to build a financial fraud detection solution.
Link to article: https://aws.amazon.com/blogs/machine-learning/combat-financial-fraud-with-graphrag-on-amazon-bedrock-knowledge-bases/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Classify call center conversations with Amazon Bedrock batch inference</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_7/</link>
      <pubDate>Tue, 08 Jul 2025 16:05:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_7/</guid>
      <description>
        
          
            In this post, we demonstrate how to build an end-to-end solution for text classification using the Amazon Bedrock batch inference capability with the Anthropic’s Claude Haiku model. We walk through classifying travel agency call center conversations into categories, showcasing how to generate synthetic training data, process large volumes of text data, and automate the entire workflow using AWS services.
Link to article: https://aws.amazon.com/blogs/machine-learning/classify-call-center-conversations-with-amazon-bedrock-batch-inference/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Effective cross-lingual LLM evaluation with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_8/</link>
      <pubDate>Tue, 08 Jul 2025 15:46:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_8/</guid>
      <description>
        
          
            In this post, we demonstrate how to use the evaluation features of Amazon Bedrock to deliver reliable results across language barriers without the need for localized prompts or custom infrastructure. Through comprehensive testing and analysis, we share practical strategies to help reduce the cost and complexity of multilingual evaluation while maintaining high standards across global large language model (LLM) deployments.
Link to article: https://aws.amazon.com/blogs/machine-learning/effective-cross-lingual-llm-evaluation-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Cohere Embed 4 multimodal embeddings model is now available on Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_9/</link>
      <pubDate>Tue, 08 Jul 2025 15:43:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2025/08_07_2025_9/</guid>
      <description>
        
          
            The Cohere Embed 4 multimodal embeddings model is now generally available on Amazon SageMaker JumpStart. The Embed 4 model is built for multimodal business documents, has leading multilingual capabilities, and offers notable improvement over Embed 3 across key benchmarks. In this post, we discuss the benefits and capabilities of this new model. We also walk you through how to deploy and use the Embed 4 model using SageMaker JumpStart.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
