<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 31 Jul 2025 17:44:31 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Introducing AWS Batch Support for Amazon SageMaker Training jobs</title>
      <link>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_0/</link>
      <pubDate>Thu, 31 Jul 2025 17:44:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_0/</guid>
      <description>
        
          
            AWS Batch now seamlessly integrates with Amazon SageMaker Training jobs. In this post, we discuss the benefits of managing and prioritizing ML training jobs to use hardware efficiently for your business. We also walk you through how to get started using this new capability and share suggested best practices, including the use of SageMaker training plans.
Link to article: https://aws.amazon.com/blogs/machine-learning/introducing-aws-batch-support-for-amazon-sagemaker-training-jobs/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Structured outputs with Amazon Nova: A guide for builders</title>
      <link>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_1/</link>
      <pubDate>Thu, 31 Jul 2025 16:44:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_1/</guid>
      <description>
        
          
            We launched constrained decoding to provide reliability when using tools for structured outputs. Now, tools can be used with Amazon Nova foundation models (FMs) to extract data based on complex schemas, reducing tool use errors by over 95%. In this post, we explore how you can use Amazon Nova FMs for structured output use cases.
Link to article: https://aws.amazon.com/blogs/machine-learning/structured-outputs-with-amazon-nova-a-guide-for-builders/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AI agents unifying structured and unstructured data: Transforming support analytics and beyond with Amazon Q Plugins</title>
      <link>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_2/</link>
      <pubDate>Thu, 31 Jul 2025 16:28:37 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_2/</guid>
      <description>
        
          
            Learn how to enhance Amazon Q with custom plugins to combine semantic search capabilities with precise analytics for AWS Support data. This solution enables more accurate answers to analytical questions by integrating structured data querying with RAG architecture, allowing teams to transform raw support cases and health events into actionable insights. Discover how this enhanced architecture delivers exact numerical analysis while maintaining natural language interactions for improved operational decision-making.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Strands Agents SDK: A technical deep dive into agent architectures and observability</title>
      <link>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_3/</link>
      <pubDate>Thu, 31 Jul 2025 16:22:07 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_3/</guid>
      <description>
        
          
            In this post, we first introduce the Strands Agents SDK and its core features. Then we explore how it integrates with AWS environments for secure, scalable deployments, and how it provides rich observability for production use. Finally, we discuss practical use cases, and present a step-by-step example to illustrate Strands in action.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-strands-agents-sdk-a-technical-deep-dive-into-agent-architectures-and-observability/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build dynamic web research agents with the Strands Agents SDK and Tavily</title>
      <link>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_6/</link>
      <pubDate>Thu, 31 Jul 2025 14:35:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_07_2025/31_07_2025_6/</guid>
      <description>
        
          
            In this post, we introduce how to combine Strands Agents with Tavily’s purpose-built web intelligence API, to create powerful research agents that excel at complex information gathering tasks while maintaining the security and compliance standards required for enterprise deployment.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-dynamic-web-research-agents-with-the-strands-agents-sdk-and-tavily/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate the creation of handout notes using Amazon Bedrock Data Automation</title>
      <link>https://www.dotnetramblings.com/post/30_07_2025/30_07_2025_3/</link>
      <pubDate>Wed, 30 Jul 2025 16:22:27 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_07_2025/30_07_2025_3/</guid>
      <description>
        
          
            In this post, we show how you can build an automated, serverless solution to transform webinar recordings into comprehensive handouts using Amazon Bedrock Data Automation for video analysis. We walk you through the implementation of Amazon Bedrock Data Automation to transcribe and detect slide changes, as well as the use of Amazon Bedrock foundation models (FMs) for transcription refinement, combined with custom AWS Lambda functions orchestrated by AWS Step Functions.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline GitHub workflows with generative AI using Amazon Bedrock and MCP</title>
      <link>https://www.dotnetramblings.com/post/30_07_2025/30_07_2025_4/</link>
      <pubDate>Wed, 30 Jul 2025 16:16:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_07_2025/30_07_2025_4/</guid>
      <description>
        
          
            This blog post explores how to create powerful agentic applications using the Amazon Bedrock FMs, LangGraph, and the Model Context Protocol (MCP), with a practical scenario of handling a GitHub workflow of issue analysis, code fixes, and pull request generation.
Link to article: https://aws.amazon.com/blogs/machine-learning/streamline-github-workflows-with-generative-ai-using-amazon-bedrock-and-mcp/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Generate suspicious transaction report drafts for financial compliance using generative AI</title>
      <link>https://www.dotnetramblings.com/post/29_07_2025/29_07_2025_0/</link>
      <pubDate>Tue, 29 Jul 2025 18:57:44 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_07_2025/29_07_2025_0/</guid>
      <description>
        
          
            A suspicious transaction report (STR) or suspicious activity report (SAR) is a type of report that a financial organization must submit to a financial regulator if they have reasonable grounds to suspect any financial transaction that has occurred or was attempted during their activities. In this post, we explore a solution that uses FMs available in Amazon Bedrock to create a draft STR.
Link to article: https://aws.amazon.com/blogs/machine-learning/generate-suspicious-transaction-report-drafts-for-financial-compliance-using-generative-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine-tune and deploy Meta Llama 3.2 Vision for generative AI-powered web automation using AWS DLCs, Amazon EKS, and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/29_07_2025/29_07_2025_1/</link>
      <pubDate>Tue, 29 Jul 2025 18:55:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_07_2025/29_07_2025_1/</guid>
      <description>
        
          
            In this post, we present a complete solution for fine-tuning and deploying the Llama-3.2-11B-Vision-Instruct model for web automation tasks. We demonstrate how to build a secure, scalable, and efficient infrastructure using AWS Deep Learning Containers (DLCs) on Amazon Elastic Kubernetes Service (Amazon EKS).
Link to article: https://aws.amazon.com/blogs/machine-learning/fine-tune-and-deploy-meta-llama-3-2-vision-for-generative-ai-powered-web-automation-using-aws-dlcs-amazon-eks-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Nippon India Mutual Fund improved the accuracy of AI assistant responses using advanced RAG methods on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/29_07_2025/29_07_2025_9/</link>
      <pubDate>Tue, 29 Jul 2025 14:57:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_07_2025/29_07_2025_9/</guid>
      <description>
        
          
            In this post, we examine a solution adopted by Nippon Life India Asset Management Limited that improves the accuracy of the response over a regular (naive) RAG approach by rewriting the user queries and aggregating and reranking the responses. The proposed solution uses enhanced RAG methods such as reranking to improve the overall accuracy
Link to article: https://aws.amazon.com/blogs/machine-learning/how-nippon-india-mutual-fund-improved-the-accuracy-of-ai-assistant-responses-using-advanced-rag-methods-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a drug discovery research assistant using Strands Agents and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_2/</link>
      <pubDate>Mon, 28 Jul 2025 19:14:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to create a powerful research assistant for drug discovery using Strands Agents and Amazon Bedrock. This AI assistant can search multiple scientific databases simultaneously using the Model Context Protocol (MCP), synthesize its findings, and generate comprehensive reports on drug targets, disease mechanisms, and therapeutic areas.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-drug-discovery-research-assistant-using-strands-agents-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Nova Act SDK (preview): Path to production for browser automation agents</title>
      <link>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_3/</link>
      <pubDate>Mon, 28 Jul 2025 17:54:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_3/</guid>
      <description>
        
          
            In this post, we’ll walk through what makes Nova Act SDK unique, how it works, and how teams across industries are already using it to automate browser-based workflows at scale.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-nova-act-sdk-preview-path-to-production-for-browser-automation-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimizing enterprise AI assistants: How Crypto.com uses LLM reasoning and feedback for enhanced efficiency</title>
      <link>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_4/</link>
      <pubDate>Mon, 28 Jul 2025 17:53:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_4/</guid>
      <description>
        
          
            In this post, we explore how Crypto.com used user and system feedback to continuously improve and optimize our instruction prompts. This feedback-driven approach has enabled us to create more effective prompts that adapt to various subsystems while maintaining high performance across different use cases.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimizing-enterprise-ai-assistants-how-crypto-com-uses-llm-reasoning-and-feedback-for-enhanced-efficiency/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build modern serverless solutions following best practices using Amazon Q Developer CLI and MCP</title>
      <link>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_5/</link>
      <pubDate>Mon, 28 Jul 2025 17:42:38 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_07_2025/28_07_2025_5/</guid>
      <description>
        
          
            This post explores how the AWS Serverless MCP server accelerates development throughout the serverless lifecycle, from making architectural decisions with tools like get_iac_guidance and get_lambda_guidance, to streamlining development with get_serverless_templates, sam_init, to deployment with SAM integration, webapp_deployment_help, and configure_domain. We show how this conversational AI approach transforms the entire process, from architecture design through operations, dramatically accelerating AWS serverless projects while adhering to architectural principles.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-modern-serverless-solutions-following-best-practices-using-amazon-q-developer-cli-and-mcp/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an intelligent eDiscovery solution using Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/25_07_2025/25_07_2025_2/</link>
      <pubDate>Fri, 25 Jul 2025 17:22:37 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_07_2025/25_07_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to build an intelligent eDiscovery solution using Amazon Bedrock Agents for real-time document analysis. We show how to deploy specialized agents for document classification, contract analysis, email review, and legal document processing, all working together through a multi-agent architecture. We walk through the implementation details, deployment steps, and best practices to create an extensible foundation that organizations can adapt to their specific eDiscovery requirements.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How PerformLine uses prompt engineering on Amazon Bedrock to detect compliance violations</title>
      <link>https://www.dotnetramblings.com/post/25_07_2025/25_07_2025_3/</link>
      <pubDate>Fri, 25 Jul 2025 17:03:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_07_2025/25_07_2025_3/</guid>
      <description>
        
          
            PerformLine operates within the marketing compliance industry, a specialized subset of the broader compliance software market, which includes various compliance solutions like anti-money laundering (AML), know your customer (KYC), and others. In this post, PerformLine and AWS explore how PerformLine used Amazon Bedrock to accelerate compliance processes, generate actionable insights, and provide contextual data—delivering the speed and accuracy essential for large-scale oversight.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-performline-uses-prompt-engineering-on-amazon-bedrock-to-detect-compliance-violations/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Boost cold-start recommendations with vLLM on AWS Trainium</title>
      <link>https://www.dotnetramblings.com/post/24_07_2025/24_07_2025_1/</link>
      <pubDate>Thu, 24 Jul 2025 20:17:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2025/24_07_2025_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to use vLLM for scalable inference and use AWS Deep Learning Containers (DLC) to streamline model packaging and deployment. We’ll generate interest expansions through structured prompts, encode them into embeddings, retrieve candidates with FAISS, apply validation to keep results grounded, and frame the cold-start challenge as a scientific experiment—benchmarking LLM and encoder pairings, iterating rapidly on recommendation metrics, and showing clear ROI for each configuration
          
          
        
      </description>
    </item>
    
    <item>
      <title>Benchmarking Amazon Nova: A comprehensive analysis through MT-Bench and Arena-Hard-Auto</title>
      <link>https://www.dotnetramblings.com/post/24_07_2025/24_07_2025_2/</link>
      <pubDate>Thu, 24 Jul 2025 18:39:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2025/24_07_2025_2/</guid>
      <description>
        
          
            The repositories for MT-Bench and Arena-Hard were originally developed using OpenAI’s GPT API, primarily employing GPT-4 as the judge. Our team has expanded its functionality by integrating it with the Amazon Bedrock API to enable using Anthropic’s Claude Sonnet on Amazon as judge. In this post, we use both MT-Bench and Arena-Hard to benchmark Amazon Nova models by comparing them to other leading LLMs available through Amazon Bedrock.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
