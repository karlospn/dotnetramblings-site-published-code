<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Mon, 25 Nov 2024 16:01:36 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How 123RF saved over 90% of their translation costs by switching to Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/25_11_2024/25_11_2024_3/</link>
      <pubDate>Mon, 25 Nov 2024 16:01:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_11_2024/25_11_2024_3/</guid>
      <description>
        
          
            This post explores how 123RF used Amazon Bedrock, Anthropic’s Claude 3 Haiku, and a vector store to efficiently translate content metadata, significantly reduce costs, and improve their global content discovery capabilities.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-123rf-saved-over-90-of-their-translation-costs-by-switching-to-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Connect SharePoint Online to Amazon Q Business using OAuth 2.0 ROPC flow authentication</title>
      <link>https://www.dotnetramblings.com/post/25_11_2024/25_11_2024_4/</link>
      <pubDate>Mon, 25 Nov 2024 15:59:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_11_2024/25_11_2024_4/</guid>
      <description>
        
          
            In this post, we explore how to integrate Amazon Q Business with SharePoint Online using the OAuth 2.0 ROPC flow authentication method. We provide both manual and automated approaches using PowerShell scripts for configuring the required Azure AD settings. Additionally, we demonstrate how to enter those details along with your SharePoint authentication credentials into the Amazon Q console to finalize the secure connection.
Link to article: https://aws.amazon.com/blogs/machine-learning/connect-sharepoint-online-to-amazon-q-business-using-oauth-2-0-ropc-flow-authentication/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>John Snow Labs Medical LLMs are now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/25_11_2024/25_11_2024_5/</link>
      <pubDate>Mon, 25 Nov 2024 15:55:17 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_11_2024/25_11_2024_5/</guid>
      <description>
        
          
            Today, we are excited to announce that John Snow Labs’ Medical LLM – Small and Medical LLM – Medium large language models (LLMs) are now available on Amazon SageMaker Jumpstart. For medical doctors, this tool provides a rapid understanding of a patient’s medical journey, aiding in timely and informed decision-making from extensive documentation. This summarization capability not only boosts efficiency but also makes sure that no critical details are overlooked, thereby supporting optimal patient care and enhancing healthcare outcomes.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerating Mixtral MoE fine-tuning on Amazon SageMaker with QLoRA</title>
      <link>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_0/</link>
      <pubDate>Fri, 22 Nov 2024 22:52:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_0/</guid>
      <description>
        
          
            In this post, we demonstrate how you can address the challenges of model customization being complex, time-consuming, and often expensive by using fully managed environment with Amazon SageMaker Training jobs to fine-tune the Mixtral 8x7B model using PyTorch Fully Sharded Data Parallel (FSDP) and Quantized Low Rank Adaptation (QLoRA).
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerating-mixtral-moe-fine-tuning-on-amazon-sagemaker-with-qlora/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon SageMaker Inference now supports G6e instances</title>
      <link>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_1/</link>
      <pubDate>Fri, 22 Nov 2024 19:56:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_1/</guid>
      <description>
        
          
            G6e instances on SageMaker unlock the ability to deploy a wide variety of open source models cost-effectively. With superior memory capacity, enhanced performance, and cost-effectiveness, these instances represent a compelling solution for organizations looking to deploy and scale their AI applications. The ability to handle larger models, support longer context lengths, and maintain high throughput makes G6e instances particularly valuable for modern AI applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-inference-now-supports-g6e-instances/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Orchestrate generative AI workflows with Amazon Bedrock and AWS Step Functions</title>
      <link>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_2/</link>
      <pubDate>Fri, 22 Nov 2024 18:51:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_2/</guid>
      <description>
        
          
            This post discusses how to use AWS Step Functions to efficiently coordinate multi-step generative AI workflows, such as parallelizing API calls to Amazon Bedrock to quickly gather answers to lists of submitted questions. We also touch on the usage of Retrieval Augmented Generation (RAG) to optimize outputs and provide an extra layer of precision, as well as other possible integrations through Step Functions.
Link to article: https://aws.amazon.com/blogs/machine-learning/orchestrate-generative-ai-workflows-with-amazon-bedrock-and-aws-step-functions/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build generative AI applications on Amazon Bedrock with the AWS SDK for Python (Boto3)</title>
      <link>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_3/</link>
      <pubDate>Fri, 22 Nov 2024 18:43:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_3/</guid>
      <description>
        
          
            In this post, we demonstrate how to use Amazon Bedrock with the AWS SDK for Python (Boto3) to programmatically incorporate FMs. We explore invoking a specific FM and processing the generated text, showcasing the potential for developers to use these models in their applications for a variety of use cases
Link to article: https://aws.amazon.com/blogs/machine-learning/build-generative-ai-applications-on-amazon-bedrock-with-the-aws-sdk-for-python-boto3/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Improve factual consistency with LLM Debates</title>
      <link>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_4/</link>
      <pubDate>Fri, 22 Nov 2024 18:40:55 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_4/</guid>
      <description>
        
          
            In this post, we demonstrate the potential of large language model (LLM) debates using a supervised dataset with ground truth. In this post, we navigate the LLM debating technique with persuasive LLMs having two expert debater LLMs (Anthropic Claude 3 Sonnet and Mixtral 8X7B) and one judge LLM (Mistral 7B v2 to measure, compare, and contrast its performance against other techniques like self-consistency (with naive and expert judges) and LLM consultancy.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Governing the ML lifecycle at scale, Part 3: Setting up data governance at scale</title>
      <link>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_5/</link>
      <pubDate>Fri, 22 Nov 2024 18:28:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_5/</guid>
      <description>
        
          
            This post dives deep into how to set up data governance at scale using Amazon DataZone for the data mesh. The data mesh is a modern approach to data management that decentralizes data ownership and treats data as a product. It enables different business units within an organization to create, share, and govern their own data assets, promoting self-service analytics and reducing the time required to convert data experiments into production-ready applications.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock Flows is now generally available with enhanced safety and traceability</title>
      <link>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_7/</link>
      <pubDate>Fri, 22 Nov 2024 18:09:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_7/</guid>
      <description>
        
          
            Today, we are excited to announce the general availability of Amazon Bedrock Flows (previously known as Prompt Flows). With Bedrock Flows, you can quickly build and execute complex generative AI workflows without writing code. Bedrock Flows makes it easier for developers and businesses to harness the power of generative AI, enabling you to create more sophisticated and efficient AI-driven solutions for your customers.
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-flows-is-now-generally-available-with-enhanced-safety-and-traceability/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implement secure API access to your Amazon Q Business applications with IAM federation user access management</title>
      <link>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_8/</link>
      <pubDate>Fri, 22 Nov 2024 18:02:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_11_2024/22_11_2024_8/</guid>
      <description>
        
          
            Amazon Q Business provides a rich set of APIs to perform administrative tasks and to build an AI assistant with customized user experience for your enterprise. In this post, we show how to use Amazon Q Business APIs when using AWS Identity and Access Management (IAM) federation for user access management.
Link to article: https://aws.amazon.com/blogs/machine-learning/implement-secure-api-access-to-your-amazon-q-business-applications-with-iam-federation-user-access-management/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhance speech synthesis and video generation models with RLHF using audio and video segmentation in Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/21_11_2024/21_11_2024_4/</link>
      <pubDate>Thu, 21 Nov 2024 17:27:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_11_2024/21_11_2024_4/</guid>
      <description>
        
          
            In this post, we show you how to implement an audio and video segmentation solution using SageMaker Ground Truth. We guide you through deploying the necessary infrastructure using AWS CloudFormation, creating an internal labeling workforce, and setting up your first labeling job. By the end of this post, you will have a fully functional audio/video segmentation workflow that you can adapt for various use cases, from training speech synthesis models to improving video generation capabilities.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Using responsible AI principles with Amazon Bedrock Batch Inference</title>
      <link>https://www.dotnetramblings.com/post/21_11_2024/21_11_2024_5/</link>
      <pubDate>Thu, 21 Nov 2024 17:23:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_11_2024/21_11_2024_5/</guid>
      <description>
        
          
            In this post, we explore a practical, cost-effective approach for incorporating responsible AI guardrails into Amazon Bedrock Batch Inference workflows. Although we use a call center’s transcript summarization as our primary example, the methods we discuss are broadly applicable to a variety of batch inference use cases where ethical considerations and data protection are a top priority.
Link to article: https://aws.amazon.com/blogs/machine-learning/using-responsible-ai-principles-with-amazon-bedrock-batch-inference/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Revolutionizing knowledge management: VW’s AI prototype journey with AWS</title>
      <link>https://www.dotnetramblings.com/post/21_11_2024/21_11_2024_6/</link>
      <pubDate>Thu, 21 Nov 2024 17:19:20 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_11_2024/21_11_2024_6/</guid>
      <description>
        
          
            we’re excited to share the journey of the VW—an innovator in the automotive industry and Europe’s largest car maker—to enhance knowledge management by using generative AI, Amazon Bedrock, and Amazon Kendra to devise a solution based on Retrieval Augmented Generation (RAG) that makes internal information more easily accessible by its users. This solution efficiently handles documents that include both text and images, significantly enhancing VW&#39;s knowledge management capabilities within their production domain.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine-tune large language models with Amazon SageMaker Autopilot</title>
      <link>https://www.dotnetramblings.com/post/21_11_2024/21_11_2024_7/</link>
      <pubDate>Thu, 21 Nov 2024 17:01:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_11_2024/21_11_2024_7/</guid>
      <description>
        
          
            Fine-tuning foundation models (FMs) is a process that involves exposing a pre-trained FM to task-specific data and fine-tuning its parameters. It can then develop a deeper understanding and produce more accurate and relevant outputs for that particular domain. In this post, we show how to use an Amazon SageMaker Autopilot training job with the AutoMLV2 […]
Link to article: https://aws.amazon.com/blogs/machine-learning/fine-tune-large-language-models-with-amazon-sagemaker-autopilot/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unify structured data in Amazon Aurora and unstructured data in Amazon S3 for insights using Amazon Q</title>
      <link>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_3/</link>
      <pubDate>Wed, 20 Nov 2024 16:15:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_3/</guid>
      <description>
        
          
            In today’s data-intensive business landscape, organizations face the challenge of extracting valuable insights from diverse data sources scattered across their infrastructure. Whether it’s structured data in databases or unstructured content in document repositories, enterprises often struggle to efficiently query and use this wealth of information. In this post, we explore how you can use Amazon […]
Link to article: https://aws.amazon.com/blogs/machine-learning/unify-structured-data-in-amazon-aurora-and-unstructured-data-in-amazon-s3-for-insights-using-amazon-q/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate Q&amp;A email responses with Amazon Bedrock Knowledge Bases</title>
      <link>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_4/</link>
      <pubDate>Wed, 20 Nov 2024 16:11:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_4/</guid>
      <description>
        
          
            In this post, we illustrate automating the responses to email inquiries by using Amazon Bedrock Knowledge Bases and Amazon Simple Email Service (Amazon SES), both fully managed services. By linking user queries to relevant company domain information, Amazon Bedrock Knowledge Bases offers personalized responses.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-qa-email-responses-with-amazon-bedrock-knowledge-bases/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline RAG applications with intelligent metadata filtering using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_5/</link>
      <pubDate>Wed, 20 Nov 2024 16:08:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_5/</guid>
      <description>
        
          
            In this post, we explore an innovative approach that uses LLMs on Amazon Bedrock to intelligently extract metadata filters from natural language queries. By combining the capabilities of LLM function calling and Pydantic data models, you can dynamically extract metadata from user queries. This approach can also enhance the quality of retrieved information and responses generated by the RAG applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/streamline-rag-applications-with-intelligent-metadata-filtering-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Embedding secure generative AI in mission-critical public safety applications</title>
      <link>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_7/</link>
      <pubDate>Wed, 20 Nov 2024 15:59:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_7/</guid>
      <description>
        
          
            This post shows how Mark43 uses Amazon Q Business to create a secure, generative AI-powered assistant that drives operational efficiency and improves community service. We explain how they embedded Amazon Q Business web experience in their web application with low code, so they could focus on creating a rich AI experience for their customers.
Link to article: https://aws.amazon.com/blogs/machine-learning/embedding-secure-generative-ai-in-mission-critical-public-safety-applications/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How FP8 boosts LLM training by 18% on Amazon SageMaker P5 instances</title>
      <link>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_8/</link>
      <pubDate>Wed, 20 Nov 2024 15:54:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_11_2024/20_11_2024_8/</guid>
      <description>
        
          
            LLM training has seen remarkable advances in recent years, with organizations pushing the boundaries of what’s possible in terms of model size, performance, and efficiency. In this post, we explore how FP8 optimization can significantly speed up large model training on Amazon SageMaker P5 instances.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-fp8-boosts-llm-training-by-18-on-amazon-sagemaker-p5-instances/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Racing into the future: How AWS DeepRacer fueled my AI and ML journey</title>
      <link>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_1/</link>
      <pubDate>Tue, 19 Nov 2024 20:52:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_1/</guid>
      <description>
        
          
            In 2018, I sat in the audience at AWS re:Invent as Andy Jassy announced AWS DeepRacer—a fully autonomous 1/18th scale race car driven by reinforcement learning. At the time, I knew little about AI or machine learning (ML). As an engineer transitioning from legacy networks to cloud technologies, I had never considered myself a developer. […]
Link to article: https://aws.amazon.com/blogs/machine-learning/racing-into-the-future-how-aws-deepracer-fueled-my-ai-and-ml-journey/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Your guide to generative AI and ML at AWS re:Invent 2024</title>
      <link>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_3/</link>
      <pubDate>Tue, 19 Nov 2024 20:25:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_3/</guid>
      <description>
        
          
            In this attendee guide, we’re highlighting a few of our favorite sessions to give you a glimpse into what’s in store. To help you plan your agenda for this year’s re:Invent, here are some highlights of the generative AI and ML sessions. Visit the session catalog to learn about all our generative AI and ML sessions.
Link to article: https://aws.amazon.com/blogs/machine-learning/your-guide-to-generative-ai-and-ml-at-aws-reinvent-2024/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Customize small language models on AWS with automotive terminology</title>
      <link>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_5/</link>
      <pubDate>Tue, 19 Nov 2024 18:13:43 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_5/</guid>
      <description>
        
          
            In this post, we guide you through the phases of customizing SLMs on AWS, with a specific focus on automotive terminology for diagnostics as a Q&amp;amp;A task. We begin with the data analysis phase and progress through the end-to-end process, covering fine-tuning, deployment, and evaluation. We compare a customized SLM with a general purpose LLM, using various metrics to assess vocabulary richness and overall accuracy.
Link to article: https://aws.amazon.com/blogs/machine-learning/customize-small-language-models-on-aws-with-automotive-terminology/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate emails for task management using Amazon Bedrock Agents, Amazon Bedrock Knowledge Bases, and Amazon Bedrock Guardrails</title>
      <link>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_6/</link>
      <pubDate>Tue, 19 Nov 2024 18:05:20 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_6/</guid>
      <description>
        
          
            In this post, we demonstrate how to create an automated email response solution using Amazon Bedrock and its features, including Amazon Bedrock Agents, Amazon Bedrock Knowledge Bases, and Amazon Bedrock Guardrails.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-emails-for-task-management-using-amazon-bedrock-agents-amazon-bedrock-knowledge-bases-and-amazon-bedrock-guardrails/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate analysis and discovery of cancer biomarkers with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_7/</link>
      <pubDate>Tue, 19 Nov 2024 18:02:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_7/</guid>
      <description>
        
          
            Bedrock agents can streamline workflows and provide AI automation to boost productivity. In this post, we show you how agentic workflows with Amazon Bedrock Agents can help accelerate this journey for research scientists with a natural language interface. We define an example analysis pipeline, specifically for lung cancer survival with clinical, genomics, and imaging modalities of biomarkers. We showcase a variety of tools including database retrieval with Text2SQL, statistical models and visual charts with scientific libraries, biomedical literature search with public APIs and internal evidence, and medical image processing with Amazon SageMaker jobs.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate building guardrails for Amazon Bedrock using test-driven development</title>
      <link>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_8/</link>
      <pubDate>Tue, 19 Nov 2024 17:57:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_11_2024/19_11_2024_8/</guid>
      <description>
        
          
            Amazon Bedrock Guardrails helps implement safeguards for generative AI applications based on specific use cases and responsible AI policies. Amazon Bedrock Guardrails assists in controlling the interaction between users and foundation models (FMs) by detecting and filtering out undesirable and potentially harmful content, while maintaining safety and privacy. In this post, we explore a solution that automates building guardrails using a test-driven development approach.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-building-guardrails-for-amazon-bedrock-using-test-driven-development/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build cost-effective RAG applications with Binary Embeddings in Amazon Titan Text Embeddings V2, Amazon OpenSearch Serverless, and Amazon Bedrock Knowledge Bases</title>
      <link>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_1/</link>
      <pubDate>Mon, 18 Nov 2024 20:09:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_1/</guid>
      <description>
        
          
            Today, we are happy to announce the availability of Binary Embeddings for Amazon Titan Text Embeddings V2 in Amazon Bedrock Knowledge Bases and Amazon OpenSearch Serverless. This post summarizes the benefits of this new binary vector support and gives you information on how you can get started.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-cost-effective-rag-applications-with-binary-embeddings-in-amazon-titan-text-embeddings-v2-amazon-opensearch-serverless-and-amazon-bedrock-knowledge-bases/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate cloud security vulnerability assessment and alerting using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_2/</link>
      <pubDate>Mon, 18 Nov 2024 20:08:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_2/</guid>
      <description>
        
          
            This post demonstrates a proactive approach for security vulnerability assessment of your accounts and workloads, using Amazon GuardDuty, Amazon Bedrock, and other AWS serverless technologies. This approach aims to identify potential vulnerabilities proactively and provide your users with timely alerts and recommendations, avoiding reactive escalations and other damages.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-cloud-security-vulnerability-assessment-and-alerting-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>DXC transforms data exploration for their oil and gas customers with LLM-powered tools</title>
      <link>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_3/</link>
      <pubDate>Mon, 18 Nov 2024 20:05:25 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_3/</guid>
      <description>
        
          
            In this post, we show you how DXC and AWS collaborated to build an AI assistant using large language models (LLMs), enabling users to access and analyze different data types from a variety of data sources. The AI assistant is powered by an intelligent agent that routes user questions to specialized tools that are optimized for different data types such as text, tables, and domain-specific formats. It uses the LLM’s ability to understand natural language, write code, and reason about conversational context.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How MSD uses Amazon Bedrock to translate natural language into SQL for complex healthcare databases</title>
      <link>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_5/</link>
      <pubDate>Mon, 18 Nov 2024 18:57:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_5/</guid>
      <description>
        
          
            MSD, a leading pharmaceutical company, collaborates with AWS to implement a powerful text-to-SQL generative AI solution using Amazon Bedrock and Anthropic&#39;s Claude 3.5 Sonnet model. This approach streamlines data extraction from complex healthcare databases like DE-SynPUF, enabling analysts to generate SQL queries from natural language questions. The solution addresses challenges such as coded columns, non-intuitive names, and ambiguous queries, significantly reducing query time and democratizing data access.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Generate AWS Resilience Hub findings in natural language using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_6/</link>
      <pubDate>Mon, 18 Nov 2024 18:51:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_6/</guid>
      <description>
        
          
            This blog post discusses a solution that combines AWS Resilience Hub and Amazon Bedrock to generate architectural findings in natural language. By using the capabilities of Resilience Hub and Amazon Bedrock, you can share findings with C-suite executives, engineers, managers, and other personas within your corporation to provide better visibility over maintaining a resilient architecture.
Link to article: https://aws.amazon.com/blogs/machine-learning/generate-aws-resilience-hub-findings-in-natural-language-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Generate and evaluate images in Amazon Bedrock with Amazon Titan Image Generator G1 v2 and Anthropic Claude 3.5 Sonnet</title>
      <link>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_7/</link>
      <pubDate>Mon, 18 Nov 2024 18:33:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_7/</guid>
      <description>
        
          
            In this post, we demonstrate how to interact with the Amazon Titan Image Generator G1 v2 model on Amazon Bedrock to generate an image. Then, we show you how to use Anthropic’s Claude 3.5 Sonnet on Amazon Bedrock to describe it, evaluate it with a score from 1–10, explain the reason behind the given score, and suggest improvements to the image.
Link to article: https://aws.amazon.com/blogs/machine-learning/generate-and-evaluate-images-in-amazon-bedrock-with-amazon-titan-image-generator-g1-v2-and-anthropic-claude-3-5-sonnet/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How InsuranceDekho transformed insurance agent interactions using Amazon Bedrock and generative AI</title>
      <link>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_8/</link>
      <pubDate>Mon, 18 Nov 2024 18:30:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_11_2024/18_11_2024_8/</guid>
      <description>
        
          
            In this post, we explain how InsuranceDekho harnessed the power of generative AI using Amazon Bedrock and Anthropic’s Claude to provide responses to customer queries on policy coverages, exclusions, and more. This let our customer care agents and POSPs confidently help our customers understand the policies without reaching out to insurance subject matter experts (SMEs) or memorizing complex plans while providing sales and after-sales services. The use of this solution has improved sales, cross-selling, and overall customer service experience.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
