<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Mon, 14 Apr 2025 16:47:42 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Build multi-agent systems with LangGraph and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/14_04_2025/14_04_2025_1/</link>
      <pubDate>Mon, 14 Apr 2025 16:47:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_04_2025/14_04_2025_1/</guid>
      <description>
        
          
            This post demonstrates how to integrate open-source multi-agent framework, LangGraph, with Amazon Bedrock. It explains how to use LangGraph and Amazon Bedrock to build powerful, interactive multi-agent applications that use graph-based orchestration.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-multi-agent-systems-with-langgraph-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Dynamic text-to-SQL for enterprise workloads with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/14_04_2025/14_04_2025_2/</link>
      <pubDate>Mon, 14 Apr 2025 16:44:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_04_2025/14_04_2025_2/</guid>
      <description>
        
          
            This post demonstrates how enterprises can implement a scalable agentic text-to-SQL solution using Amazon Bedrock Agents, with advanced error-handling tools and automated schema discovery to enhance database query efficiency.
Link to article: https://aws.amazon.com/blogs/machine-learning/dynamic-text-to-sql-for-enterprise-workloads-with-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building an AIOps chatbot with Amazon Q Business custom plugins</title>
      <link>https://www.dotnetramblings.com/post/11_04_2025/11_04_2025_3/</link>
      <pubDate>Fri, 11 Apr 2025 17:50:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_04_2025/11_04_2025_3/</guid>
      <description>
        
          
            In this post, we demonstrate how you can use custom plugins for Amazon Q Business to build a chatbot that can interact with multiple APIs using natural language prompts. We showcase how to build an AIOps chatbot that enables users to interact with their AWS infrastructure through natural language queries and commands. The chatbot is capable of handling tasks such as querying the data about Amazon Elastic Compute Cloud (Amazon EC2) ports and Amazon Simple Storage Service (Amazon S3) buckets access settings.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How TransPerfect Improved Translation Quality and Efficiency Using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/11_04_2025/11_04_2025_5/</link>
      <pubDate>Fri, 11 Apr 2025 17:25:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_04_2025/11_04_2025_5/</guid>
      <description>
        
          
            This post describes how the AWS Customer Channel Technology – Localization Team worked with TransPerfect to integrate Amazon Bedrock into the GlobalLink translation management system, a cloud-based solution designed to help organizations manage their multilingual content and translation workflows. Organizations use TransPerfect’s solution to rapidly create and deploy content at scale in multiple languages using AI.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-transperfect-improved-translation-quality-and-efficiency-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Racing beyond DeepRacer: Debut of the AWS LLM League</title>
      <link>https://www.dotnetramblings.com/post/11_04_2025/11_04_2025_6/</link>
      <pubDate>Fri, 11 Apr 2025 17:16:58 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_04_2025/11_04_2025_6/</guid>
      <description>
        
          
            The AWS LLM League was designed to lower the barriers to entry in generative AI model customization by providing an experience where participants, regardless of their prior data science experience, could engage in fine-tuning LLMs. Using Amazon SageMaker JumpStart, attendees were guided through the process of customizing LLMs to address real business challenges adaptable to their domain.
Link to article: https://aws.amazon.com/blogs/machine-learning/racing-beyond-deepracer-debut-of-the-aws-llm-league/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Reduce ML training costs with Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_1/</link>
      <pubDate>Thu, 10 Apr 2025 20:11:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_1/</guid>
      <description>
        
          
            In this post, we explore the challenges of large-scale frontier model training, focusing on hardware failures and the benefits of Amazon SageMaker HyperPod - a solution that minimizes disruptions, enhances efficiency, and reduces training costs.
Link to article: https://aws.amazon.com/blogs/machine-learning/reduce-ml-training-costs-with-amazon-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Model customization, RAG, or both: A case study with Amazon Nova</title>
      <link>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_6/</link>
      <pubDate>Thu, 10 Apr 2025 16:50:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_6/</guid>
      <description>
        
          
            The introduction of Amazon Nova models represent a significant advancement in the field of AI, offering new opportunities for large language model (LLM) optimization. In this post, we demonstrate how to effectively perform model customization and RAG with Amazon Nova models as a baseline. We conducted a comprehensive comparison study between model customization and RAG using the latest Amazon Nova models, and share these valuable insights.
Link to article: https://aws.amazon.com/blogs/machine-learning/model-customization-rag-or-both-a-case-study-with-amazon-nova/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Generate user-personalized communication with Amazon Personalize and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_7/</link>
      <pubDate>Thu, 10 Apr 2025 16:43:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_7/</guid>
      <description>
        
          
            In this post, we demonstrate how to use Amazon Personalize and Amazon Bedrock to generate personalized outreach emails for individual users using a video-on-demand use case. This concept can be applied to other domains, such as compelling customer experiences for ecommerce and digital marketing use cases.
Link to article: https://aws.amazon.com/blogs/machine-learning/generate-user-personalized-communication-with-amazon-personalize-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automating regulatory compliance: A multi-agent solution using Amazon Bedrock and CrewAI</title>
      <link>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_8/</link>
      <pubDate>Thu, 10 Apr 2025 16:39:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_8/</guid>
      <description>
        
          
            In this post, we explore how AI agents can streamline compliance and fulfill regulatory requirements for financial institutions using Amazon Bedrock and CrewAI. We demonstrate how to build a multi-agent system that can automatically summarize new regulations, assess their impact on operations, and provide prescriptive technical guidance. You&#39;ll learn how to use Amazon Bedrock Knowledge Bases and Amazon Bedrock Agents with CrewAI to create a comprehensive, automated compliance solution.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Pixtral Large is now available in Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_11/</link>
      <pubDate>Thu, 10 Apr 2025 15:30:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_04_2025/10_04_2025_11/</guid>
      <description>
        
          
            In this post, we demonstrate how to get started with the Pixtral Large model in Amazon Bedrock. The Pixtral Large multimodal model allows you to tackle a variety of use cases, such as document understanding, logical reasoning, handwriting recognition, image comparison, entity extraction, extracting structured data from scanned images, and caption generation.
Link to article: https://aws.amazon.com/blogs/machine-learning/pixtral-large-is-now-available-in-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implement human-in-the-loop confirmation with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/09_04_2025/09_04_2025_1/</link>
      <pubDate>Wed, 09 Apr 2025 19:46:34 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_04_2025/09_04_2025_1/</guid>
      <description>
        
          
            In this post, we focus specifically on enabling end-users to approve actions and provide feedback using built-in Amazon Bedrock Agents features, specifically HITL patterns for providing safe and effective agent operations. We explore the patterns available using a Human Resources (HR) agent example that helps employees requesting time off.
Link to article: https://aws.amazon.com/blogs/machine-learning/implement-human-in-the-loop-confirmation-with-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Boost team productivity with Amazon Q Business Insights</title>
      <link>https://www.dotnetramblings.com/post/09_04_2025/09_04_2025_4/</link>
      <pubDate>Wed, 09 Apr 2025 16:10:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_04_2025/09_04_2025_4/</guid>
      <description>
        
          
            In this post, we explore Amazon Q Business Insights capabilities and its importance for organizations. We begin with an overview of the available metrics and how they can be used for measuring user engagement and system effectiveness. Then we provide instructions for accessing and navigating this dashboard.
Link to article: https://aws.amazon.com/blogs/machine-learning/boost-team-productivity-with-amazon-q-business-insights/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Multi-LLM routing strategies for generative AI applications on AWS</title>
      <link>https://www.dotnetramblings.com/post/09_04_2025/09_04_2025_5/</link>
      <pubDate>Wed, 09 Apr 2025 16:02:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_04_2025/09_04_2025_5/</guid>
      <description>
        
          
            Organizations are increasingly using multiple large language models (LLMs) when building generative AI applications. Although an individual LLM can be highly capable, it might not optimally address a wide range of use cases or meet diverse performance requirements. The multi-LLM approach enables organizations to effectively choose the right model for each task, adapt to different […]
Link to article: https://aws.amazon.com/blogs/machine-learning/multi-llm-routing-strategies-for-generative-ai-applications-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How iFood built a platform to run hundreds of machine learning models with Amazon SageMaker Inference</title>
      <link>https://www.dotnetramblings.com/post/08_04_2025/08_04_2025_4/</link>
      <pubDate>Tue, 08 Apr 2025 17:37:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_04_2025/08_04_2025_4/</guid>
      <description>
        
          
            In this post, we show how iFood uses SageMaker to revolutionize its ML operations. By harnessing the power of SageMaker, iFood streamlines the entire ML lifecycle, from model training to deployment. This integration not only simplifies complex processes but also automates critical tasks.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-ifood-built-a-platform-to-run-hundreds-of-machine-learning-models-with-amazon-sagemaker-inference/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an enterprise synthetic data strategy using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/08_04_2025/08_04_2025_5/</link>
      <pubDate>Tue, 08 Apr 2025 16:40:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_04_2025/08_04_2025_5/</guid>
      <description>
        
          
            In this post, we explore how to use Amazon Bedrock for synthetic data generation, considering these challenges alongside the potential benefits to develop effective strategies for various applications across multiple industries, including AI and machine learning (ML).
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-enterprise-synthetic-data-strategy-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Llama 4 family of models from Meta are now available in SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_0/</link>
      <pubDate>Mon, 07 Apr 2025 22:54:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_0/</guid>
      <description>
        
          
            Today, we’re excited to announce the availability of Llama 4 Scout and Maverick models in Amazon SageMaker JumpStart. In this blog post, we walk you through how to deploy and prompt a Llama-4-Scout-17B-16E-Instruct model using SageMaker JumpStart.
Link to article: https://aws.amazon.com/blogs/machine-learning/llama-4-family-of-models-from-meta-are-now-available-in-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Multi-tenancy in RAG applications in a single Amazon Bedrock knowledge base with metadata filtering</title>
      <link>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_1/</link>
      <pubDate>Mon, 07 Apr 2025 21:56:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_1/</guid>
      <description>
        
          
            This post demonstrates how Amazon Bedrock Knowledge Bases can help you scale your data management effectively while maintaining proper access controls on different management levels.
Link to article: https://aws.amazon.com/blogs/machine-learning/multi-tenancy-in-rag-applications-in-a-single-amazon-bedrock-knowledge-base-with-metadata-filtering/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Effectively use prompt caching on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_2/</link>
      <pubDate>Mon, 07 Apr 2025 21:53:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_2/</guid>
      <description>
        
          
            Prompt caching, now generally available on Amazon Bedrock with Anthropic’s Claude 3.5 Haiku and Claude 3.7 Sonnet, along with Nova Micro, Nova Lite, and Nova Pro models, lowers response latency by up to 85% and reduces costs up to 90% by caching frequently used prompts across multiple API calls. This post provides a detailed overview of the prompt caching feature on Amazon Bedrock and offers guidance on how to effectively use this feature to achieve improved latency and cost savings.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Advanced tracing and evaluation of generative AI agents using LangChain and Amazon SageMaker AI MLFlow</title>
      <link>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_4/</link>
      <pubDate>Mon, 07 Apr 2025 17:45:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_04_2025/07_04_2025_4/</guid>
      <description>
        
          
            In this post, I show you how to combine LangChain&#39;s LangGraph, Amazon SageMaker AI, and MLflow to demonstrate a powerful workflow for developing, evaluating, and deploying sophisticated generative AI agents. This integration provides the tools needed to gain deep insights into the generative AI agent&#39;s performance, iterate quickly, and maintain version control throughout the development process.
Link to article: https://aws.amazon.com/blogs/machine-learning/advanced-tracing-and-evaluation-of-generative-ai-agents-using-langchain-and-amazon-sagemaker-ai-mlflow/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
