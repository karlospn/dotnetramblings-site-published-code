<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Mon, 22 Dec 2025 18:37:13 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Move Beyond Chain-of-Thought with Chain-of-Draft on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/22_12_2025/22_12_2025_1/</link>
      <pubDate>Mon, 22 Dec 2025 18:37:13 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_12_2025/22_12_2025_1/</guid>
      <description>
        
          
            This post explores Chain-of-Draft (CoD), an innovative prompting technique introduced in a Zoom AI Research paper Chain of Draft: Thinking Faster by Writing Less, that revolutionizes how models approach reasoning tasks. While Chain-of-Thought (CoT) prompting has been the go-to method for enhancing model reasoning, CoD offers a more efficient alternative that mirrors human problem-solving patterns—using concise, high-signal thinking steps rather than verbose explanations.
Link to article: https://aws.amazon.com/blogs/machine-learning/move-beyond-chain-of-thought-with-chain-of-draft-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deploy Mistral AI’s Voxtral on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/22_12_2025/22_12_2025_2/</link>
      <pubDate>Mon, 22 Dec 2025 18:32:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_12_2025/22_12_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate hosting Voxtral models on Amazon SageMaker AI endpoints using vLLM and the Bring Your Own Container (BYOC) approach. vLLM is a high-performance library for serving large language models (LLMs) that features paged attention for improved memory management and tensor parallelism for distributing models across multiple GPUs.
Link to article: https://aws.amazon.com/blogs/machine-learning/deploy-mistral-ais-voxtral-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhance document analytics with Strands AI Agents for the GenAI IDP Accelerator</title>
      <link>https://www.dotnetramblings.com/post/22_12_2025/22_12_2025_3/</link>
      <pubDate>Mon, 22 Dec 2025 18:26:17 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_12_2025/22_12_2025_3/</guid>
      <description>
        
          
            To address the need for businesses to quickly analyze information and unlock actionable insights, we are announcing Analytics Agent, a new feature that is seamlessly integrated into the GenAI IDP Accelerator. With this feature, users can perform advanced searches and complex analyses using natural language queries without SQL or data analysis expertise. In this post, we discuss how non-technical users can use this tool to analyze and understand the documents they have processed at scale with natural language.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a multimodal generative AI assistant for root cause diagnosis in predictive maintenance using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/22_12_2025/22_12_2025_4/</link>
      <pubDate>Mon, 22 Dec 2025 18:21:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_12_2025/22_12_2025_4/</guid>
      <description>
        
          
            In this post, we demonstrate how to implement a predictive maintenance solution using Foundation Models (FMs) on Amazon Bedrock, with a case study of Amazon&#39;s manufacturing equipment within their fulfillment centers. The solution is highly adaptable and can be customized for other industries, including oil and gas, logistics, manufacturing, and healthcare.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-multimodal-generative-ai-assistant-for-root-cause-diagnosis-in-predictive-maintenance-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Introducing SOCI indexing for Amazon SageMaker Studio: Faster container startup times for AI/ML workloads</title>
      <link>https://www.dotnetramblings.com/post/19_12_2025/19_12_2025_2/</link>
      <pubDate>Fri, 19 Dec 2025 18:23:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_12_2025/19_12_2025_2/</guid>
      <description>
        
          
            Today, we are excited to introduce a new feature for SageMaker Studio: SOCI (Seekable Open Container Initiative) indexing. SOCI supports lazy loading of container images, where only the necessary parts of an image are downloaded initially rather than the entire container.
Link to article: https://aws.amazon.com/blogs/machine-learning/introducing-soci-indexing-for-amazon-sagemaker-studio-faster-container-startup-times-for-ai-ml-workloads/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build and deploy scalable AI agents with NVIDIA NeMo, Amazon Bedrock AgentCore, and Strands Agents</title>
      <link>https://www.dotnetramblings.com/post/18_12_2025/18_12_2025_3/</link>
      <pubDate>Thu, 18 Dec 2025 17:26:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_12_2025/18_12_2025_3/</guid>
      <description>
        
          
            This post demonstrates how to use the powerful combination of Strands Agents, Amazon Bedrock AgentCore, and NVIDIA NeMo Agent Toolkit to build, evaluate, optimize, and deploy AI agents on Amazon Web Services (AWS) from initial development through production deployment.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-and-deploy-scalable-ai-agents-with-nvidia-nemo-amazon-bedrock-agentcore-and-strands-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Bi-directional streaming for real-time agent interactions now available in Amazon Bedrock AgentCore Runtime</title>
      <link>https://www.dotnetramblings.com/post/18_12_2025/18_12_2025_4/</link>
      <pubDate>Thu, 18 Dec 2025 17:00:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_12_2025/18_12_2025_4/</guid>
      <description>
        
          
            In this post, you will learn about bi-directional streaming on AgentCore Runtime and the prerequisites to create a WebSocket implementation. You will also learn how to use Strands Agents to implement a bi-directional streaming solution for voice agents.
Link to article: https://aws.amazon.com/blogs/machine-learning/bi-directional-streaming-for-real-time-agent-interactions-now-available-in-amazon-bedrock-agentcore-runtime/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Tracking and managing assets used in AI development with Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/17_12_2025/17_12_2025_1/</link>
      <pubDate>Wed, 17 Dec 2025 16:53:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_12_2025/17_12_2025_1/</guid>
      <description>
        
          
            In this post, we&#39;ll explore the new capabilities and core concepts that help organizations track and manage models development and deployment lifecycles. We will show you how the features are configured to train models with automatic end-to-end lineage, from dataset upload and versioning to model fine-tuning, evaluation, and seamless endpoint deployment.
Link to article: https://aws.amazon.com/blogs/machine-learning/tracking-and-managing-assets-used-in-ai-development-with-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Track machine learning experiments with MLflow on Amazon SageMaker using Snowflake integration</title>
      <link>https://www.dotnetramblings.com/post/17_12_2025/17_12_2025_2/</link>
      <pubDate>Wed, 17 Dec 2025 16:50:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_12_2025/17_12_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to integrate Amazon SageMaker managed MLflow as a central repository to log these experiments and provide a unified system for monitoring their progress.
Link to article: https://aws.amazon.com/blogs/machine-learning/track-machine-learning-experiments-with-mlflow-on-amazon-sagemaker-using-snowflake-integration/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Governance by design: The essential guide for successful AI scaling</title>
      <link>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_2/</link>
      <pubDate>Tue, 16 Dec 2025 21:18:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_2/</guid>
      <description>
        
          
            Picture this: Your enterprise has just deployed its first generative AI application. The initial results are promising, but as you plan to scale across departments, critical questions emerge. How will you enforce consistent security, prevent model bias, and maintain control as AI applications multiply?
Link to article: https://aws.amazon.com/blogs/machine-learning/governance-by-design-the-essential-guide-for-successful-ai-scaling/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Tata Power CoE built a scalable AI-powered solar panel inspection solution with Amazon SageMaker AI and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_4/</link>
      <pubDate>Tue, 16 Dec 2025 18:55:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_4/</guid>
      <description>
        
          
            In this post, we explore how Tata Power CoE and Oneture Technologies use AWS services to automate the inspection process end-to-end.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-tata-power-coe-built-a-scalable-ai-powered-solar-panel-inspection-solution-with-amazon-sagemaker-ai-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlocking video understanding with TwelveLabs Marengo on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_5/</link>
      <pubDate>Tue, 16 Dec 2025 18:51:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_5/</guid>
      <description>
        
          
            In this post, we&#39;ll show how the TwelveLabs Marengo embedding model, available on Amazon Bedrock, enhances video understanding through multimodal AI. We&#39;ll build a video semantic search and analysis solution using embeddings from the Marengo model with Amazon OpenSearch Serverless as the vector database, for semantic search capabilities that go beyond simple metadata matching to deliver intelligent content discovery.
Link to article: https://aws.amazon.com/blogs/machine-learning/unlocking-video-understanding-with-twelvelabs-marengo-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
