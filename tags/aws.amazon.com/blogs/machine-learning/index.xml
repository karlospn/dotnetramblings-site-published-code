<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 11 Apr 2024 19:21:54 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cost-effective document classification using the Amazon Titan Multimodal Embeddings Model</title>
      <link>https://www.dotnetramblings.com/post/11_04_2024/11_04_2024_2/</link>
      <pubDate>Thu, 11 Apr 2024 19:21:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_04_2024/11_04_2024_2/</guid>
      <description>
        
          
            Organizations across industries want to categorize and extract insights from high volumes of documents of different formats. Manually processing these documents to classify and extract information remains expensive, error prone, and difficult to scale. Advances in generative artificial intelligence (AI) have given rise to intelligent document processing (IDP) solutions that can automate the document classification, […]
Link to article: https://aws.amazon.com/blogs/machine-learning/cost-effective-document-classification-using-the-amazon-titan-multimodal-embeddings-model/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS at NVIDIA GTC 2024: Accelerate innovation with generative AI on AWS</title>
      <link>https://www.dotnetramblings.com/post/11_04_2024/11_04_2024_4/</link>
      <pubDate>Thu, 11 Apr 2024 16:14:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_04_2024/11_04_2024_4/</guid>
      <description>
        
          
            AWS was delighted to present to and connect with over 18,000 in-person and 267,000 virtual attendees at NVIDIA GTC, a global artificial intelligence (AI) conference that took place March 2024 in San Jose, California, returning to a hybrid, in-person experience for the first time since 2019. AWS has had a long-standing collaboration with NVIDIA for […]
Link to article: https://aws.amazon.com/blogs/machine-learning/aws-at-nvidia-gtc-2024-accelerate-innovation-with-generative-ai-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an active learning pipeline for automatic annotation of images with AWS services</title>
      <link>https://www.dotnetramblings.com/post/10_04_2024/10_04_2024_1/</link>
      <pubDate>Wed, 10 Apr 2024 16:26:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_04_2024/10_04_2024_1/</guid>
      <description>
        
          
            This blog post is co-written with Caroline Chung from Veoneer. Veoneer is a global automotive electronics company and a world leader in automotive electronic safety systems. They offer best-in-class restraint control systems and have delivered over 1 billion electronic control units and crash sensors to car manufacturers globally. The company continues to build on a […]
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-active-learning-pipeline-for-automatic-annotation-of-images-with-aws-services/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Knowledge Bases for Amazon Bedrock now supports custom prompts for the RetrieveAndGenerate API and configuration of the maximum number of retrieved results</title>
      <link>https://www.dotnetramblings.com/post/09_04_2024/09_04_2024_1/</link>
      <pubDate>Tue, 09 Apr 2024 19:01:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_04_2024/09_04_2024_1/</guid>
      <description>
        
          
            With Knowledge Bases for Amazon Bedrock, you can securely connect foundation models (FMs) in Amazon Bedrock to your company data for Retrieval Augmented Generation (RAG). Access to additional data helps the model generate more relevant, context-specific, and accurate responses without retraining the FMs. In this post, we discuss two new features of Knowledge Bases for […]
Link to article: https://aws.amazon.com/blogs/machine-learning/knowledge-bases-for-amazon-bedrock-now-supports-custom-prompts-for-the-retrieveandgenerate-api-and-configuration-of-the-maximum-number-of-retrieved-results/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Knowledge Bases for Amazon Bedrock now supports metadata filtering to improve retrieval accuracy</title>
      <link>https://www.dotnetramblings.com/post/08_04_2024/08_04_2024_0/</link>
      <pubDate>Mon, 08 Apr 2024 19:23:02 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_04_2024/08_04_2024_0/</guid>
      <description>
        
          
            At AWS re:Invent 2023, we announced the general availability of Knowledge Bases for Amazon Bedrock. With Knowledge Bases for Amazon Bedrock, you can securely connect foundation models (FMs) in Amazon Bedrock to your company data using a fully managed Retrieval Augmented Generation (RAG) model. For RAG-based applications, the accuracy of the generated responses from FMs […]
Link to article: https://aws.amazon.com/blogs/machine-learning/knowledge-bases-for-amazon-bedrock-now-supports-metadata-filtering-to-improve-retrieval-accuracy/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build knowledge-powered conversational applications using LlamaIndex and Llama 2-Chat</title>
      <link>https://www.dotnetramblings.com/post/08_04_2024/08_04_2024_1/</link>
      <pubDate>Mon, 08 Apr 2024 17:03:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_04_2024/08_04_2024_1/</guid>
      <description>
        
          
            Unlocking accurate and insightful answers from vast amounts of text is an exciting capability enabled by large language models (LLMs). When building LLM applications, it is often necessary to connect and query external data sources to provide relevant context to the model. One popular approach is using Retrieval Augmented Generation (RAG) to create Q&amp;amp;A systems […]
Link to article: https://aws.amazon.com/blogs/machine-learning/build-knowledge-powered-conversational-applications-using-llamaindex-and-llama-2-chat/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use everyday language to search and retrieve data with Mixtral 8x7B on Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/08_04_2024/08_04_2024_2/</link>
      <pubDate>Mon, 08 Apr 2024 16:53:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_04_2024/08_04_2024_2/</guid>
      <description>
        
          
            With the widespread adoption of generative artificial intelligence (AI) solutions, organizations are trying to use these technologies to make their teams more productive. One exciting use case is enabling natural language interactions with relational databases. Rather than writing complex SQL queries, you can describe in plain language what data you want to retrieve or manipulate. […]
Link to article: https://aws.amazon.com/blogs/machine-learning/use-everyday-language-to-search-and-retrieve-data-with-mixtral-8x7b-on-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Boost inference performance for Mixtral and Llama 2 models with new Amazon SageMaker containers</title>
      <link>https://www.dotnetramblings.com/post/08_04_2024/08_04_2024_3/</link>
      <pubDate>Mon, 08 Apr 2024 16:50:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_04_2024/08_04_2024_3/</guid>
      <description>
        
          
            In January 2024, Amazon SageMaker launched a new version (0.26.0) of Large Model Inference (LMI) Deep Learning Containers (DLCs). This version offers support for new models (including Mixture of Experts), performance and usability improvements across inference backends, as well as new generation details for increased control and prediction explainability (such as reason for generation completion […]
Link to article: https://aws.amazon.com/blogs/machine-learning/boost-inference-performance-for-mixtral-and-llama-2-models-with-new-amazon-sagemaker-containers/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
