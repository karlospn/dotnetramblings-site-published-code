<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Mon, 26 Aug 2024 20:30:08 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Secure RAG applications using prompt engineering on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/26_08_2024/26_08_2024_0/</link>
      <pubDate>Mon, 26 Aug 2024 20:30:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_08_2024/26_08_2024_0/</guid>
      <description>
        
          
            In this post, we discuss existing prompt-level threats and outline several security guardrails for mitigating prompt-level threats. For our example, we work with Anthropic Claude on Amazon Bedrock, implementing prompt templates that allow us to enforce guardrails against common security threats such as prompt injection. These templates are compatible with and can be modified for other LLMs.
Link to article: https://aws.amazon.com/blogs/machine-learning/secure-rag-applications-using-prompt-engineering-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Get the most from Amazon Titan Text Premier</title>
      <link>https://www.dotnetramblings.com/post/26_08_2024/26_08_2024_1/</link>
      <pubDate>Mon, 26 Aug 2024 20:03:34 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_08_2024/26_08_2024_1/</guid>
      <description>
        
          
            In this post, we introduce the new Amazon Titan Text Premier model, specifically optimized for enterprise use cases, such as building Retrieval Augmented Generation (RAG) and agent-based applications. Such integrations enable advanced applications like building interactive AI assistants that use enterprise APIs and interact with your propriety documents.
Link to article: https://aws.amazon.com/blogs/machine-learning/get-the-most-from-amazon-titan-text-premier/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>GenASL: Generative AI-powered American Sign Language avatars</title>
      <link>https://www.dotnetramblings.com/post/26_08_2024/26_08_2024_2/</link>
      <pubDate>Mon, 26 Aug 2024 19:49:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_08_2024/26_08_2024_2/</guid>
      <description>
        
          
            In this post, we dive into the architecture and implementation details of GenASL, which uses AWS generative AI capabilities to create human-like ASL avatar videos. GenASL is a solution that translates speech or text into expressive ASL avatar animations, bridging the gap between spoken and written language and sign language.
Link to article: https://aws.amazon.com/blogs/machine-learning/genasl-generative-ai-powered-american-sign-language-avatars/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS empowers sales teams using generative AI solution built on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/26_08_2024/26_08_2024_9/</link>
      <pubDate>Mon, 26 Aug 2024 14:22:25 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_08_2024/26_08_2024_9/</guid>
      <description>
        
          
            Through this series of posts, we share our generative AI journey and use cases, detailing the architecture, AWS services used, lessons learned, and the impact of these solutions on our teams and customers. In this first post, we explore Account Summaries, one of our initial production use cases built on Amazon Bedrock. Account Summaries equips our teams to be better prepared for customer engagements. It combines information from various sources into comprehensive, on-demand summaries available in our CRM or proactively delivered based on upcoming meetings.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build private and secure enterprise generative AI applications with Amazon Q Business using IAM Federation</title>
      <link>https://www.dotnetramblings.com/post/23_08_2024/23_08_2024_5/</link>
      <pubDate>Fri, 23 Aug 2024 01:23:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_08_2024/23_08_2024_5/</guid>
      <description>
        
          
            Amazon Q Business is a conversational assistant powered by generative artificial intelligence (AI) that enhances workforce productivity by answering questions and completing tasks based on information in your enterprise systems, which each user is authorized to access. In an earlier post, we discussed how you can build private and secure enterprise generative AI applications with Amazon Q Business and AWS IAM Identity Center. If you want to use Amazon Q Business to build enterprise generative AI applications, and have yet to adopt organization-wide use of AWS IAM Identity Center, you can use Amazon Q Business IAM Federation to directly manage user access to Amazon Q Business applications from your enterprise identity provider (IdP), such as Okta or Ping Identity.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unleashing the power of generative AI: Verisk’s Discovery Navigator revolutionizes medical record review</title>
      <link>https://www.dotnetramblings.com/post/22_08_2024/22_08_2024_0/</link>
      <pubDate>Thu, 22 Aug 2024 22:39:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_08_2024/22_08_2024_0/</guid>
      <description>
        
          
            In this post, we describe the development of the automated summary feature in Verisk&#39;s Discovery Navigator incorporating generative AI, the data, the architecture, and the evaluation of the pipeline. This new functionality offers an immediate overview of the initial injury and current medical status, empowering record reviewers of all skill levels to quickly assess injury severity with the click of a button.
Link to article: https://aws.amazon.com/blogs/machine-learning/unleashing-the-power-of-generative-ai-verisks-discovery-navigator-revolutionizes-medical-record-review/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Index your Atlassian Confluence Cloud contents using the Amazon Q Confluence Cloud connector for Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/22_08_2024/22_08_2024_1/</link>
      <pubDate>Thu, 22 Aug 2024 20:46:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_08_2024/22_08_2024_1/</guid>
      <description>
        
          
            In this post, we provide an overview of Amazon Q Business Confluence Cloud connector and how you can use it for seamless integration of generative AI assistance to your Confluence Cloud.
Link to article: https://aws.amazon.com/blogs/machine-learning/index-your-atlassian-confluence-cloud-contents-using-the-amazon-q-confluence-cloud-connector-for-amazon-q-business/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Snowflake Arctic models are now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/22_08_2024/22_08_2024_2/</link>
      <pubDate>Thu, 22 Aug 2024 19:22:46 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_08_2024/22_08_2024_2/</guid>
      <description>
        
          
            Today, we are excited to announce that the Snowflake Arctic Instruct model is available through Amazon SageMaker JumpStart to deploy and run inference. In this post, we walk through how to discover and deploy the Snowflake Arctic Instruct model using SageMaker JumpStart, and provide example use cases with specific prompts.
Link to article: https://aws.amazon.com/blogs/machine-learning/snowflake-arctic-models-are-now-available-in-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine tune a generative AI application for Amazon Bedrock using Amazon SageMaker Pipeline decorators</title>
      <link>https://www.dotnetramblings.com/post/22_08_2024/22_08_2024_3/</link>
      <pubDate>Thu, 22 Aug 2024 18:30:34 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_08_2024/22_08_2024_3/</guid>
      <description>
        
          
            In this post, we show you how to convert Python code that fine-tunes a generative AI model in Amazon Bedrock from local files to a reusable workflow using Amazon SageMaker Pipelines decorators.
Link to article: https://aws.amazon.com/blogs/machine-learning/fine-tune-a-generative-ai-application-for-amazon-bedrock-using-amazon-sagemaker-pipeline-decorators/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhance call center efficiency using batch inference for transcript summarization with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_0/</link>
      <pubDate>Wed, 21 Aug 2024 22:50:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_0/</guid>
      <description>
        
          
            Today, we are excited to announce general availability of batch inference for Amazon Bedrock. This new feature enables organizations to process large volumes of data when interacting with foundation models (FMs), addressing a critical need in various industries, including call center operations. In this post, we demonstrate the capabilities of batch inference using call center transcript summarization as an example.
Link to article: https://aws.amazon.com/blogs/machine-learning/enhance-call-center-efficiency-using-batch-inference-for-transcript-summarization-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fine-tune Meta Llama 3.1 models for generative AI inference using Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_1/</link>
      <pubDate>Wed, 21 Aug 2024 22:34:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_1/</guid>
      <description>
        
          
            Fine-tuning Meta Llama 3.1 models with Amazon SageMaker JumpStart enables developers to customize these publicly available foundation models (FMs). The Meta Llama 3.1 collection represents a significant advancement in the field of generative artificial intelligence (AI), offering a range of capabilities to create innovative applications. The Meta Llama 3.1 models come in various sizes, with 8 billion, 70 billion, and 405 billion parameters, catering to diverse project needs. In this post, we demonstrate how to fine-tune Meta Llama 3-1 pre-trained text generation models using SageMaker JumpStart.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Analyze customer reviews using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_4/</link>
      <pubDate>Wed, 21 Aug 2024 17:00:01 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_4/</guid>
      <description>
        
          
            This post explores an innovative application of large language models (LLMs) to automate the process of customer review analysis. LLMs are a type of foundation model (FM) that have been pre-trained on vast amounts of text data. This post discusses how LLMs can be accessed through Amazon Bedrock to build a generative AI solution that automatically summarizes key information, recognizes the customer sentiment, and generates actionable insights from customer reviews. This method shows significant promise in saving human analysts time while producing high-quality results.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accuracy evaluation framework for Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_5/</link>
      <pubDate>Wed, 21 Aug 2024 16:43:16 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_5/</guid>
      <description>
        
          
            Generative artificial intelligence (AI), particularly Retrieval Augmented Generation (RAG) solutions, are rapidly demonstrating their vast potential to revolutionize enterprise operations. RAG models combine the strengths of information retrieval systems with advanced natural language generation, enabling more contextually accurate and informative outputs. From automating customer interactions to optimizing backend operation processes, these technologies are not just […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accuracy-evaluation-framework-for-amazon-q-business/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Elevate healthcare interaction and documentation with Amazon Bedrock and Amazon Transcribe using Live Meeting Assistant</title>
      <link>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_6/</link>
      <pubDate>Wed, 21 Aug 2024 16:40:19 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_6/</guid>
      <description>
        
          
            Today, physicians spend about 49% of their workday documenting clinical visits, which impacts physician productivity and patient care. Did you know that for every eight hours that office-based physicians have scheduled with patients, they spend more than five hours in the EHR? As a consequence, healthcare practitioners exhibit a pronounced inclination towards conversational intelligence solutions, […]
Link to article: https://aws.amazon.com/blogs/machine-learning/elevate-healthcare-interaction-and-documentation-with-amazon-bedrock-and-amazon-transcribe-using-live-meeting-assistant/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlock the power of data governance and no-code machine learning with Amazon SageMaker Canvas and Amazon DataZone</title>
      <link>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_7/</link>
      <pubDate>Wed, 21 Aug 2024 16:28:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_7/</guid>
      <description>
        
          
            Amazon DataZone is a data management service that makes it quick and convenient to catalog, discover, share, and govern data stored in AWS, on-premises, and third-party sources. Amazon DataZone allows you to create and manage data zones, which are virtual data lakes that store and process your data, without the need for extensive coding or […]
Link to article: https://aws.amazon.com/blogs/machine-learning/unlock-the-power-of-data-governance-and-no-code-machine-learning-with-amazon-sagemaker-canvas-and-amazon-datazone/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate performance using a custom chunking mechanism with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_8/</link>
      <pubDate>Wed, 21 Aug 2024 16:15:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_08_2024/21_08_2024_8/</guid>
      <description>
        
          
            This post explores how Accenture used the customization capabilities of Knowledge Bases for Amazon Bedrock to incorporate their data processing workflow and custom logic to create a custom chunking mechanism that enhances the performance of Retrieval Augmented Generation (RAG) and unlock the potential of your PDF data.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-performance-using-a-custom-chunking-mechanism-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Migrate Amazon SageMaker Data Wrangler flows to Amazon SageMaker Canvas for faster data preparation</title>
      <link>https://www.dotnetramblings.com/post/20_08_2024/20_08_2024_1/</link>
      <pubDate>Tue, 20 Aug 2024 17:34:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_08_2024/20_08_2024_1/</guid>
      <description>
        
          
            This post demonstrates how you can bring your existing SageMaker Data Wrangler flows—the instructions created when building data transformations—from SageMaker Studio Classic to SageMaker Canvas. We provide an example of moving files from SageMaker Studio Classic to Amazon Simple Storage Service (Amazon S3) as an intermediate step before importing them into SageMaker Canvas.
Link to article: https://aws.amazon.com/blogs/machine-learning/migrate-amazon-sagemaker-data-wrangler-flows-to-amazon-sagemaker-canvas-for-faster-data-preparation/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use IP-restricted presigned URLs to enhance security in Amazon SageMaker Ground Truth</title>
      <link>https://www.dotnetramblings.com/post/20_08_2024/20_08_2024_4/</link>
      <pubDate>Tue, 20 Aug 2024 15:24:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_08_2024/20_08_2024_4/</guid>
      <description>
        
          
            While presigned URLs offer a convenient way to grant temporary access to S3 objects, sharing these URLs with people outside of the workteam can lead to unintended access of those objects. To mitigate this risk and enhance the security of SageMaker Ground Truth labeling tasks, we have introduced a new feature that adds an additional layer of security by restricting access to the presigned URLs to the worker’s IP address or virtual private cloud (VPC) endpoint from which they access the labeling task.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlock the power of structured data for enterprises using natural language with Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/20_08_2024/20_08_2024_5/</link>
      <pubDate>Tue, 20 Aug 2024 15:15:29 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/20_08_2024/20_08_2024_5/</guid>
      <description>
        
          
            In this post, we discuss an architecture to query structured data using Amazon Q Business, and build out an application to query cost and usage data in Amazon Athena with Amazon Q Business. Amazon Q Business can create SQL queries to your data sources when provided with the database schema, additional metadata describing the columns and tables, and prompting instructions. You can extend this architecture to use additional data sources, query validation, and prompting techniques to cover a wider range of use cases.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Cohere Rerank 3 Nimble now generally available on Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/19_08_2024/19_08_2024_2/</link>
      <pubDate>Mon, 19 Aug 2024 16:41:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_08_2024/19_08_2024_2/</guid>
      <description>
        
          
            The Cohere Rerank 3 Nimble foundation model (FM) is now generally available in Amazon SageMaker JumpStart. This model is the newest FM in Cohere’s Rerank model series, built to enhance enterprise search and Retrieval Augmented Generation (RAG) systems. In this post, we discuss the benefits and capabilities of this new model with some examples. Overview […]
Link to article: https://aws.amazon.com/blogs/machine-learning/cohere-rerank-3-nimble-now-generally-available-on-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
