<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 03 Sep 2024 21:13:59 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Build a generative AI image description application with Anthropic’s Claude 3.5 Sonnet on Amazon Bedrock and AWS CDK</title>
      <link>https://www.dotnetramblings.com/post/03_09_2024/03_09_2024_1/</link>
      <pubDate>Tue, 03 Sep 2024 21:13:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_09_2024/03_09_2024_1/</guid>
      <description>
        
          
            In this post, we delve into the process of building and deploying a sample application capable of generating multilingual descriptions for multiple images with a Streamlit UI, AWS Lambda powered with the Amazon Bedrock SDK, and AWS AppSync driven by the open source Generative AI CDK Constructs.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-generative-ai-image-description-application-with-anthropics-claude-3-5-sonnet-on-amazon-bedrock-and-aws-cdk/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use LangChain with PySpark to process documents at massive scale with Amazon SageMaker Studio and Amazon EMR Serverless</title>
      <link>https://www.dotnetramblings.com/post/03_09_2024/03_09_2024_2/</link>
      <pubDate>Tue, 03 Sep 2024 19:05:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_09_2024/03_09_2024_2/</guid>
      <description>
        
          
            In this post, we explore how to build a scalable and efficient Retrieval Augmented Generation (RAG) system using the new EMR Serverless integration, Spark’s distributed processing, and an Amazon OpenSearch Service vector database powered by the LangChain orchestration framework. This solution enables you to process massive volumes of textual data, generate relevant embeddings, and store them in a powerful vector database for seamless retrieval and generation.
Link to article: https://aws.amazon.com/blogs/machine-learning/use-langchain-with-pyspark-to-process-documents-at-massive-scale-with-amazon-sagemaker-studio-and-amazon-emr-serverless/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Best practices for prompt engineering with Meta Llama 3 for Text-to-SQL use cases</title>
      <link>https://www.dotnetramblings.com/post/30_08_2024/30_08_2024_0/</link>
      <pubDate>Fri, 30 Aug 2024 20:36:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_08_2024/30_08_2024_0/</guid>
      <description>
        
          
            In this post, we explore a solution that uses the vector engine ChromaDB and Meta Llama 3, a publicly available foundation model hosted on SageMaker JumpStart, for a Text-to-SQL use case. We shared a brief history of Meta Llama 3, best practices for prompt engineering with Meta Llama 3 models, and an architecture pattern using few-shot prompting and RAG to extract the relevant schemas stored as vectors in ChromaDB.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implementing advanced prompt engineering with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/30_08_2024/30_08_2024_1/</link>
      <pubDate>Fri, 30 Aug 2024 20:09:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_08_2024/30_08_2024_1/</guid>
      <description>
        
          
            In this post, we provide insights and practical examples to help balance and optimize the prompt engineering workflow. We focus on advanced prompt techniques and best practices for the models provided in Amazon Bedrock, a fully managed service that offers a choice of high-performing foundation models from leading AI companies such as Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon through a single API. With these prompting techniques, developers and researchers can harness the full capabilities of Amazon Bedrock, providing clear and concise communication while mitigating potential risks or undesirable outputs.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate Generative AI Inference with NVIDIA NIM Microservices on Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/29_08_2024/29_08_2024_0/</link>
      <pubDate>Thu, 29 Aug 2024 22:26:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_08_2024/29_08_2024_0/</guid>
      <description>
        
          
            In this post, we provide a walkthrough of how customers can use generative artificial intelligence (AI) models and LLMs using NVIDIA NIM integration with SageMaker. We demonstrate how this integration works and how you can deploy these state-of-the-art models on SageMaker, optimizing their performance and cost.
Link to article: https://aws.amazon.com/blogs/machine-learning/get-started-with-nvidia-nim-inference-microservices-on-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Celebrating the final AWS DeepRacer  League championship and road ahead</title>
      <link>https://www.dotnetramblings.com/post/29_08_2024/29_08_2024_3/</link>
      <pubDate>Thu, 29 Aug 2024 19:01:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_08_2024/29_08_2024_3/</guid>
      <description>
        
          
            The AWS DeepRacer League is the world’s first autonomous racing league, open to everyone and powered by machine learning (ML). AWS DeepRacer brings builders together from around the world, creating a community where you learn ML hands-on through friendly autonomous racing competitions. As we celebrate the achievements of over 560,000 participants from more than 150 countries who sharpened their skills through the AWS DeepRacer League over the last 6 years, we also prepare to close this chapter with a final season that serves as both a victory lap and a launching point for what’s next in the world of AWS DeepRacer.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Provide a personalized experience for news readers using Amazon Personalize and Amazon Titan Text Embeddings on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/29_08_2024/29_08_2024_8/</link>
      <pubDate>Thu, 29 Aug 2024 17:00:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_08_2024/29_08_2024_8/</guid>
      <description>
        
          
            In this post, we show how you can recommend breaking news to a user using AWS AI/ML services. By taking advantage of the power of Amazon Personalize and Amazon Titan Text Embeddings on Amazon Bedrock, you can show articles to interested users within seconds of them being published.
Link to article: https://aws.amazon.com/blogs/machine-learning/provide-a-personalized-experience-for-news-readers-using-amazon-personalize-and-amazon-titan-text-embeddings-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implementing tenant isolation using Agents for Amazon Bedrock in a multi-tenant environment</title>
      <link>https://www.dotnetramblings.com/post/28_08_2024/28_08_2024_1/</link>
      <pubDate>Wed, 28 Aug 2024 20:57:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_08_2024/28_08_2024_1/</guid>
      <description>
        
          
            In this blog post, we will show you how to implement tenant isolation using Amazon Bedrock agents within a multi-tenant environment. We’ll demonstrate this using a sample multi-tenant e-commerce application that provides a service for various tenants to create online stores. This application will use Amazon Bedrock agents to develop an AI assistant or chatbot capable of providing tenant-specific information, such as return policies and user-specific information like order counts and status updates.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Connect the Amazon Q Business generative AI coding companion to your GitHub repositories with Amazon Q GitHub (Cloud) connector</title>
      <link>https://www.dotnetramblings.com/post/28_08_2024/28_08_2024_2/</link>
      <pubDate>Wed, 28 Aug 2024 20:29:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_08_2024/28_08_2024_2/</guid>
      <description>
        
          
            In this post, we show you how to perform natural language queries over the indexed GitHub (Cloud) data using the AI-powered chat interface provided by Amazon Q Business. We also cover how Amazon Q Business applies access control lists (ACLs) associated with the indexed documents to provide permissions-filtered responses.
Link to article: https://aws.amazon.com/blogs/machine-learning/connect-the-amazon-q-business-generative-ai-coding-companion-to-your-github-repositories-with-amazon-q-github-cloud-connector/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Elevate customer experience through an intelligent email automation solution using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/28_08_2024/28_08_2024_3/</link>
      <pubDate>Wed, 28 Aug 2024 20:14:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_08_2024/28_08_2024_3/</guid>
      <description>
        
          
            In this post, we show you how to use Amazon Bedrock to automate email responses to customer queries. With our solution, you can identify the intent of customer emails and send an automated response if the intent matches your existing knowledge base or data sources. If the intent doesn’t have a match, the email goes to the support team for a manual response.
Link to article: https://aws.amazon.com/blogs/machine-learning/elevate-customer-experience-through-an-intelligent-email-automation-solution-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an end-to-end RAG solution using Knowledge Bases for Amazon Bedrock and the AWS CDK</title>
      <link>https://www.dotnetramblings.com/post/28_08_2024/28_08_2024_4/</link>
      <pubDate>Wed, 28 Aug 2024 20:06:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_08_2024/28_08_2024_4/</guid>
      <description>
        
          
            In this post, we demonstrate how to seamlessly automate the deployment of an end-to-end RAG solution using Knowledge Bases for Amazon Bedrock and the AWS Cloud Development Kit (AWS CDK), enabling organizations to quickly set up a powerful question answering system.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-end-to-end-rag-solution-using-knowledge-bases-for-amazon-bedrock-and-the-aws-cdk/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
