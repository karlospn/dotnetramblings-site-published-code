<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Tue, 30 Jul 2024 13:03:24 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Intuit uses Amazon Bedrock and Anthropic’s Claude to explain taxes in TurboTax to millions of consumer tax filers</title>
      <link>https://www.dotnetramblings.com/post/30_07_2024/30_07_2024_0/</link>
      <pubDate>Tue, 30 Jul 2024 13:03:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_07_2024/30_07_2024_0/</guid>
      <description>
        
          
            Intuit is committed to providing its customers innovative solutions that simplify complex financial processes. Tax filing can be a challenge, with its ever-changing regulations and intricate nuances. That’s why the company empowers millions of individuals and small businesses to comprehend tax-related information effortlessly and file with full confidence that their taxes are done right. For the […]
Link to article: https://aws.amazon.com/blogs/machine-learning/intuit-uses-amazon-bedrock-and-anthropic-claude-to-explain-taxes-in-turbotax-to-millions-of-consumer-tax-filers/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build generative AI–powered Salesforce applications with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/29_07_2024/29_07_2024_1/</link>
      <pubDate>Mon, 29 Jul 2024 21:48:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_07_2024/29_07_2024_1/</guid>
      <description>
        
          
            In this post, we show how native integrations between Salesforce and Amazon Web Services (AWS) enable you to Bring Your Own Large Language Models (BYO LLMs) from your AWS account to power generative artificial intelligence (AI) applications in Salesforce. Requests and responses between Salesforce and Amazon Bedrock pass through the Einstein Trust Layer, which promotes responsible AI use across Salesforce.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-generative-ai-powered-salesforce-applications-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Transition your Amazon Forecast usage to Amazon SageMaker Canvas</title>
      <link>https://www.dotnetramblings.com/post/29_07_2024/29_07_2024_2/</link>
      <pubDate>Mon, 29 Jul 2024 19:47:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_07_2024/29_07_2024_2/</guid>
      <description>
        
          
            Amazon Forecast is a fully managed service that uses statistical and machine learning (ML) algorithms to deliver highly accurate time series forecasts. Launched in August 2019, Forecast predates Amazon SageMaker Canvas, a popular low-code no-code AWS tool for building, customizing, and deploying ML models, including time series forecasting models. With SageMaker Canvas, you get faster […]
Link to article: https://aws.amazon.com/blogs/machine-learning/transition-your-amazon-forecast-usage-to-amazon-sagemaker-canvas/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Connect Amazon Q Business to Microsoft SharePoint Online using least privilege access controls</title>
      <link>https://www.dotnetramblings.com/post/29_07_2024/29_07_2024_7/</link>
      <pubDate>Mon, 29 Jul 2024 17:46:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_07_2024/29_07_2024_7/</guid>
      <description>
        
          
            Amazon Q Business is the generative artificial intelligence (AI) assistant that empowers employees with your company’s knowledge and data. Microsoft SharePoint Online is used by many organizations as a secure place to store, organize, share, and access their internal data. With generative AI, employees can get answers to their questions, summarize content, or generate insights […]
Link to article: https://aws.amazon.com/blogs/machine-learning/connect-amazon-q-business-to-microsoft-sharepoint-online-using-least-privilege-access-controls/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Improve the productivity of your customer support and project management teams using Amazon Q Business and Atlassian Jira</title>
      <link>https://www.dotnetramblings.com/post/29_07_2024/29_07_2024_8/</link>
      <pubDate>Mon, 29 Jul 2024 17:39:03 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/29_07_2024/29_07_2024_8/</guid>
      <description>
        
          
            Effective customer support and project management are critical aspects of providing effective customer relationship management. Atlassian Jira, a platform for issue tracking and project management functions for software projects, has become an indispensable part of many organizations’ workflows to ensure success of the customer and the product. However, extracting valuable insights from the vast amount […]
Link to article: https://aws.amazon.com/blogs/machine-learning/improve-the-productivity-of-your-customer-support-and-project-management-teams-using-amazon-q-business-and-atlassian-jira/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon SageMaker inference launches faster auto scaling for generative AI models</title>
      <link>https://www.dotnetramblings.com/post/25_07_2024/25_07_2024_0/</link>
      <pubDate>Thu, 25 Jul 2024 21:13:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_07_2024/25_07_2024_0/</guid>
      <description>
        
          
            Today, we are excited to announce a new capability in Amazon SageMaker inference that can help you reduce the time it takes for your generative artificial intelligence (AI) models to scale automatically. You can now use sub-minute metrics and significantly reduce overall scaling latency for generative AI models. With this enhancement, you can improve the […]
Link to article: https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-inference-launches-faster-auto-scaling-for-generative-ai-models/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Find answers accurately and quickly using Amazon Q Business with the SharePoint Online connector</title>
      <link>https://www.dotnetramblings.com/post/25_07_2024/25_07_2024_3/</link>
      <pubDate>Thu, 25 Jul 2024 17:53:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_07_2024/25_07_2024_3/</guid>
      <description>
        
          
            Amazon Q Business is a fully managed, generative artificial intelligence (AI)-powered assistant that helps enterprises unlock the value of their data and knowledge. With Amazon Q, you can quickly find answers to questions, generate summaries and content, and complete tasks by using the information and expertise stored across your company’s various data sources and enterprise […]
Link to article: https://aws.amazon.com/blogs/machine-learning/find-answers-accurately-and-quickly-using-amazon-q-business-with-the-sharepoint-online-connector/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluate conversational AI agents with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/25_07_2024/25_07_2024_4/</link>
      <pubDate>Thu, 25 Jul 2024 17:47:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_07_2024/25_07_2024_4/</guid>
      <description>
        
          
            As conversational artificial intelligence (AI) agents gain traction across industries, providing reliability and consistency is crucial for delivering seamless and trustworthy user experiences. However, the dynamic and conversational nature of these interactions makes traditional testing and evaluation methods challenging. Conversational AI agents also encompass multiple layers, from Retrieval Augmented Generation (RAG) to function-calling mechanisms that […]
Link to article: https://aws.amazon.com/blogs/machine-learning/evaluate-conversational-ai-agents-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Node problem detection and recovery for AWS Neuron nodes within Amazon EKS clusters</title>
      <link>https://www.dotnetramblings.com/post/25_07_2024/25_07_2024_5/</link>
      <pubDate>Thu, 25 Jul 2024 17:39:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_07_2024/25_07_2024_5/</guid>
      <description>
        
          
            In the post, we introduce the AWS Neuron node problem detector and recovery DaemonSet for AWS Trainium and AWS Inferentia on Amazon Elastic Kubernetes Service (Amazon EKS). This component can quickly detect rare occurrences of issues when Neuron devices fail by tailing monitoring logs. It marks the worker nodes in a defective Neuron device as unhealthy, and promptly replaces them with new worker nodes. By accelerating the speed of issue detection and remediation, it increases the reliability of your ML training and reduces the wasted time and cost due to hardware failure.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Mistral Large 2 is now available in Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_1/</link>
      <pubDate>Wed, 24 Jul 2024 20:14:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_1/</guid>
      <description>
        
          
            Mistral AI’s Mistral Large 2 (24.07) foundation model (FM) is now generally available in Amazon Bedrock. Mistral Large 2 is the newest version of Mistral Large, and according to Mistral AI offers significant improvements across multilingual capabilities, math, reasoning, coding, and much more. In this post, we discuss the benefits and capabilities of this new […]
Link to article: https://aws.amazon.com/blogs/machine-learning/mistral-large-2-is-now-available-in-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>LLM experimentation at scale using Amazon SageMaker Pipelines and MLflow</title>
      <link>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_2/</link>
      <pubDate>Wed, 24 Jul 2024 19:01:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_2/</guid>
      <description>
        
          
            Large language models (LLMs) have achieved remarkable success in various natural language processing (NLP) tasks, but they may not always generalize well to specific domains or tasks. You may need to customize an LLM to adapt to your unique use case, improving its performance on your specific dataset or task. You can customize the model […]
Link to article: https://aws.amazon.com/blogs/machine-learning/llm-experimentation-at-scale-using-amazon-sagemaker-pipelines-and-mlflow/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Discover insights from Amazon S3 with Amazon Q S3 connector</title>
      <link>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_3/</link>
      <pubDate>Wed, 24 Jul 2024 18:53:41 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_3/</guid>
      <description>
        
          
            Amazon Q is a fully managed, generative artificial intelligence (AI) powered assistant that you can configure to answer questions, provide summaries, generate content, gain insights, and complete tasks based on data in your enterprise. The enterprise data required for these generative-AI powered assistants can reside in varied repositories across your organization. One common repository to […]
Link to article: https://aws.amazon.com/blogs/machine-learning/discover-insights-from-amazon-s3-with-amazon-q-s3-connector/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Boosting Salesforce Einstein’s code generating model performance with Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_5/</link>
      <pubDate>Wed, 24 Jul 2024 16:52:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_07_2024/24_07_2024_5/</guid>
      <description>
        
          
            This post is a joint collaboration between Salesforce and AWS and is being cross-published on both the Salesforce Engineering Blog and the AWS Machine Learning Blog. Salesforce, Inc. is an American cloud-based software company headquartered in San Francisco, California. It provides customer relationship management (CRM) software and applications focused on sales, customer service, marketing automation, […]
Link to article: https://aws.amazon.com/blogs/machine-learning/boosting-salesforce-einsteins-code-generating-model-performance-with-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Detect and protect sensitive data with Amazon Lex and Amazon CloudWatch Logs</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_2/</link>
      <pubDate>Tue, 23 Jul 2024 20:01:37 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_2/</guid>
      <description>
        
          
            In today’s digital landscape, the protection of personally identifiable information (PII) is not just a regulatory requirement, but a cornerstone of consumer trust and business integrity. Organizations use advanced natural language detection services like Amazon Lex for building conversational interfaces and Amazon CloudWatch for monitoring and analyzing operational data. One risk many organizations face is […]
Link to article: https://aws.amazon.com/blogs/machine-learning/detect-and-protect-sensitive-data-with-amazon-lex-and-amazon-cloudwatch-logs/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS AI chips deliver high performance and low cost for Llama 3.1 models on AWS</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_7/</link>
      <pubDate>Tue, 23 Jul 2024 16:18:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_7/</guid>
      <description>
        
          
            Today, we are excited to announce AWS Trainium and AWS Inferentia support for fine-tuning and inference of the Llama 3.1 models. The Llama 3.1 family of multilingual large language models (LLMs) is a collection of pre-trained and instruction tuned generative models in 8B, 70B, and 405B sizes. In a previous post, we covered how to deploy Llama 3 models on AWS Trainium and Inferentia based instances in Amazon SageMaker JumpStart. In this post, we outline how to get started with fine-tuning and deploying the Llama 3.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use Llama 3.1 405B to generate synthetic data for fine-tuning tasks</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_8/</link>
      <pubDate>Tue, 23 Jul 2024 16:18:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_8/</guid>
      <description>
        
          
            Today, we are excited to announce the availability of the Llama 3.1 405B model on Amazon SageMaker JumpStart, and Amazon Bedrock in preview. The Llama 3.1 models are a collection of state-of-the-art pre-trained and instruct fine-tuned generative artificial intelligence (AI) models in 8B, 70B, and 405B sizes. Amazon SageMaker JumpStart is a machine learning (ML) hub that provides access to algorithms, models, and ML solutions so you can quickly get started with ML.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Llama 3.1 models are now available in Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_9/</link>
      <pubDate>Tue, 23 Jul 2024 16:16:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_07_2024/23_07_2024_9/</guid>
      <description>
        
          
            Today, we are excited to announce that the state-of-the-art Llama 3.1 collection of multilingual large language models (LLMs), which includes pre-trained and instruction tuned generative AI models in 8B, 70B, and 405B sizes, is available through Amazon SageMaker JumpStart to deploy for inference. Llama is a publicly accessible LLM designed for developers, researchers, and businesses to build, experiment, and responsibly scale their generative artificial intelligence (AI) ideas. In this post, we walk through how to discover and deploy Llama 3.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
