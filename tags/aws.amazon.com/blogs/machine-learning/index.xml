<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Wed, 10 Jul 2024 15:30:06 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fine-tune Anthropic’s Claude 3 Haiku in Amazon Bedrock to boost model accuracy and quality</title>
      <link>https://www.dotnetramblings.com/post/10_07_2024/10_07_2024_0/</link>
      <pubDate>Wed, 10 Jul 2024 15:30:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/10_07_2024/10_07_2024_0/</guid>
      <description>
        
          
            Frontier large language models (LLMs) like Anthropic Claude on Amazon Bedrock are trained on vast amounts of data, allowing Anthropic Claude to understand and generate human-like text. Fine-tuning Anthropic Claude 3 Haiku on proprietary datasets can provide optimal performance on specific domains or tasks. The fine-tuning as a deep level of customization represents a key […]
Link to article: https://aws.amazon.com/blogs/machine-learning/fine-tune-anthropics-claude-3-haiku-in-amazon-bedrock-to-boost-model-accuracy-and-quality/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Achieve up to ~2x higher throughput while reducing costs by up to ~50% for generative AI inference on Amazon SageMaker with the new inference optimization toolkit – Part 2</title>
      <link>https://www.dotnetramblings.com/post/09_07_2024/09_07_2024_0/</link>
      <pubDate>Tue, 09 Jul 2024 21:59:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2024/09_07_2024_0/</guid>
      <description>
        
          
            As generative artificial intelligence (AI) inference becomes increasingly critical for businesses, customers are seeking ways to scale their generative AI operations or integrate generative AI models into existing workflows. Model optimization has emerged as a crucial step, allowing organizations to balance cost-effectiveness and responsiveness, improving productivity. However, price-performance requirements vary widely across use cases. For […]
Link to article: https://aws.amazon.com/blogs/machine-learning/achieve-up-to-2x-higher-throughput-while-reducing-costs-by-up-to-50-for-generative-ai-inference-on-amazon-sagemaker-with-the-new-inference-optimization-toolkit-part-2/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Achieve up to ~2x higher throughput while reducing costs by ~50% for generative AI inference on Amazon SageMaker with the new inference optimization toolkit – Part 1</title>
      <link>https://www.dotnetramblings.com/post/09_07_2024/09_07_2024_1/</link>
      <pubDate>Tue, 09 Jul 2024 21:59:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2024/09_07_2024_1/</guid>
      <description>
        
          
            Today, Amazon SageMaker announced a new inference optimization toolkit that helps you reduce the time it takes to optimize generative artificial intelligence (AI) models from months to hours, to achieve best-in-class performance for your use case. With this new capability, you can choose from a menu of optimization techniques, apply them to your generative AI […]
Link to article: https://aws.amazon.com/blogs/machine-learning/achieve-up-to-2x-higher-throughput-while-reducing-costs-by-50-for-generative-ai-inference-on-amazon-sagemaker-with-the-new-inference-optimization-toolkit-part-1/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Anthropic Claude 3.5 Sonnet ranks number 1 for business and finance in S&amp;P AI Benchmarks by Kensho</title>
      <link>https://www.dotnetramblings.com/post/09_07_2024/09_07_2024_2/</link>
      <pubDate>Tue, 09 Jul 2024 20:09:02 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/09_07_2024/09_07_2024_2/</guid>
      <description>
        
          
            Anthropic Claude 3.5 Sonnet currently ranks at the top of S&amp;amp;P AI Benchmarks by Kensho, which assesses large language models (LLMs) for finance and business. Kensho is the AI Innovation Hub for S&amp;amp;P Global. Using Amazon Bedrock, Kensho was able to quickly run Anthropic Claude 3.5 Sonnet through a challenging suite of business and financial […]
Link to article: https://aws.amazon.com/blogs/machine-learning/anthropic-claude-3-5-sonnet-ranks-number-1-for-business-and-finance-in-sp-ai-benchmarks-by-kensho/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>The Weather Company enhances MLOps with Amazon SageMaker, AWS CloudFormation, and Amazon CloudWatch</title>
      <link>https://www.dotnetramblings.com/post/08_07_2024/08_07_2024_0/</link>
      <pubDate>Mon, 08 Jul 2024 19:12:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2024/08_07_2024_0/</guid>
      <description>
        
          
            In this post, we share the story of how The Weather Company (TWCo) enhanced its MLOps platform using services such as Amazon SageMaker, AWS CloudFormation, and Amazon CloudWatch. TWCo data scientists and ML engineers took advantage of automation, detailed experiment tracking, integrated training, and deployment pipelines to help scale MLOps effectively. TWCo reduced infrastructure management time by 90% while also reducing model deployment time by 20%.
Link to article: https://aws.amazon.com/blogs/machine-learning/the-weather-company-enhances-mlops-with-amazon-sagemaker-aws-cloudformation-and-amazon-cloudwatch/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Eviden scales AWS DeepRacer Global League using AWS DeepRacer Event Manager</title>
      <link>https://www.dotnetramblings.com/post/08_07_2024/08_07_2024_1/</link>
      <pubDate>Mon, 08 Jul 2024 18:59:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2024/08_07_2024_1/</guid>
      <description>
        
          
            Eviden is a next-gen technology leader in data-driven, trusted, and sustainable digital transformation. With a strong portfolio of patented technologies and worldwide leading positions in advanced computing, security, AI, cloud, and digital platforms, Eviden provides deep expertise for a multitude of industries in more than 47 countries. Eviden is an AWS Premier partner, bringing together […]
Link to article: https://aws.amazon.com/blogs/machine-learning/eviden-scales-aws-deepracer-global-league-using-aws-deepracer-event-manager/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Generate unique images by fine-tuning Stable Diffusion XL with Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/08_07_2024/08_07_2024_2/</link>
      <pubDate>Mon, 08 Jul 2024 18:47:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_07_2024/08_07_2024_2/</guid>
      <description>
        
          
            Stable Diffusion XL by Stability AI is a high-quality text-to-image deep learning model that allows you to generate professional-looking images in various styles. Managed versions of Stable Diffusion XL are already available to you on Amazon SageMaker JumpStart (see Use Stable Diffusion XL with Amazon SageMaker JumpStart in Amazon SageMaker Studio) and Amazon Bedrock (see […]
Link to article: https://aws.amazon.com/blogs/machine-learning/generate-unique-images-by-fine-tuning-stable-diffusion-xl-with-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build your multilingual personal calendar assistant with Amazon Bedrock and AWS Step Functions</title>
      <link>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_0/</link>
      <pubDate>Wed, 03 Jul 2024 16:57:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_0/</guid>
      <description>
        
          
            This post shows you how to apply AWS services such as Amazon Bedrock, AWS Step Functions, and Amazon Simple Email Service (Amazon SES) to build a fully-automated multilingual calendar artificial intelligence (AI) assistant. It understands the incoming messages, translates them to the preferred language, and automatically sets up calendar reminders.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-your-multilingual-personal-calendar-assistant-with-amazon-bedrock-and-aws-step-functions/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Medical content creation in the age of generative AI</title>
      <link>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_1/</link>
      <pubDate>Wed, 03 Jul 2024 16:50:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_1/</guid>
      <description>
        
          
            Generative AI and transformer-based large language models (LLMs) have been in the top headlines recently. These models demonstrate impressive performance in question answering, text summarization, code, and text generation. Today, LLMs are being used in real settings by companies, including the heavily-regulated healthcare and life sciences industry (HCLS). The use cases can range from medical […]
Link to article: https://aws.amazon.com/blogs/machine-learning/medical-content-creation-in-the-age-of-generative-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Introducing guardrails in Knowledge Bases for Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_2/</link>
      <pubDate>Wed, 03 Jul 2024 16:46:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_2/</guid>
      <description>
        
          
            Knowledge Bases for Amazon Bedrock is a fully managed capability that helps you securely connect foundation models (FMs) in Amazon Bedrock to your company data using Retrieval Augmented Generation (RAG). This feature streamlines the entire RAG workflow, from ingestion to retrieval and prompt augmentation, eliminating the need for custom data source integrations and data flow […]
Link to article: https://aws.amazon.com/blogs/machine-learning/introducing-guardrails-in-knowledge-bases-for-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prompt engineering techniques and best practices: Learn by doing with Anthropic’s Claude 3 on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_3/</link>
      <pubDate>Wed, 03 Jul 2024 16:42:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_3/</guid>
      <description>
        
          
            You have likely already had the opportunity to interact with generative artificial intelligence (AI) tools (such as virtual assistants and chatbot applications) and noticed that you don’t always get the answer you are looking for, and that achieving it may not be straightforward. Large language models (LLMs), the models behind the generative AI revolution, receive […]
Link to article: https://aws.amazon.com/blogs/machine-learning/prompt-engineering-techniques-and-best-practices-learn-by-doing-with-anthropics-claude-3-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Improve productivity when processing scanned PDFs using Amazon Q Business</title>
      <link>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_12/</link>
      <pubDate>Wed, 03 Jul 2024 00:30:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_07_2024/03_07_2024_12/</guid>
      <description>
        
          
            Amazon Q Business is a generative AI-powered assistant that can answer questions, provide summaries, generate content, and extract insights directly from the content in digital as well as scanned PDF documents in your enterprise data sources without needing to extract the text first. Customers across industries such as finance, insurance, healthcare life sciences, and more need […]
Link to article: https://aws.amazon.com/blogs/machine-learning/improve-productivity-when-processing-scanned-pdfs-using-amazon-q-business/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
