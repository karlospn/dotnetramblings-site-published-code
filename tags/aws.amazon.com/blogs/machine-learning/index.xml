<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 08 Aug 2024 17:07:56 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Discover insights from Box with the Amazon Q Box connector</title>
      <link>https://www.dotnetramblings.com/post/08_08_2024/08_08_2024_1/</link>
      <pubDate>Thu, 08 Aug 2024 17:07:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_08_2024/08_08_2024_1/</guid>
      <description>
        
          
            Seamless access to content and insights is crucial for delivering exceptional customer experiences and driving successful business outcomes. Box, a leading cloud content management platform, serves as a central repository for diverse digital assets and documents in many organizations. An enterprise Box account typically contains a wealth of materials, including documents, presentations, knowledge articles, and […]
Link to article: https://aws.amazon.com/blogs/machine-learning/discover-insights-from-box-with-the-amazon-q-box-connector/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Twilio generated SQL using Looker Modeling Language data with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/08_08_2024/08_08_2024_2/</link>
      <pubDate>Thu, 08 Aug 2024 16:48:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/08_08_2024/08_08_2024_2/</guid>
      <description>
        
          
            As one of the largest AWS customers, Twilio engages with data, artificial intelligence (AI), and machine learning (ML) services to run their daily workloads. This post highlights how Twilio enabled natural language-driven data exploration of business intelligence (BI) data with RAG and Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-twilio-generated-sql-using-looker-modeling-language-data-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Improve AI assistant response accuracy using Knowledge Bases for Amazon Bedrock and a reranking model</title>
      <link>https://www.dotnetramblings.com/post/07_08_2024/07_08_2024_2/</link>
      <pubDate>Wed, 07 Aug 2024 18:47:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_08_2024/07_08_2024_2/</guid>
      <description>
        
          
            AI chatbots and virtual assistants have become increasingly popular in recent years thanks the breakthroughs of large language models (LLMs). Trained on a large volume of datasets, these models incorporate memory components in their architectural design, allowing them to understand and comprehend textual context. Most common use cases for chatbot assistants focus on a few […]
Link to article: https://aws.amazon.com/blogs/machine-learning/improve-ai-assistant-response-accuracy-using-knowledge-bases-for-amazon-bedrock-and-a-reranking-model/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Automate the machine learning model approval process with Amazon SageMaker Model Registry and Amazon SageMaker Pipelines</title>
      <link>https://www.dotnetramblings.com/post/07_08_2024/07_08_2024_3/</link>
      <pubDate>Wed, 07 Aug 2024 18:39:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/07_08_2024/07_08_2024_3/</guid>
      <description>
        
          
            This post illustrates how to use common architecture principles to transition from a manual monitoring process to one that is automated. You can use these principles and existing AWS services such as Amazon SageMaker Model Registry and Amazon SageMaker Pipelines to deliver innovative solutions to your customers while maintaining compliance for your ML workloads.
Link to article: https://aws.amazon.com/blogs/machine-learning/automate-the-machine-learning-model-approval-process-with-amazon-sagemaker-model-registry-and-amazon-sagemaker-pipelines/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build custom generative AI applications powered by Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/06_08_2024/06_08_2024_0/</link>
      <pubDate>Tue, 06 Aug 2024 19:06:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_08_2024/06_08_2024_0/</guid>
      <description>
        
          
            With last month’s blog, I started a series of posts that highlight the key factors that are driving customers to choose Amazon Bedrock. I explored how Bedrock enables customers to build a secure, compliant foundation for generative AI applications. Now I’d like to turn to a slightly more technical, but equally important differentiator for Bedrock—the multiple techniques that you can use to customize models and meet your specific business needs.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use Amazon Bedrock to generate, evaluate, and understand code in your software development pipeline</title>
      <link>https://www.dotnetramblings.com/post/06_08_2024/06_08_2024_6/</link>
      <pubDate>Tue, 06 Aug 2024 15:20:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_08_2024/06_08_2024_6/</guid>
      <description>
        
          
            Generative artificial intelligence (AI) models have opened up new possibilities for automating and enhancing software development workflows. Specifically, the emergent capability for generative models to produce code based on natural language prompts has opened many doors to how developers and DevOps professionals approach their work and improve their efficiency. In this post, we provide an […]
Link to article: https://aws.amazon.com/blogs/machine-learning/use-amazon-bedrock-to-generate-evaluate-and-understand-code-in-your-software-development-pipeline/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Inference AudioCraft MusicGen models using Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/06_08_2024/06_08_2024_9/</link>
      <pubDate>Tue, 06 Aug 2024 14:42:43 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_08_2024/06_08_2024_9/</guid>
      <description>
        
          
            Music generation models have emerged as powerful tools that transform natural language text into musical compositions. Originating from advancements in artificial intelligence (AI) and deep learning, these models are designed to understand and translate descriptive text into coherent, aesthetically pleasing music. Their ability to democratize music production allows individuals without formal training to create high-quality […]
Link to article: https://aws.amazon.com/blogs/machine-learning/inference-audiocraft-musicgen-models-using-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an end-to-end RAG solution using Knowledge Bases for Amazon Bedrock and AWS CloudFormation</title>
      <link>https://www.dotnetramblings.com/post/05_08_2024/05_08_2024_1/</link>
      <pubDate>Mon, 05 Aug 2024 19:53:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_08_2024/05_08_2024_1/</guid>
      <description>
        
          
            Retrieval Augmented Generation (RAG) is a state-of-the-art approach to building question answering systems that combines the strengths of retrieval and foundation models (FMs). RAG models first retrieve relevant information from a large corpus of text and then use a FM to synthesize an answer based on the retrieved information. An end-to-end RAG solution involves several […]
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-end-to-end-rag-solution-using-knowledge-bases-for-amazon-bedrock-and-aws-cloudformation/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Faster LLMs with speculative decoding and AWS Inferentia2</title>
      <link>https://www.dotnetramblings.com/post/05_08_2024/05_08_2024_3/</link>
      <pubDate>Mon, 05 Aug 2024 17:51:05 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_08_2024/05_08_2024_3/</guid>
      <description>
        
          
            In recent years, we have seen a big increase in the size of large language models (LLMs) used to solve natural language processing (NLP) tasks such as question answering and text summarization. Larger models with more parameters, which are in the order of hundreds of billions at the time of writing, tend to produce better […]
Link to article: https://aws.amazon.com/blogs/machine-learning/faster-llms-with-speculative-decoding-and-aws-inferentia2/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Catalog, query, and search audio programs with Amazon Transcribe and Knowledge Bases for Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/05_08_2024/05_08_2024_4/</link>
      <pubDate>Mon, 05 Aug 2024 17:41:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_08_2024/05_08_2024_4/</guid>
      <description>
        
          
            Information retrieval systems have powered the information age through their ability to crawl and sift through massive amounts of data and quickly return accurate and relevant results. These systems, such as search engines and databases, typically work by indexing on keywords and fields contained in data files. However, much of our data in the digital […]
Link to article: https://aws.amazon.com/blogs/machine-learning/catalog-query-and-search-audio-programs-with-amazon-transcribe-and-knowledge-bases-for-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Cepsa Química improves the efficiency and accuracy of product stewardship using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/02_08_2024/02_08_2024_0/</link>
      <pubDate>Fri, 02 Aug 2024 19:11:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_08_2024/02_08_2024_0/</guid>
      <description>
        
          
            In this post, we explain how Cepsa Química and partner Keepler have implemented a generative AI assistant to increase the efficiency of the product stewardship team when answering compliance queries related to the chemical products they market. To accelerate development, they used Amazon Bedrock, a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Stability AI, and Amazon through a single API, along with a broad set of capabilities to build generative AI applications with security, privacy and safety.
          
          
        
      </description>
    </item>
    
    <item>
      <title>GraphStorm 0.3: Scalable, multi-task learning on graphs with user-friendly APIs</title>
      <link>https://www.dotnetramblings.com/post/02_08_2024/02_08_2024_3/</link>
      <pubDate>Fri, 02 Aug 2024 17:56:55 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_08_2024/02_08_2024_3/</guid>
      <description>
        
          
            GraphStorm is a low-code enterprise graph machine learning (GML) framework to build, train, and deploy graph ML solutions on complex enterprise-scale graphs in days instead of months. With GraphStorm, you can build solutions that directly take into account the structure of relationships or interactions between billions of entities, which are inherently embedded in most real-world […]
Link to article: https://aws.amazon.com/blogs/machine-learning/graphstorm-0-3-scalable-multi-task-learning-on-graphs-with-user-friendly-apis/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Few-shot prompt engineering and fine-tuning for LLMs in Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/02_08_2024/02_08_2024_4/</link>
      <pubDate>Fri, 02 Aug 2024 17:46:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/02_08_2024/02_08_2024_4/</guid>
      <description>
        
          
            This blog is part of the series, Generative AI and AI/ML in Capital Markets and Financial Services. Company earnings calls are crucial events that provide transparency into a company’s financial health and prospects. Earnings reports detail a firm’s financials over a specific period, including revenue, net income, earnings per share, balance sheet, and cash flow […]
Link to article: https://aws.amazon.com/blogs/machine-learning/few-shot-prompt-engineering-and-fine-tuning-for-llms-in-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline insurance underwriting with generative AI using Amazon Bedrock – Part 1</title>
      <link>https://www.dotnetramblings.com/post/01_08_2024/01_08_2024_3/</link>
      <pubDate>Thu, 01 Aug 2024 16:26:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_08_2024/01_08_2024_3/</guid>
      <description>
        
          
            Underwriting is a fundamental function within the insurance industry, serving as the foundation for risk assessment and management. Underwriters are responsible for evaluating insurance applications, determining the level of risk associated with each applicant, and making decisions on whether to accept or reject the application based on the insurer’s guidelines and risk appetite. In this […]
Link to article: https://aws.amazon.com/blogs/machine-learning/streamline-insurance-underwriting-with-generative-ai-using-amazon-bedrock-part-1/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Import a fine-tuned Meta Llama 3 model for SQL query generation on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/01_08_2024/01_08_2024_4/</link>
      <pubDate>Thu, 01 Aug 2024 15:47:58 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/01_08_2024/01_08_2024_4/</guid>
      <description>
        
          
            In this post, we demonstrate the process of fine-tuning Meta Llama 3 8B on SageMaker to specialize it in the generation of SQL queries (text-to-SQL). Meta Llama 3 8B is a relatively small model that offers a balance between performance and resource efficiency. AWS customers have explored fine-tuning Meta Llama 3 8B for the generation of SQL queries—especially when using non-standard SQL dialects—and have requested methods to import their customized models into Amazon Bedrock to benefit from the managed infrastructure and security that Amazon Bedrock provides when serving those models.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
