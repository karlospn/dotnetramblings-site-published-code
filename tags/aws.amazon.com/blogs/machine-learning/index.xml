<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Fri, 28 Feb 2025 18:31:11 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Streamline work insights with the Amazon Q Business connector for Smartsheet</title>
      <link>https://www.dotnetramblings.com/post/28_02_2025/28_02_2025_3/</link>
      <pubDate>Fri, 28 Feb 2025 18:31:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_02_2025/28_02_2025_3/</guid>
      <description>
        
          
            This post explains how to integrate Smartsheet with Amazon Q Business to use natural language and generative AI capabilities for enhanced insights. Smartsheet, the AI-enhanced enterprise-grade work management platform, helps users manage projects, programs, and processes at scale.
Link to article: https://aws.amazon.com/blogs/machine-learning/streamline-work-insights-with-the-amazon-q-business-connector-for-smartsheet/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Level up your problem-solving and strategic thinking skills with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/28_02_2025/28_02_2025_5/</link>
      <pubDate>Fri, 28 Feb 2025 18:17:07 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_02_2025/28_02_2025_5/</guid>
      <description>
        
          
            In this post, we show how Anthropic’s Claude 3.5 Sonnet in Amazon Bedrock can be used for a variety of business-related cognitive tasks, such as problem-solving, critical thinking and ideation—to help augment human thinking and improve decision-making among knowledge workers to accelerate innovation.
Link to article: https://aws.amazon.com/blogs/machine-learning/level-up-your-problem-solving-and-strategic-thinking-skills-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Optimizing AI implementation costs with Automat-it</title>
      <link>https://www.dotnetramblings.com/post/28_02_2025/28_02_2025_6/</link>
      <pubDate>Fri, 28 Feb 2025 18:11:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_02_2025/28_02_2025_6/</guid>
      <description>
        
          
            In this guest post, we explain how AWS Partner Automat-it helped their customer achieve a more than twelvefold cost savings while keeping AI model performance within the required performance thresholds. This was accomplished through careful tuning of architecture, algorithm selection, and infrastructure management.
Link to article: https://aws.amazon.com/blogs/machine-learning/optimizing-ai-implementation-costs-with-automat-it/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>The end of an era: the final AWS DeepRacer League Championship at re:Invent 2024</title>
      <link>https://www.dotnetramblings.com/post/28_02_2025/28_02_2025_7/</link>
      <pubDate>Fri, 28 Feb 2025 18:03:46 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_02_2025/28_02_2025_7/</guid>
      <description>
        
          
            The AWS DeepRacer League is the world&#39;s first global autonomous racing league powered by machine learning (ML). Over the past 6 years, a diverse community of over 560,000 builders from more than 150 countries worldwide have participated in the League to learn ML fundamentals hands-on through the fun of friendly autonomous racing. After an 8-month season of nail-biting virtual qualifiers, finalists convened in person at re:Invent in Las Vegas for one final showdown to compete for prizes and glory in the high-stakes, winner-take-all AWS DeepRacer League Championship.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluate healthcare generative AI applications using LLM-as-a-judge on AWS</title>
      <link>https://www.dotnetramblings.com/post/27_02_2025/27_02_2025_4/</link>
      <pubDate>Thu, 27 Feb 2025 17:40:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/27_02_2025/27_02_2025_4/</guid>
      <description>
        
          
            In this post, we demonstrate how to implement this evaluation framework using Amazon Bedrock, compare the performance of different generator models, including Anthropic’s Claude and Amazon Nova on Amazon Bedrock, and showcase how to use the new RAG evaluation feature to optimize knowledge base parameters and assess retrieval quality.
Link to article: https://aws.amazon.com/blogs/machine-learning/evaluate-healthcare-generative-ai-applications-using-llm-as-a-judge-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS DeepRacer: Closing time at AWS re:Invent 2024 –How did that physical racing go?</title>
      <link>https://www.dotnetramblings.com/post/27_02_2025/27_02_2025_5/</link>
      <pubDate>Thu, 27 Feb 2025 17:33:24 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/27_02_2025/27_02_2025_5/</guid>
      <description>
        
          
            In AWS DeepRacer: How to master physical racing?, I wrote in detail about some aspects relevant to racing AWS DeepRacer in the physical world. The previous post was left open-ended—with one last Championship Final left, it was too early to share all my secrets. Now that AWS re:Invent is over, it’s time to share my strategy, how I prepared, and how it went in the end.
Link to article: https://aws.amazon.com/blogs/machine-learning/aws-deepracer-closing-time-at-aws-reinvent-2024-how-did-that-physical-racing-go/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Pattern PXM’s Content Brief is driving conversion on ecommerce marketplaces using AI</title>
      <link>https://www.dotnetramblings.com/post/26_02_2025/26_02_2025_3/</link>
      <pubDate>Wed, 26 Feb 2025 17:27:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_02_2025/26_02_2025_3/</guid>
      <description>
        
          
            Pattern is a leader in ecommerce acceleration, helping brands navigate the complexities of selling on marketplaces and achieve profitable growth through a combination of proprietary technology and on-demand expertise. In this post, we share how Pattern uses AWS services to process trillions of data points to deliver actionable insights, optimizing product listings across multiple services.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-pattern-pxms-content-brief-is-driving-conversion-on-ecommerce-marketplaces-using-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How to configure cross-account model deployment using Amazon Bedrock Custom Model Import</title>
      <link>https://www.dotnetramblings.com/post/26_02_2025/26_02_2025_4/</link>
      <pubDate>Wed, 26 Feb 2025 17:23:28 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_02_2025/26_02_2025_4/</guid>
      <description>
        
          
            In this guide, we walk you through step-by-step instructions for configuring cross-account access for Amazon Bedrock Custom Model Import, covering both non-encrypted and AWS Key Management Service (AWS KMS) based encrypted scenarios.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-to-configure-cross-account-model-deployment-using-amazon-bedrock-custom-model-import/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>ByteDance processes billions of daily videos using their multimodal video understanding models on AWS Inferentia2</title>
      <link>https://www.dotnetramblings.com/post/26_02_2025/26_02_2025_5/</link>
      <pubDate>Wed, 26 Feb 2025 17:18:43 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/26_02_2025/26_02_2025_5/</guid>
      <description>
        
          
            At ByteDance, we collaborated with Amazon Web Services (AWS) to deploy multimodal large language models (LLMs) for video understanding using AWS Inferentia2 across multiple AWS Regions around the world. By using sophisticated ML algorithms, the platform efficiently scans billions of videos each day. In this post, we discuss the use of multimodal LLMs for video understanding, the solution architecture, and techniques for performance optimization.
Link to article: https://aws.amazon.com/blogs/machine-learning/bytedance-processes-billions-of-daily-videos-using-their-multimodal-video-understanding-models-on-aws-inferentia2/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How IDIADA optimized its intelligent chatbot with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/25_02_2025/25_02_2025_3/</link>
      <pubDate>Tue, 25 Feb 2025 16:53:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_02_2025/25_02_2025_3/</guid>
      <description>
        
          
            In 2021, Applus+ IDIADA, a global partner to the automotive industry with over 30 years of experience supporting customers in product development activities through design, engineering, testing, and homologation services, established the Digital Solutions department. In this post, we showcase the research process undertaken to develop a classifier for human interactions in this AI-based environment using Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-idiada-optimized-its-intelligent-chatbot-with-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate IaC troubleshooting with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/25_02_2025/25_02_2025_4/</link>
      <pubDate>Tue, 25 Feb 2025 16:19:03 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_02_2025/25_02_2025_4/</guid>
      <description>
        
          
            This post demonstrates how Amazon Bedrock Agents, combined with action groups and generative AI models, streamlines and accelerates the resolution of Terraform errors while maintaining compliance with environment security and operational guidelines.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-iac-troubleshooting-with-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Derive generative AI powered insights from Alation Cloud Services using Amazon Q Business Custom Connector</title>
      <link>https://www.dotnetramblings.com/post/25_02_2025/25_02_2025_5/</link>
      <pubDate>Tue, 25 Feb 2025 16:16:25 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/25_02_2025/25_02_2025_5/</guid>
      <description>
        
          
            In this post, we showcase a sample of how Alation’s business policies can be integrated with an Amazon Q Business application using a custom data source connector.
Link to article: https://aws.amazon.com/blogs/machine-learning/derive-generative-ai-powered-insights-from-alation-cloud-services-using-amazon-q-business-custom-connector/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Mistral-Small-24B-Instruct-2501 is now available on SageMaker Jumpstart and Amazon Bedrock Marketplace</title>
      <link>https://www.dotnetramblings.com/post/24_02_2025/24_02_2025_1/</link>
      <pubDate>Mon, 24 Feb 2025 21:02:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_02_2025/24_02_2025_1/</guid>
      <description>
        
          
            We’re excited to announce that Mistral-Small-24B-Instruct-2501—a twenty-four billion parameter large language model (LLM) from Mistral AI that’s optimized for low latency text generation tasks—is available for customers through Amazon SageMaker JumpStart and Amazon Bedrock Marketplace. In this post, we walk through how to discover, deploy, and use Mistral-Small-24B-Instruct-2501.
Link to article: https://aws.amazon.com/blogs/machine-learning/mistral-small-24b-instruct-2501-is-now-available-on-sagemaker-jumpstart-and-amazon-bedrock-marketplace/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Rocket Companies modernized their data science solution on AWS</title>
      <link>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_0/</link>
      <pubDate>Fri, 21 Feb 2025 18:45:46 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_0/</guid>
      <description>
        
          
            In this post, we share how we modernized Rocket Companies’ data science solution on AWS to increase the speed to delivery from eight weeks to under one hour, improve operational stability and support by reducing incident tickets by over 99% in 18 months, power 10 million automated data science and AI decisions made daily, and provide a seamless data science development experience.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-rocket-companies-modernized-their-data-science-solution-on-aws/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS and DXC collaborate to deliver customizable, near real-time voice-to-voice translation capabilities for Amazon Connect</title>
      <link>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_1/</link>
      <pubDate>Fri, 21 Feb 2025 17:08:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_1/</guid>
      <description>
        
          
            In this post, we discuss how AWS and DXC used Amazon Connect and other AWS AI services to deliver near real-time V2V translation capabilities.
Link to article: https://aws.amazon.com/blogs/machine-learning/aws-and-dxc-collaborate-to-deliver-customizable-near-real-time-voice-to-voice-translation-capabilities-for-amazon-connect/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Orchestrate an intelligent document processing workflow using tools in Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_2/</link>
      <pubDate>Fri, 21 Feb 2025 16:44:25 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_2/</guid>
      <description>
        
          
            This intelligent document processing solution uses Amazon Bedrock FMs to orchestrate a sophisticated workflow for handling multi-page healthcare documents with mixed content types. The solution uses the FM’s tool use capabilities, accessed through the Amazon Bedrock Converse API. This enables the FMs to not just process text, but to actively engage with various external tools and APIs to perform complex document analysis tasks.
Link to article: https://aws.amazon.com/blogs/machine-learning/orchestrate-an-intelligent-document-processing-workflow-using-tools-in-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Reducing hallucinations in LLM agents with a verified semantic cache using Amazon Bedrock Knowledge Bases</title>
      <link>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_3/</link>
      <pubDate>Fri, 21 Feb 2025 16:36:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_3/</guid>
      <description>
        
          
            This post introduces a solution to reduce hallucinations in Large Language Models (LLMs) by implementing a verified semantic cache using Amazon Bedrock Knowledge Bases, which checks if user questions match curated and verified responses before generating new answers. The solution combines the flexibility of LLMs with reliable, verified answers to improve response accuracy, reduce latency, and lower costs while preventing potential misinformation in critical domains such as healthcare, finance, and legal services.
          
          
        
      </description>
    </item>
    
    <item>
      <title>LLM continuous self-instruct fine-tuning framework powered by a compound AI system on Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_4/</link>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_4/</guid>
      <description>
        
          
            In this post, we present the continuous self-instruct fine-tuning framework as a compound AI system implemented by the DSPy framework. The framework first generates a synthetic dataset from the domain knowledge base and documents for self-instruction, then drives model fine-tuning through SFT, and introduces the human-in-the-loop workflow to collect human and AI feedback to the model response, which is used to further improve the model performance by aligning human preference through reinforcement learning (RLHF/RLAIF).
          
          
        
      </description>
    </item>
    
    <item>
      <title>Maximize your file server data’s potential by using Amazon Q Business on Amazon FSx for Windows</title>
      <link>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_6/</link>
      <pubDate>Fri, 21 Feb 2025 16:17:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_02_2025/21_02_2025_6/</guid>
      <description>
        
          
            In this post, we show you how to connect Amazon Q, a generative AI-powered assistant, to Amazon FSx for Windows File Server to securely analyze, query, and extract insights from your file system data.
Link to article: https://aws.amazon.com/blogs/machine-learning/maximize-your-file-server-datas-potential-by-using-amazon-q-business-on-amazon-fsx-for-windows/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
