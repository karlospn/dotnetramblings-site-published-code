<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 17 Jul 2025 22:12:26 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Evaluating generative AI models with Amazon Nova LLM-as-a-Judge on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/17_07_2025/17_07_2025_0/</link>
      <pubDate>Thu, 17 Jul 2025 22:12:26 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_07_2025/17_07_2025_0/</guid>
      <description>
        
          
            Evaluating the performance of large language models (LLMs) goes beyond statistical metrics like perplexity or bilingual evaluation understudy (BLEU) scores. For most real-world generative AI scenarios, it’s crucial to understand whether a model is producing better outputs than a baseline or an earlier iteration. This is especially important for applications such as summarization, content generation, […]
Link to article: https://aws.amazon.com/blogs/machine-learning/evaluating-generative-ai-models-with-amazon-nova-llm-as-a-judge-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building cost-effective RAG applications with Amazon Bedrock Knowledge Bases and Amazon S3 Vectors</title>
      <link>https://www.dotnetramblings.com/post/17_07_2025/17_07_2025_1/</link>
      <pubDate>Thu, 17 Jul 2025 22:09:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_07_2025/17_07_2025_1/</guid>
      <description>
        
          
            In this post, we demonstrate how to integrate Amazon S3 Vectors with Amazon Bedrock Knowledge Bases for RAG applications. You&#39;ll learn a practical approach to scale your knowledge bases to handle millions of documents while maintaining retrieval quality and using S3 Vectors cost-effective storage.
Link to article: https://aws.amazon.com/blogs/machine-learning/building-cost-effective-rag-applications-with-amazon-bedrock-knowledge-bases-and-amazon-s3-vectors/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implementing on-demand deployment with customized Amazon Nova models on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/17_07_2025/17_07_2025_2/</link>
      <pubDate>Thu, 17 Jul 2025 19:36:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_07_2025/17_07_2025_2/</guid>
      <description>
        
          
            In this post, we walk through the custom model on-demand deployment workflow for Amazon Bedrock and provide step-by-step implementation guides using both the AWS Management Console and APIs or AWS SDKs. We also discuss best practices and considerations for deploying customized Amazon Nova models on Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/implementing-on-demand-deployment-with-customized-amazon-nova-models-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building enterprise-scale RAG applications with Amazon S3 Vectors and DeepSeek R1 on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/17_07_2025/17_07_2025_9/</link>
      <pubDate>Thu, 17 Jul 2025 12:30:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_07_2025/17_07_2025_9/</guid>
      <description>
        
          
            Organizations are adopting large language models (LLMs), such as DeepSeek R1, to transform business processes, enhance customer experiences, and drive innovation at unprecedented speed. However, standalone LLMs have key limitations such as hallucinations, outdated knowledge, and no access to proprietary data. Retrieval Augmented Generation (RAG) addresses these gaps by combining semantic search with generative AI, […]
Link to article: https://aws.amazon.com/blogs/machine-learning/building-enterprise-scale-rag-applications-with-amazon-s3-vectors-and-deepseek-r1-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accenture scales video analysis with Amazon Nova and Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/16_07_2025/16_07_2025_0/</link>
      <pubDate>Wed, 16 Jul 2025 22:32:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_07_2025/16_07_2025_0/</guid>
      <description>
        
          
            This post was written with Ilan Geller, Kamal Mannar, Debasmita Ghosh, and Nakul Aggarwal of Accenture. Video highlights offer a powerful way to boost audience engagement and extend content value for content publishers. These short, high-impact clips capture key moments that drive viewer retention, amplify reach across social media, reinforce brand identity, and open new […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accenture-scales-video-analysis-with-amazon-nova-and-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deploy conversational agents with Vonage and Amazon Nova Sonic</title>
      <link>https://www.dotnetramblings.com/post/16_07_2025/16_07_2025_2/</link>
      <pubDate>Wed, 16 Jul 2025 18:29:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_07_2025/16_07_2025_2/</guid>
      <description>
        
          
            In this post, we explore how developers can integrate Amazon Nova Sonic with the Vonage communications service to build responsive, natural-sounding voice experiences in real time. By combining the Vonage Voice API with the low-latency and expressive speech capabilities of Amazon Nova Sonic, businesses can deploy AI voice agents that deliver more human-like interactions than traditional voice interfaces. These agents can be used as customer support, virtual assistants, and more.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enabling customers to deliver production-ready AI agents at scale</title>
      <link>https://www.dotnetramblings.com/post/16_07_2025/16_07_2025_5/</link>
      <pubDate>Wed, 16 Jul 2025 15:04:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_07_2025/16_07_2025_5/</guid>
      <description>
        
          
            Today, I’m excited to share how we’re bringing this vision to life with new capabilities that address the fundamental aspects of building and deploying agents at scale. These innovations will help you move beyond experiments to production-ready agent systems that can be trusted with your most critical business processes.
Link to article: https://aws.amazon.com/blogs/machine-learning/enabling-customers-to-deliver-production-ready-ai-agents-at-scale/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock Knowledge Bases now supports Amazon OpenSearch Service Managed Cluster as vector store</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_0/</link>
      <pubDate>Tue, 15 Jul 2025 22:05:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_0/</guid>
      <description>
        
          
            Amazon Bedrock Knowledge Bases has extended its vector store options by enabling support for Amazon OpenSearch Service managed clusters, further strengthening its capabilities as a fully managed Retrieval Augmented Generation (RAG) solution. This enhancement builds on the core functionality of Amazon Bedrock Knowledge Bases , which is designed to seamlessly connect foundation models (FMs) with internal data sources. This post provides a comprehensive, step-by-step guide on integrating an Amazon Bedrock knowledge base with an OpenSearch Service managed cluster as its vector store.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Monitor agents built on Amazon Bedrock with Datadog LLM Observability</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_1/</link>
      <pubDate>Tue, 15 Jul 2025 22:02:38 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_1/</guid>
      <description>
        
          
            We’re excited to announce a new integration between Datadog LLM Observability and Amazon Bedrock Agents that helps monitor agentic applications built on Amazon Bedrock. In this post, we&#39;ll explore how Datadog&#39;s LLM Observability provides the visibility and control needed to successfully monitor, operate, and debug production-grade agentic applications built on Amazon Bedrock Agents.
Link to article: https://aws.amazon.com/blogs/machine-learning/monitor-agents-built-on-amazon-bedrock-with-datadog-llm-observability/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How PayU built a secure enterprise AI assistant using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_2/</link>
      <pubDate>Tue, 15 Jul 2025 21:54:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_2/</guid>
      <description>
        
          
            PayU offers a full-stack digital financial services system that serves the financial needs of merchants, banks, and consumers through technology. In this post, we explain how we equipped the PayU team with an enterprise AI solution and democratized AI access using Amazon Bedrock, without compromising on data residency requirements.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-payu-built-a-secure-enterprise-ai-assistant-using-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Supercharge generative AI workflows with NVIDIA DGX Cloud on AWS and Amazon Bedrock Custom Model Import</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_9/</link>
      <pubDate>Tue, 15 Jul 2025 13:32:12 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_9/</guid>
      <description>
        
          
            This post is co-written with Andrew Liu, Chelsea Isaac, Zoey Zhang, and Charlie Huang from NVIDIA. DGX Cloud on Amazon Web Services (AWS) represents a significant leap forward in democratizing access to high-performance AI infrastructure. By combining NVIDIA GPU expertise with AWS scalable cloud services, organizations can accelerate their time-to-train, reduce operational complexity, and unlock […]
Link to article: https://aws.amazon.com/blogs/machine-learning/supercharge-generative-ai-workflows-with-nvidia-dgx-cloud-on-aws-and-amazon-bedrock-custom-model-import/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate generative AI inference with NVIDIA Dynamo and Amazon EKS</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_10/</link>
      <pubDate>Tue, 15 Jul 2025 13:03:32 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_10/</guid>
      <description>
        
          
            This post introduces NVIDIA Dynamo and explains how to set it up on Amazon EKS for automated scaling and streamlined Kubernetes operations. We provide a hands-on walkthrough, which uses the NVIDIA Dynamo blueprint on the AI on EKS GitHub repo by AWS Labs to provision the infrastructure, configure monitoring, and install the NVIDIA Dynamo operator.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-generative-ai-inference-with-nvidia-dynamo-and-amazon-eks/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS doubles investment in AWS Generative AI Innovation Center, marking two years of customer success</title>
      <link>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_11/</link>
      <pubDate>Tue, 15 Jul 2025 12:40:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_07_2025/15_07_2025_11/</guid>
      <description>
        
          
            In this post, AWS announces a $100 million additional investment in its AWS Generative AI Innovation Center, marking two years of successful customer collaborations across industries from financial services to healthcare. The investment comes as AI evolves toward more autonomous, agentic systems, with the center already helping thousands of customers drive millions in productivity gains and transform customer experiences.
Link to article: https://aws.amazon.com/blogs/machine-learning/aws-doubles-investment-in-aws-generative-ai-innovation-center-marking-two-years-of-customer-success/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build AI-driven policy creation for vehicle data collection and automation using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_1/</link>
      <pubDate>Mon, 14 Jul 2025 16:58:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_1/</guid>
      <description>
        
          
            Sonatus partnered with the AWS Generative AI Innovation Center to develop a natural language interface to generate data collection and automation policies using generative AI. This innovation aims to reduce the policy generation process from days to minutes while making it accessible to both engineers and non-experts alike. In this post, we explore how we built this system using Sonatus’s Collector AI and Amazon Bedrock. We discuss the background, challenges, and high-level solution architecture.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Rapid7 automates vulnerability risk scores with ML pipelines using Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_2/</link>
      <pubDate>Mon, 14 Jul 2025 16:55:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_2/</guid>
      <description>
        
          
            In this post, we share how Rapid7 implemented end-to-end automation for the training, validation, and deployment of ML models that predict CVSS vectors. Rapid7 customers have the information they need to accurately understand their risk and prioritize remediation measures.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-rapid7-automates-vulnerability-risk-scores-with-ml-pipelines-using-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build secure RAG applications with AWS serverless data lakes</title>
      <link>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_3/</link>
      <pubDate>Mon, 14 Jul 2025 16:51:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/14_07_2025/14_07_2025_3/</guid>
      <description>
        
          
            In this post, we explore how to build a secure RAG application using serverless data lake architecture, an important data strategy to support generative AI development. We use Amazon Web Services (AWS) services including Amazon S3, Amazon DynamoDB, AWS Lambda, and Amazon Bedrock Knowledge Bases to create a comprehensive solution supporting unstructured data assets which can be extended to structured data. The post covers how to implement fine-grained access controls for your enterprise data and design metadata-driven retrieval systems that respect security boundaries.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Advanced fine-tuning methods on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_3/</link>
      <pubDate>Fri, 11 Jul 2025 17:26:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_3/</guid>
      <description>
        
          
            When fine-tuning ML models on AWS, you can choose the right tool for your specific needs. AWS provides a comprehensive suite of tools for data scientists, ML engineers, and business users to achieve their ML goals. AWS has built solutions to support various levels of ML sophistication, from simple SageMaker training jobs for FM fine-tuning to the power of SageMaker HyperPod for cutting-edge research. We invite you to explore these options, starting with what suits your current needs, and evolve your approach as those needs change.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline machine learning workflows with SkyPilot on Amazon SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_4/</link>
      <pubDate>Fri, 11 Jul 2025 17:22:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_4/</guid>
      <description>
        
          
            This post is co-written with Zhanghao Wu, co-creator of SkyPilot. The rapid advancement of generative AI and foundation models (FMs) has significantly increased computational resource requirements for machine learning (ML) workloads. Modern ML pipelines require efficient systems for distributing workloads across accelerated compute resources, while making sure developer productivity remains high. Organizations need infrastructure solutions […]
Link to article: https://aws.amazon.com/blogs/machine-learning/streamline-machine-learning-workflows-with-skypilot-on-amazon-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Intelligent document processing at scale with generative AI and Amazon Bedrock Data Automation</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_5/</link>
      <pubDate>Fri, 11 Jul 2025 16:49:04 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_5/</guid>
      <description>
        
          
            This post presents an end-to-end IDP application powered by Amazon Bedrock Data Automation and other AWS services. It provides a reusable AWS infrastructure as code (IaC) that deploys an IDP pipeline and provides an intuitive UI for transforming documents into structured tables at scale. The application only requires the user to provide the input documents (such as contracts or emails) and a list of attributes to be extracted. It then performs IDP with generative AI.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a conversational data assistant, Part 2 – Embedding generative business intelligence with Amazon Q in QuickSight</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_6/</link>
      <pubDate>Fri, 11 Jul 2025 16:33:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_6/</guid>
      <description>
        
          
            In this post, we dive into how we integrated Amazon Q in QuickSight to transform natural language requests like “Show me how many items were returned in the US over the past 6 months” into meaningful data visualizations. We demonstrate how combining Amazon Bedrock Agents with Amazon Q in QuickSight creates a comprehensive data assistant that delivers both SQL code and visual insights through a single, intuitive conversational interface—democratizing data access across the enterprise.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a conversational data assistant, Part 1: Text-to-SQL with Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_7/</link>
      <pubDate>Fri, 11 Jul 2025 16:32:44 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_7/</guid>
      <description>
        
          
            In this post, we focus on building a Text-to-SQL solution with Amazon Bedrock, a managed service for building generative AI applications. Specifically, we demonstrate the capabilities of Amazon Bedrock Agents. Part 2 explains how we extended the solution to provide business insights using Amazon Q in QuickSight, a business intelligence assistant that answers questions with auto-generated visualizations.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-conversational-data-assistant-part-1-text-to-sql-with-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Implement user-level access control for multi-tenant ML platforms on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_8/</link>
      <pubDate>Fri, 11 Jul 2025 16:17:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_8/</guid>
      <description>
        
          
            In this post, we discuss permission management strategies, focusing on attribute-based access control (ABAC) patterns that enable granular user access control while minimizing the proliferation of AWS Identity and Access Management (IAM) roles. We also share proven best practices that help organizations maintain security and compliance without sacrificing operational efficiency in their ML workflows.
Link to article: https://aws.amazon.com/blogs/machine-learning/implement-user-level-access-control-for-multi-tenant-ml-platforms-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Long-running execution flows now supported in Amazon Bedrock Flows in public preview</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_9/</link>
      <pubDate>Fri, 11 Jul 2025 16:13:11 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_9/</guid>
      <description>
        
          
            We announce the public preview of long-running execution (asynchronous) flow support within Amazon Bedrock Flows. With Amazon Bedrock Flows, you can link foundation models (FMs), Amazon Bedrock Prompt Management, Amazon Bedrock Agents, Amazon Bedrock Knowledge Bases, Amazon Bedrock Guardrails, and other AWS services together to build and scale predefined generative AI workflows.
Link to article: https://aws.amazon.com/blogs/machine-learning/long-running-execution-flows-now-supported-in-amazon-bedrock-flows-in-public-preview/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Fraud detection empowered by federated learning with the Flower framework on Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_10/</link>
      <pubDate>Fri, 11 Jul 2025 16:03:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_10/</guid>
      <description>
        
          
            In this post, we explore how SageMaker and federated learning help financial institutions build scalable, privacy-first fraud detection systems.
Link to article: https://aws.amazon.com/blogs/machine-learning/fraud-detection-empowered-by-federated-learning-with-the-flower-framework-on-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building intelligent AI voice agents with Pipecat and Amazon Bedrock – Part 2</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_11/</link>
      <pubDate>Fri, 11 Jul 2025 15:56:09 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_11/</guid>
      <description>
        
          
            In Part 1 of this series, you learned how you can use the combination of Amazon Bedrock and Pipecat, an open source framework for voice and multimodal conversational AI agents to build applications with human-like conversational AI. You learned about common use cases of voice agents and the cascaded models approach, where you orchestrate several components to build your voice AI agent. In this post (Part 2), you explore how to use speech-to-speech foundation model, Amazon Nova Sonic, and the benefits of using a unified model.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Uphold ethical standards in fashion using multimodal toxicity detection with Amazon Bedrock Guardrails</title>
      <link>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_12/</link>
      <pubDate>Fri, 11 Jul 2025 15:49:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_07_2025/11_07_2025_12/</guid>
      <description>
        
          
            In the fashion industry, teams are frequently innovating quickly, often utilizing AI. Sharing content, whether it be through videos, designs, or otherwise, can lead to content moderation challenges. There remains a risk (through intentional or unintentional actions) of inappropriate, offensive, or toxic content being produced and shared. In this post, we cover the use of the multimodal toxicity detection feature of Amazon Bedrock Guardrails to guard against toxic content. Whether you’re an enterprise giant in the fashion industry or an up-and-coming brand, you can use this solution to screen potentially harmful content before it impacts your brand’s reputation and ethical standards.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
