<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Mon, 28 Apr 2025 17:47:59 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Customize Amazon Nova models to improve tool usage</title>
      <link>https://www.dotnetramblings.com/post/28_04_2025/28_04_2025_2/</link>
      <pubDate>Mon, 28 Apr 2025 17:47:59 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_04_2025/28_04_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate model customization (fine-tuning) for tool use with Amazon Nova. We first introduce a tool usage use case, and gave details about the dataset. We walk through the details of Amazon Nova specific data formatting and showed how to do tool calling through the Converse and Invoke APIs in Amazon Bedrock. After getting the baseline results from Amazon Nova models, we explain in detail the fine-tuning process, hosting fine-tuned models with provisioned throughput, and using the fine-tuned Amazon Nova models for inference.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Evaluate Amazon Bedrock Agents with Ragas and LLM-as-a-judge</title>
      <link>https://www.dotnetramblings.com/post/28_04_2025/28_04_2025_4/</link>
      <pubDate>Mon, 28 Apr 2025 15:31:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/28_04_2025/28_04_2025_4/</guid>
      <description>
        
          
            In this post, we introduced the Open Source Bedrock Agent Evaluation framework, a Langfuse-integrated solution that streamlines the agent development process. We demonstrated how this evaluation framework can be integrated with pharmaceutical research agents. We used it to evaluate agent performance against biomarker questions and sent traces to Langfuse to view evaluation metrics across question types.
Link to article: https://aws.amazon.com/blogs/machine-learning/evaluate-amazon-bedrock-agents-with-ragas-and-llm-as-a-judge/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enterprise-grade natural language to SQL generation using LLMs: Balancing accuracy, latency, and scale</title>
      <link>https://www.dotnetramblings.com/post/24_04_2025/24_04_2025_1/</link>
      <pubDate>Thu, 24 Apr 2025 16:23:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_04_2025/24_04_2025_1/</guid>
      <description>
        
          
            In this post, the AWS and Cisco teams unveil a new methodical approach that addresses the challenges of enterprise-grade SQL generation. The teams were able to reduce the complexity of the NL2SQL process while delivering higher accuracy and better overall performance.
Link to article: https://aws.amazon.com/blogs/machine-learning/enterprise-grade-natural-language-to-sql-generation-using-llms-balancing-accuracy-latency-and-scale/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>AWS Field Experience reduced cost and delivered low latency and high performance with Amazon Nova Lite foundation model</title>
      <link>https://www.dotnetramblings.com/post/24_04_2025/24_04_2025_2/</link>
      <pubDate>Thu, 24 Apr 2025 16:17:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_04_2025/24_04_2025_2/</guid>
      <description>
        
          
            The AFX team’s product migration to the Nova Lite model has delivered tangible enterprise value by enhancing sales workflows. By migrating to the Amazon Nova Lite model, the team has not only achieved significant cost savings and reduced latency, but has also empowered sellers with a leading intelligent and reliable solution.
Link to article: https://aws.amazon.com/blogs/machine-learning/aws-field-experience-reduced-cost-and-delivered-low-latency-and-high-performance-with-amazon-nova-lite-foundation-model/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Combine keyword and semantic search for text and images using Amazon Bedrock and Amazon OpenSearch Service</title>
      <link>https://www.dotnetramblings.com/post/24_04_2025/24_04_2025_3/</link>
      <pubDate>Thu, 24 Apr 2025 16:13:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/24_04_2025/24_04_2025_3/</guid>
      <description>
        
          
            In this post, we walk you through how to build a hybrid search solution using OpenSearch Service powered by multimodal embeddings from the Amazon Titan Multimodal Embeddings G1 model through Amazon Bedrock. This solution demonstrates how you can enable users to submit both text and images as queries to retrieve relevant results from a sample retail image dataset.
Link to article: https://aws.amazon.com/blogs/machine-learning/combine-keyword-and-semantic-search-for-text-and-images-using-amazon-bedrock-and-amazon-opensearch-service/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an AI-powered document processing platform with open source NER model and LLM on Amazon SageMaker</title>
      <link>https://www.dotnetramblings.com/post/23_04_2025/23_04_2025_5/</link>
      <pubDate>Wed, 23 Apr 2025 16:06:35 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_04_2025/23_04_2025_5/</guid>
      <description>
        
          
            In this post, we discuss how you can build an AI-powered document processing platform with open source NER and LLMs on SageMaker.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-an-ai-powered-document-processing-platform-with-open-source-ner-model-and-llm-on-amazon-sagemaker/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Protect sensitive data in RAG applications with Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/23_04_2025/23_04_2025_6/</link>
      <pubDate>Wed, 23 Apr 2025 16:00:18 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_04_2025/23_04_2025_6/</guid>
      <description>
        
          
            In this post, we explore two approaches for securing sensitive data in RAG applications using Amazon Bedrock. The first approach focused on identifying and redacting sensitive data before ingestion into an Amazon Bedrock knowledge base, and the second demonstrated a fine-grained RBAC pattern for managing access to sensitive information during retrieval. These solutions represent just two possible approaches among many for securing sensitive data in generative AI applications.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Supercharge your LLM performance with Amazon SageMaker Large Model Inference container v15</title>
      <link>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_0/</link>
      <pubDate>Tue, 22 Apr 2025 17:28:40 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_0/</guid>
      <description>
        
          
            Today, we’re excited to announce the launch of Amazon SageMaker Large Model Inference (LMI) container v15, powered by vLLM 0.8.4 with support for the vLLM V1 engine. This release introduces significant performance improvements, expanded model compatibility with multimodality (that is, the ability to understand and analyze text-to-text, images-to-text, and text-to-images data), and provides built-in integration with vLLM to help you seamlessly deploy and serve large language models (LLMs) with the highest performance at scale.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accuracy evaluation framework for Amazon Q Business – Part 2</title>
      <link>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_1/</link>
      <pubDate>Tue, 22 Apr 2025 17:18:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_1/</guid>
      <description>
        
          
            In the first post of this series, we introduced a comprehensive evaluation framework for Amazon Q Business, a fully managed Retrieval Augmented Generation (RAG) solution that uses your company’s proprietary data without the complexity of managing large language models (LLMs). The first post focused on selecting appropriate use cases, preparing data, and implementing metrics to […]
Link to article: https://aws.amazon.com/blogs/machine-learning/accuracy-evaluation-framework-for-amazon-q-business-part-2/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Use Amazon Bedrock Intelligent Prompt Routing for cost and latency benefits</title>
      <link>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_2/</link>
      <pubDate>Tue, 22 Apr 2025 17:15:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_2/</guid>
      <description>
        
          
            Today, we’re happy to announce the general availability of Amazon Bedrock Intelligent Prompt Routing. In this blog post, we detail various highlights from our internal testing, how you can get started, and point out some caveats and best practices. We encourage you to incorporate Amazon Bedrock Intelligent Prompt Routing into your new and existing generative AI applications.
Link to article: https://aws.amazon.com/blogs/machine-learning/use-amazon-bedrock-intelligent-prompt-routing-for-cost-and-latency-benefits/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Infosys improved accessibility for Event Knowledge using Amazon Nova Pro, Amazon Bedrock and Amazon Elemental Media Services</title>
      <link>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_3/</link>
      <pubDate>Tue, 22 Apr 2025 17:12:46 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/22_04_2025/22_04_2025_3/</guid>
      <description>
        
          
            In this post, we explore how Infosys developed Infosys Event AI to unlock the insights generated from events and conferences. Through its suite of features—including real-time transcription, intelligent summaries, and an interactive chat assistant—Infosys Event AI makes event knowledge accessible and provides an immersive engagement solution for the attendees, during and after the event.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-infosys-improved-accessibility-for-event-knowledge-using-amazon-nova-pro-amazon-bedrock-and-amazon-elemental-media-services/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Amazon Bedrock Prompt Optimization Drives LLM Applications Innovation for Yuewen Group</title>
      <link>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_0/</link>
      <pubDate>Mon, 21 Apr 2025 22:57:14 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_0/</guid>
      <description>
        
          
            Today, we are excited to announce the availability of Prompt Optimization on Amazon Bedrock. With this capability, you can now optimize your prompts for several use cases with a single API call or a click of a button on the Amazon Bedrock console. In this blog post, we discuss how Prompt Optimization improves the performance of large language models (LLMs) for intelligent text processing task in Yuewen Group.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a location-aware agent using Amazon Bedrock Agents and Foursquare APIs</title>
      <link>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_3/</link>
      <pubDate>Mon, 21 Apr 2025 18:45:27 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_3/</guid>
      <description>
        
          
            In this post, we combine Amazon Bedrock Agents and Foursquare APIs to demonstrate how you can use a location-aware agent to bring personalized responses to your users.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-a-location-aware-agent-using-amazon-bedrock-agents-and-foursquare-apis/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build an automated generative AI solution evaluation pipeline with Amazon Nova</title>
      <link>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_5/</link>
      <pubDate>Mon, 21 Apr 2025 17:16:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/21_04_2025/21_04_2025_5/</guid>
      <description>
        
          
            In this post, we explore the importance of evaluating LLMs in the context of generative AI applications, highlighting the challenges posed by issues like hallucinations and biases. We introduced a comprehensive solution using AWS services to automate the evaluation process, allowing for continuous monitoring and assessment of LLM performance. By using tools like the FMeval Library, Ragas, LLMeter, and Step Functions, the solution provides flexibility and scalability, meeting the evolving needs of LLM consumers.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
