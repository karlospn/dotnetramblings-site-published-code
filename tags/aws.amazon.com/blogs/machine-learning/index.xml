<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Fri, 19 Dec 2025 18:23:50 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Introducing SOCI indexing for Amazon SageMaker Studio: Faster container startup times for AI/ML workloads</title>
      <link>https://www.dotnetramblings.com/post/19_12_2025/19_12_2025_2/</link>
      <pubDate>Fri, 19 Dec 2025 18:23:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/19_12_2025/19_12_2025_2/</guid>
      <description>
        
          
            Today, we are excited to introduce a new feature for SageMaker Studio: SOCI (Seekable Open Container Initiative) indexing. SOCI supports lazy loading of container images, where only the necessary parts of an image are downloaded initially rather than the entire container.
Link to article: https://aws.amazon.com/blogs/machine-learning/introducing-soci-indexing-for-amazon-sagemaker-studio-faster-container-startup-times-for-ai-ml-workloads/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build and deploy scalable AI agents with NVIDIA NeMo, Amazon Bedrock AgentCore, and Strands Agents</title>
      <link>https://www.dotnetramblings.com/post/18_12_2025/18_12_2025_3/</link>
      <pubDate>Thu, 18 Dec 2025 17:26:39 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_12_2025/18_12_2025_3/</guid>
      <description>
        
          
            This post demonstrates how to use the powerful combination of Strands Agents, Amazon Bedrock AgentCore, and NVIDIA NeMo Agent Toolkit to build, evaluate, optimize, and deploy AI agents on Amazon Web Services (AWS) from initial development through production deployment.
Link to article: https://aws.amazon.com/blogs/machine-learning/build-and-deploy-scalable-ai-agents-with-nvidia-nemo-amazon-bedrock-agentcore-and-strands-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Bi-directional streaming for real-time agent interactions now available in Amazon Bedrock AgentCore Runtime</title>
      <link>https://www.dotnetramblings.com/post/18_12_2025/18_12_2025_4/</link>
      <pubDate>Thu, 18 Dec 2025 17:00:21 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_12_2025/18_12_2025_4/</guid>
      <description>
        
          
            In this post, you will learn about bi-directional streaming on AgentCore Runtime and the prerequisites to create a WebSocket implementation. You will also learn how to use Strands Agents to implement a bi-directional streaming solution for voice agents.
Link to article: https://aws.amazon.com/blogs/machine-learning/bi-directional-streaming-for-real-time-agent-interactions-now-available-in-amazon-bedrock-agentcore-runtime/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Tracking and managing assets used in AI development with Amazon SageMaker AI</title>
      <link>https://www.dotnetramblings.com/post/17_12_2025/17_12_2025_1/</link>
      <pubDate>Wed, 17 Dec 2025 16:53:30 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_12_2025/17_12_2025_1/</guid>
      <description>
        
          
            In this post, we&#39;ll explore the new capabilities and core concepts that help organizations track and manage models development and deployment lifecycles. We will show you how the features are configured to train models with automatic end-to-end lineage, from dataset upload and versioning to model fine-tuning, evaluation, and seamless endpoint deployment.
Link to article: https://aws.amazon.com/blogs/machine-learning/tracking-and-managing-assets-used-in-ai-development-with-amazon-sagemaker-ai/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Track machine learning experiments with MLflow on Amazon SageMaker using Snowflake integration</title>
      <link>https://www.dotnetramblings.com/post/17_12_2025/17_12_2025_2/</link>
      <pubDate>Wed, 17 Dec 2025 16:50:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/17_12_2025/17_12_2025_2/</guid>
      <description>
        
          
            In this post, we demonstrate how to integrate Amazon SageMaker managed MLflow as a central repository to log these experiments and provide a unified system for monitoring their progress.
Link to article: https://aws.amazon.com/blogs/machine-learning/track-machine-learning-experiments-with-mlflow-on-amazon-sagemaker-using-snowflake-integration/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Governance by design: The essential guide for successful AI scaling</title>
      <link>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_2/</link>
      <pubDate>Tue, 16 Dec 2025 21:18:54 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_2/</guid>
      <description>
        
          
            Picture this: Your enterprise has just deployed its first generative AI application. The initial results are promising, but as you plan to scale across departments, critical questions emerge. How will you enforce consistent security, prevent model bias, and maintain control as AI applications multiply?
Link to article: https://aws.amazon.com/blogs/machine-learning/governance-by-design-the-essential-guide-for-successful-ai-scaling/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Tata Power CoE built a scalable AI-powered solar panel inspection solution with Amazon SageMaker AI and Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_4/</link>
      <pubDate>Tue, 16 Dec 2025 18:55:36 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_4/</guid>
      <description>
        
          
            In this post, we explore how Tata Power CoE and Oneture Technologies use AWS services to automate the inspection process end-to-end.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-tata-power-coe-built-a-scalable-ai-powered-solar-panel-inspection-solution-with-amazon-sagemaker-ai-and-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Unlocking video understanding with TwelveLabs Marengo on Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_5/</link>
      <pubDate>Tue, 16 Dec 2025 18:51:10 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/16_12_2025/16_12_2025_5/</guid>
      <description>
        
          
            In this post, we&#39;ll show how the TwelveLabs Marengo embedding model, available on Amazon Bedrock, enhances video understanding through multimodal AI. We&#39;ll build a video semantic search and analysis solution using embeddings from the Marengo model with Amazon OpenSearch Serverless as the vector database, for semantic search capabilities that go beyond simple metadata matching to deliver intelligent content discovery.
Link to article: https://aws.amazon.com/blogs/machine-learning/unlocking-video-understanding-with-twelvelabs-marengo-on-amazon-bedrock/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Checkpointless training on Amazon SageMaker HyperPod: Production-scale training with faster fault recovery</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_0/</link>
      <pubDate>Mon, 15 Dec 2025 19:45:50 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_0/</guid>
      <description>
        
          
            In this post, we introduce checkpointless training on Amazon SageMaker HyperPod, a paradigm shift in model training that reduces the need for traditional checkpointing by enabling peer-to-peer state recovery. Results from production-scale validation show 80–93% reduction in recovery time (from 15–30 minutes or more to under 2 minutes) and enables up to 95% training goodput on cluster sizes with thousands of AI accelerators.
Link to article: https://aws.amazon.com/blogs/machine-learning/checkpointless-training-on-amazon-sagemaker-hyperpod-production-scale-training-with-faster-fault-recovery/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Adaptive infrastructure for foundation model training with elastic training on SageMaker HyperPod</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_2/</link>
      <pubDate>Mon, 15 Dec 2025 18:12:22 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_2/</guid>
      <description>
        
          
            Amazon SageMaker HyperPod now supports elastic training, enabling your machine learning (ML) workloads to automatically scale based on resource availability. In this post, we demonstrate how elastic training helps you maximize GPU utilization, reduce costs, and accelerate model development through dynamic resource adaptation, while maintain training quality and minimizing manual intervention.
Link to article: https://aws.amazon.com/blogs/machine-learning/adaptive-infrastructure-for-foundation-model-training-with-elastic-training-on-sagemaker-hyperpod/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Customize agent workflows with advanced orchestration techniques using Strands Agents</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_4/</link>
      <pubDate>Mon, 15 Dec 2025 17:35:47 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_4/</guid>
      <description>
        
          
            In this post, we explore two powerful orchestration patterns implemented with Strands Agents. Using a common set of travel planning tools, we demonstrate how different orchestration strategies can solve the same problem through distinct reasoning approaches,
Link to article: https://aws.amazon.com/blogs/machine-learning/customize-agent-workflows-with-advanced-orchestration-techniques-using-strands-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Operationalize generative AI workloads and scale to hundreds of use cases with Amazon Bedrock – Part 1: GenAIOps</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_5/</link>
      <pubDate>Mon, 15 Dec 2025 17:31:53 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_5/</guid>
      <description>
        
          
            In this first part of our two-part series, you&#39;ll learn how to evolve your existing DevOps architecture for generative AI workloads and implement GenAIOps practices. We&#39;ll showcase practical implementation strategies for different generative AI adoption levels, focusing on consuming foundation models.
Link to article: https://aws.amazon.com/blogs/machine-learning/operationalize-generative-ai-workloads-and-scale-to-hundreds-of-use-cases-with-amazon-bedrock-part-1-genaiops/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Applying data loading best practices for ML training with Amazon S3 clients</title>
      <link>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_6/</link>
      <pubDate>Mon, 15 Dec 2025 17:29:31 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/15_12_2025/15_12_2025_6/</guid>
      <description>
        
          
            In this post, we present practical techniques and recommendations for optimizing throughput in ML training workloads that read data directly from Amazon S3 general purpose buckets.
Link to article: https://aws.amazon.com/blogs/machine-learning/applying-data-loading-best-practices-for-ml-training-with-amazon-s3-clients/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Building a voice-driven AWS assistant with Amazon Nova Sonic</title>
      <link>https://www.dotnetramblings.com/post/12_12_2025/12_12_2025_1/</link>
      <pubDate>Fri, 12 Dec 2025 18:07:57 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/12_12_2025/12_12_2025_1/</guid>
      <description>
        
          
            In this post, we explore how to build a sophisticated voice-powered AWS operations assistant using Amazon Nova Sonic for speech processing and Strands Agents for multi-agent orchestration. This solution demonstrates how natural language voice interactions can transform cloud operations, making AWS services more accessible and operations more efficient.
Link to article: https://aws.amazon.com/blogs/machine-learning/building-a-voice-driven-aws-assistant-with-amazon-nova-sonic/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
