<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/</link>
    <description>Recent content in Aws.amazon.com/Blogs/Machine-Learning on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Thu, 06 Feb 2025 18:07:55 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/aws.amazon.com/blogs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fine-tune and host SDXL models cost-effectively with AWS Inferentia2</title>
      <link>https://www.dotnetramblings.com/post/06_02_2025/06_02_2025_3/</link>
      <pubDate>Thu, 06 Feb 2025 18:07:55 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_02_2025/06_02_2025_3/</guid>
      <description>
        
          
            As technology continues to evolve, newer models are emerging, offering higher quality, increased flexibility, and faster image generation capabilities. One such groundbreaking model is Stable Diffusion XL (SDXL), released by StabilityAI, advancing the text-to-image generative AI technology to unprecedented heights. In this post, we demonstrate how to efficiently fine-tune the SDXL model using SageMaker Studio. We show how to then prepare the fine-tuned model to run on AWS Inferentia2 powered Amazon EC2 Inf2 instances, unlocking superior price performance for your inference workloads.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Aetion is using generative AI and Amazon Bedrock to translate scientific intent to results</title>
      <link>https://www.dotnetramblings.com/post/06_02_2025/06_02_2025_5/</link>
      <pubDate>Thu, 06 Feb 2025 17:55:49 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/06_02_2025/06_02_2025_5/</guid>
      <description>
        
          
            Aetion is a leading provider of decision-grade real-world evidence software to biopharma, payors, and regulatory agencies. In this post, we review how Aetion is using Amazon Bedrock to help streamline the analytical process toward producing decision-grade real-world evidence and enable users without data science expertise to interact with complex real-world datasets.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-aetion-is-using-generative-ai-and-amazon-bedrock-to-translate-scientific-intent-to-results/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Trellix lowers cost, increases speed, and adds delivery flexibility with cost-effective and performant Amazon Nova Micro and Amazon Nova Lite models</title>
      <link>https://www.dotnetramblings.com/post/05_02_2025/05_02_2025_0/</link>
      <pubDate>Wed, 05 Feb 2025 22:53:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_02_2025/05_02_2025_0/</guid>
      <description>
        
          
            This post discusses the adoption and evaluation of Amazon Nova foundation models by Trellix, a leading company delivering cybersecurity’s broadest AI-powered platform to over 53,000 customers worldwide.
Link to article: https://aws.amazon.com/blogs/machine-learning/trellix-lowers-cost-increases-speed-and-adds-delivery-flexibility-with-cost-effective-and-performant-amazon-nova-micro-and-amazon-nova-lite-models/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>OfferUp improved local results by 54% and relevance recall by 27% with multimodal search on Amazon Bedrock and Amazon OpenSearch Service</title>
      <link>https://www.dotnetramblings.com/post/05_02_2025/05_02_2025_8/</link>
      <pubDate>Wed, 05 Feb 2025 19:06:55 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_02_2025/05_02_2025_8/</guid>
      <description>
        
          
            In this post, we demonstrate how OfferUp transformed its foundational search architecture using Amazon Titan Multimodal Embeddings and OpenSearch Service, significantly increasing user engagement, improving search quality and offering users the ability to search with both text and images. OfferUp selected Amazon Titan Multimodal Embeddings and Amazon OpenSearch Service for their fully managed capabilities, enabling the development of a robust multimodal search solution with high accuracy and a faster time to market for search and recommendation use cases.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Enhancing LLM Capabilities with NeMo Guardrails on Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/05_02_2025/05_02_2025_11/</link>
      <pubDate>Wed, 05 Feb 2025 17:50:14 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_02_2025/05_02_2025_11/</guid>
      <description>
        
          
            Integrating NeMo Guardrails with Large Language Models (LLMs) is a powerful step forward in deploying AI in customer-facing applications. The example of AnyCompany Pet Supplies illustrates how these technologies can enhance customer interactions while handling refusal and guiding the conversation toward the implemented outcomes. This journey towards ethical AI deployment is crucial for building sustainable, trust-based relationships with customers and shaping a future where technology aligns seamlessly with human values.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Build a multi-interface AI assistant using Amazon Q and Slack with Amazon CloudFront clickable references from an Amazon S3 bucket</title>
      <link>https://www.dotnetramblings.com/post/05_02_2025/05_02_2025_12/</link>
      <pubDate>Wed, 05 Feb 2025 16:56:56 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/05_02_2025/05_02_2025_12/</guid>
      <description>
        
          
            There is consistent customer feedback that AI assistants are the most useful when users can interface with them within the productivity tools they already use on a daily basis, to avoid switching applications and context. Web applications like Amazon Q Business and Slack have become essential environments for modern AI assistant deployment. This post explores how diverse interfaces enhance user interaction, improve accessibility, and cater to varying preferences.
Link to article: https://aws.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Orchestrate seamless business systems integrations using Amazon Bedrock Agents</title>
      <link>https://www.dotnetramblings.com/post/04_02_2025/04_02_2025_1/</link>
      <pubDate>Tue, 04 Feb 2025 17:58:33 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/04_02_2025/04_02_2025_1/</guid>
      <description>
        
          
            The post showcases how generative AI can be used to logic, reason, and orchestrate integrations using a fictitious business process. It demonstrates strategies and techniques for orchestrating Amazon Bedrock agents and action groups to seamlessly integrate generative AI with existing business systems, enabling efficient data access and unlocking the full potential of generative AI.
Link to article: https://aws.amazon.com/blogs/machine-learning/orchestrate-seamless-business-systems-integrations-using-amazon-bedrock-agents/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate video Q&amp;A workflows using Amazon Bedrock Knowledge Bases, Amazon Transcribe, and thoughtful UX design</title>
      <link>https://www.dotnetramblings.com/post/03_02_2025/03_02_2025_3/</link>
      <pubDate>Mon, 03 Feb 2025 17:04:42 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_02_2025/03_02_2025_3/</guid>
      <description>
        
          
            The solution presented in this post demonstrates a powerful pattern for accelerating video and audio review workflows while maintaining human oversight. By combining the power of AI models in Amazon Bedrock with human expertise, you can create tools that not only boost productivity but also maintain the critical element of human judgment in important decision-making processes.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-video-qa-workflows-using-amazon-bedrock-knowledge-bases-amazon-transcribe-and-thoughtful-ux-design/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Boost team innovation, productivity, and knowledge sharing with Amazon Q Apps</title>
      <link>https://www.dotnetramblings.com/post/03_02_2025/03_02_2025_4/</link>
      <pubDate>Mon, 03 Feb 2025 16:59:17 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/03_02_2025/03_02_2025_4/</guid>
      <description>
        
          
            In this post, we demonstrate how Amazon Q Apps can help maximize the value of existing knowledge resources and improve productivity among various teams, ranging from finance to DevOps to support engineers. We share specific examples of how the generative AI assistant can enable surface relevant information, distill complex topics, generate custom content, and execute workflows—all while maintaining robust security and data governance controls.
Link to article: https://aws.amazon.com/blogs/machine-learning/boost-team-innovation-productivity-and-knowledge-sharing-with-amazon-q-apps/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Harnessing Amazon Bedrock generative AI for resilient supply chain</title>
      <link>https://www.dotnetramblings.com/post/31_01_2025/31_01_2025_2/</link>
      <pubDate>Fri, 31 Jan 2025 19:59:48 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_01_2025/31_01_2025_2/</guid>
      <description>
        
          
            By leveraging the generative AI capabilities and tooling of Amazon Bedrock, you can create an intelligent nerve center that connects diverse data sources, converts data into actionable insights, and creates a comprehensive plan to mitigate supply chain risks. This post walks through how Amazon Bedrock Flows connects your business systems, monitors medical device shortages, and provides mitigation strategies based on knowledge from Amazon Bedrock Knowledge Bases or data stored in Amazon S3 directly.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Travelers Insurance classified emails with Amazon Bedrock and prompt engineering</title>
      <link>https://www.dotnetramblings.com/post/31_01_2025/31_01_2025_4/</link>
      <pubDate>Fri, 31 Jan 2025 17:18:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_01_2025/31_01_2025_4/</guid>
      <description>
        
          
            In this post, we discuss how FMs can reliably automate the classification of insurance service emails through prompt engineering. When formulating the problem as a classification task, an FM can perform well enough for production environments, while maintaining extensibility into other tasks and getting up and running quickly. All experiments were conducted using Anthropic’s Claude models on Amazon Bedrock.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-travelers-insurance-classified-emails-with-amazon-bedrock-and-prompt-engineering/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Accelerate digital pathology slide annotation workflows on AWS using H-optimus-0</title>
      <link>https://www.dotnetramblings.com/post/31_01_2025/31_01_2025_5/</link>
      <pubDate>Fri, 31 Jan 2025 17:10:08 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_01_2025/31_01_2025_5/</guid>
      <description>
        
          
            In this post, we demonstrate how to use H-optimus-0 for two common digital pathology tasks: patch-level analysis for detailed tissue examination, and slide-level analysis for broader diagnostic assessment. Through practical examples, we show you how to adapt this FM to these specific use cases while optimizing computational resources.
Link to article: https://aws.amazon.com/blogs/machine-learning/accelerate-digital-pathology-slide-annotation-workflows-on-aws-using-h-optimus-0/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>DeepSeek-R1 model now available in Amazon Bedrock Marketplace and Amazon SageMaker JumpStart</title>
      <link>https://www.dotnetramblings.com/post/31_01_2025/31_01_2025_10/</link>
      <pubDate>Fri, 31 Jan 2025 02:31:38 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/31_01_2025/31_01_2025_10/</guid>
      <description>
        
          
            DeepSeek-R1 is an advanced large language model that combines reinforcement learning, chain-of-thought reasoning, and a Mixture of Experts architecture to deliver efficient, interpretable responses while maintaining safety through Amazon Bedrock Guardrails integration.
Link to article: https://aws.amazon.com/blogs/machine-learning/deepseek-r1-model-now-available-in-amazon-bedrock-marketplace-and-amazon-sagemaker-jumpstart/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Streamline grant proposal reviews using Amazon Bedrock</title>
      <link>https://www.dotnetramblings.com/post/30_01_2025/30_01_2025_7/</link>
      <pubDate>Thu, 30 Jan 2025 17:55:52 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_01_2025/30_01_2025_7/</guid>
      <description>
        
          
            The AWS Social Responsibility &amp;amp; Impact (SRI) team recognized an opportunity to augment this function using generative AI. The team developed an innovative solution to streamline grant proposal review and evaluation by using the natural language processing (NLP) capabilities of Amazon Bedrock. In this post, we explore the technical implementation details and key learnings from the team’s Amazon Bedrock powered grant proposal review solution, providing a blueprint for organizations seeking to optimize their grants management processes.
          
          
        
      </description>
    </item>
    
    <item>
      <title>How Aetion is using generative AI and Amazon Bedrock to unlock hidden insights about patient populations</title>
      <link>https://www.dotnetramblings.com/post/30_01_2025/30_01_2025_8/</link>
      <pubDate>Thu, 30 Jan 2025 17:51:51 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_01_2025/30_01_2025_8/</guid>
      <description>
        
          
            In this post, we review how Aetion’s Smart Subgroups Interpreter enables users to interact with Smart Subgroups using natural language queries. Powered by Amazon Bedrock and Anthropic’s Claude 3 large language models (LLMs), the interpreter responds to user questions expressed in conversational language about patient subgroups and provides insights to generate further hypotheses and evidence.
Link to article: https://aws.amazon.com/blogs/machine-learning/how-aetion-is-using-generative-ai-and-amazon-bedrock-to-unlock-hidden-insights-about-patient-populations/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deploy DeepSeek-R1 distilled Llama models with Amazon Bedrock Custom Model Import</title>
      <link>https://www.dotnetramblings.com/post/30_01_2025/30_01_2025_15/</link>
      <pubDate>Thu, 30 Jan 2025 01:10:15 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/30_01_2025/30_01_2025_15/</guid>
      <description>
        
          
            In this post, we demonstrate how to deploy distilled versions of DeepSeek-R1 models using Amazon Bedrock Custom Model Import. We focus on importing the variants currently supported DeepSeek-R1-Distill-Llama-8B and DeepSeek-R1-Distill-Llama-70B, which offer an optimal balance between performance and resource efficiency.
Link to article: https://aws.amazon.com/blogs/machine-learning/deploy-deepseek-r1-distilled-llama-models-with-amazon-bedrock-custom-model-import/ 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
