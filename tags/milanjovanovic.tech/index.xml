<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Milanjovanovic.tech on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/milanjovanovic.tech/</link>
    <description>Recent content in Milanjovanovic.tech on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Sat, 18 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/milanjovanovic.tech/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Scaling Monoliths: A Practical Guide for Growing Systems</title>
      <link>https://www.dotnetramblings.com/post/18_01_2025/18_01_2025_0/</link>
      <pubDate>Sat, 18 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/18_01_2025/18_01_2025_0/</guid>
      <description>
        
          
            A well-designed monolith can scale remarkably well, despite industry trends pushing toward microservices. From database sharding to message queues, learn practical strategies to grow your monolithic system effectively.
Link to article: https://www.milanjovanovic.tech/blog/scaling-monoliths-a-practical-guide-for-growing-systems 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Working with LLMs in .NET using Microsoft.Extensions.AI</title>
      <link>https://www.dotnetramblings.com/post/11_01_2025/11_01_2025_2/</link>
      <pubDate>Sat, 11 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/11_01_2025/11_01_2025_2/</guid>
      <description>
        
          
            Microsoft.Extensions.AI provides a unified interface for integrating LLMs into .NET applications, allowing developers to switch between providers like Ollama, Azure, or OpenAI without changing application code. Through practical examples of chat completion, article summarization, and smart categorization, this article demonstrates how to leverage the library&#39;s features while running LLMs locally using Ollama.
Link to article: https://www.milanjovanovic.tech/blog/working-with-llms-in-dotnet-using-microsoft-extensions-ai 
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
