<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Build5nines.com on .NET Ramblings</title>
    <link>https://www.dotnetramblings.com/tags/build5nines.com/</link>
    <description>Recent content in Build5nines.com on .NET Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>.NET Ramblings</copyright>
    <lastBuildDate>Mon, 23 Dec 2024 21:30:23 +0000</lastBuildDate><atom:link href="https://www.dotnetramblings.com/tags/build5nines.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Phi-4: Microsoft’s New Small Language Model Outperforms Giants in AI Reasoning</title>
      <link>https://www.dotnetramblings.com/post/23_12_2024/23_12_2024_1/</link>
      <pubDate>Mon, 23 Dec 2024 21:30:23 +0000</pubDate>
      
      <guid>https://www.dotnetramblings.com/post/23_12_2024/23_12_2024_1/</guid>
      <description>
        
          
            With Artificial Intelligence and Large Language Models (LLMs), bigger has often better. LLMs like OpenAI’s GPT-4o and Google’s Gemini Pro have dominated headlines for their massive scale and capabilities. However, Microsoft is redefining this narrative with Phi-4, a 14-billion parameter small language model (SLM) that delivers exceptional performance, rivaling models many times its size. Phi-4 […] The article Phi-4: Microsoft’s New Small Language Model Outperforms Giants in AI Reasoning was originally published on Build5Nines.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
